{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3afb562f0ddb45fd8580a8fa52ea46db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4447517179442188300a293a488a07d",
              "IPY_MODEL_ebabf6f21d3743a5b91ce200c9583b9b",
              "IPY_MODEL_b907a5524f5b4d8bb720a9caa0c8a49e"
            ],
            "layout": "IPY_MODEL_043487af67e94a07a223c106e85dbe20"
          }
        },
        "d4447517179442188300a293a488a07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_978dd8179e54493b9b45b13c710247db",
            "placeholder": "​",
            "style": "IPY_MODEL_fe69de0eab644cbbae558ab72d45dc1c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ebabf6f21d3743a5b91ce200c9583b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_585323f6ce6240da89bbe758a0c112f7",
            "max": 81,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52d287c068fa424abb89e70da8c405f1",
            "value": 81
          }
        },
        "b907a5524f5b4d8bb720a9caa0c8a49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49982e8ce73145a9868f79c1683d4a70",
            "placeholder": "​",
            "style": "IPY_MODEL_e638b01ecf6f4e6c88f09b5915428b8b",
            "value": " 81.0/81.0 [00:00&lt;00:00, 9.59kB/s]"
          }
        },
        "043487af67e94a07a223c106e85dbe20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "978dd8179e54493b9b45b13c710247db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe69de0eab644cbbae558ab72d45dc1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "585323f6ce6240da89bbe758a0c112f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52d287c068fa424abb89e70da8c405f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49982e8ce73145a9868f79c1683d4a70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e638b01ecf6f4e6c88f09b5915428b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7130a7ab461043e4af74af1015919a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9dda30c38ea74edbb13cfb820c9d3418",
              "IPY_MODEL_64e37bc0b22242abab2f4472bc30c355",
              "IPY_MODEL_9497be6b27f2457e87c271d94b341fa6"
            ],
            "layout": "IPY_MODEL_abe798d94d91434ea78f2779470aaed1"
          }
        },
        "9dda30c38ea74edbb13cfb820c9d3418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29c0c78a9ff245fbad2767bf968699f8",
            "placeholder": "​",
            "style": "IPY_MODEL_976591eb0ff84caf847a0517c9885e86",
            "value": "config.json: 100%"
          }
        },
        "64e37bc0b22242abab2f4472bc30c355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_510da51030244aeaaabf02f3358e79af",
            "max": 541,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abf69c2690314697800082082bfbbb35",
            "value": 541
          }
        },
        "9497be6b27f2457e87c271d94b341fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_952167dee6f644f2a52c054b026a6289",
            "placeholder": "​",
            "style": "IPY_MODEL_08fcb8acbef9415e8e90ee3471b05417",
            "value": " 541/541 [00:00&lt;00:00, 44.4kB/s]"
          }
        },
        "abe798d94d91434ea78f2779470aaed1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29c0c78a9ff245fbad2767bf968699f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "976591eb0ff84caf847a0517c9885e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "510da51030244aeaaabf02f3358e79af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abf69c2690314697800082082bfbbb35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "952167dee6f644f2a52c054b026a6289": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08fcb8acbef9415e8e90ee3471b05417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b84060cc44e04353ba0ca823deac0ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fe62f1eb349451e9d4a10e85c737a95",
              "IPY_MODEL_ad8d6fa2a3ba4e6cbf7ed5241e935ace",
              "IPY_MODEL_940e08289df74703a83e1b59c12e1180"
            ],
            "layout": "IPY_MODEL_c10284631d8546b0a0d272725abee486"
          }
        },
        "0fe62f1eb349451e9d4a10e85c737a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d90d36922ca48b0832e3871773476b3",
            "placeholder": "​",
            "style": "IPY_MODEL_93df43cfe56c475da6036a4a898fcb77",
            "value": "spiece.model: 100%"
          }
        },
        "ad8d6fa2a3ba4e6cbf7ed5241e935ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aab6f51de9b4298b0b1a6d59a0b5ec7",
            "max": 2435308,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_294a8b393b194d069e682c36d99ad333",
            "value": 2435308
          }
        },
        "940e08289df74703a83e1b59c12e1180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_771ac60e36b04938ac84dd9e9d532e46",
            "placeholder": "​",
            "style": "IPY_MODEL_5de50799b0cd45e9b18c7cd936023c63",
            "value": " 2.44M/2.44M [00:00&lt;00:00, 44.6MB/s]"
          }
        },
        "c10284631d8546b0a0d272725abee486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d90d36922ca48b0832e3871773476b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93df43cfe56c475da6036a4a898fcb77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6aab6f51de9b4298b0b1a6d59a0b5ec7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "294a8b393b194d069e682c36d99ad333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "771ac60e36b04938ac84dd9e9d532e46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5de50799b0cd45e9b18c7cd936023c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cebe836690d471182ec1e8c48f7d79b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a095ca87b884693a2e00f9d4c483a8e",
              "IPY_MODEL_07b5f3ce8c6e45a182f964e432993965",
              "IPY_MODEL_735415fc2d3547c19da5ceaff1238423"
            ],
            "layout": "IPY_MODEL_76b8a8dac6c54a95a13d88847eb227ac"
          }
        },
        "1a095ca87b884693a2e00f9d4c483a8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_754520b5a1d94c858dadb54cd65cf842",
            "placeholder": "​",
            "style": "IPY_MODEL_a08b94be7ef543bf8d667db6e76abbf9",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "07b5f3ce8c6e45a182f964e432993965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1fc6e755aee46ef80e8ab4ac800898f",
            "max": 98,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca9735659c6f48999c4ecb506e13c8d6",
            "value": 98
          }
        },
        "735415fc2d3547c19da5ceaff1238423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af473c771236423fb6161d57a2523282",
            "placeholder": "​",
            "style": "IPY_MODEL_6a17dc60093e4c10aa4f4fe8c15f0751",
            "value": " 98.0/98.0 [00:00&lt;00:00, 10.1kB/s]"
          }
        },
        "76b8a8dac6c54a95a13d88847eb227ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "754520b5a1d94c858dadb54cd65cf842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a08b94be7ef543bf8d667db6e76abbf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1fc6e755aee46ef80e8ab4ac800898f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca9735659c6f48999c4ecb506e13c8d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af473c771236423fb6161d57a2523282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a17dc60093e4c10aa4f4fe8c15f0751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "137db1e3798c499c81a502e480322fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64e7b3af4fab454e85f40b08ca41b1b4",
              "IPY_MODEL_7a47aedc98e24c328139eb53e0aeafaa",
              "IPY_MODEL_4f9ad940657547bebe0da53e22382313"
            ],
            "layout": "IPY_MODEL_edf4ea668d574e36816508f4d9c93541"
          }
        },
        "64e7b3af4fab454e85f40b08ca41b1b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59598302744945a3b20bbd9cf9e7d2c4",
            "placeholder": "​",
            "style": "IPY_MODEL_6d12ce5f1c9b4a609e9eb027d1e53233",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "7a47aedc98e24c328139eb53e0aeafaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d87c84f8df2b40faa5b7b71b2eff8dda",
            "max": 1131212560,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24b8da519f2742b089f720ef90f121b9",
            "value": 1131212560
          }
        },
        "4f9ad940657547bebe0da53e22382313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7ab81c1e85c4e08972cab5e54113939",
            "placeholder": "​",
            "style": "IPY_MODEL_78f5e99d982f4a019e964da218d1ace4",
            "value": " 1.13G/1.13G [00:06&lt;00:00, 212MB/s]"
          }
        },
        "edf4ea668d574e36816508f4d9c93541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59598302744945a3b20bbd9cf9e7d2c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d12ce5f1c9b4a609e9eb027d1e53233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d87c84f8df2b40faa5b7b71b2eff8dda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24b8da519f2742b089f720ef90f121b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7ab81c1e85c4e08972cab5e54113939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78f5e99d982f4a019e964da218d1ace4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd142d8abbdd4568bde85bb1190b553b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d784f044a6a4e8eaa2dfaf765a197b1",
              "IPY_MODEL_99e9b8c0f58448048cd7ad62acf00822",
              "IPY_MODEL_1a26b8e7131a47b4ad17f5d2182a222e"
            ],
            "layout": "IPY_MODEL_17363429dced43ad85b190a0e913becf"
          }
        },
        "5d784f044a6a4e8eaa2dfaf765a197b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d732f5a84a242a4a945c62e448fd535",
            "placeholder": "​",
            "style": "IPY_MODEL_04eb032b530c4de0844b1d24de28162e",
            "value": "model.safetensors: 100%"
          }
        },
        "99e9b8c0f58448048cd7ad62acf00822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb4975ccf04e44e5a4b806c368cdda1c",
            "max": 1131116552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56f858c1534f4d928f8fc476bd0d6884",
            "value": 1131116552
          }
        },
        "1a26b8e7131a47b4ad17f5d2182a222e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14648dabe7b44d1d87730bf339dd219e",
            "placeholder": "​",
            "style": "IPY_MODEL_429031390bae42bdadc848ace866f49e",
            "value": " 1.13G/1.13G [00:05&lt;00:00, 233MB/s]"
          }
        },
        "17363429dced43ad85b190a0e913becf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d732f5a84a242a4a945c62e448fd535": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04eb032b530c4de0844b1d24de28162e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb4975ccf04e44e5a4b806c368cdda1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56f858c1534f4d928f8fc476bd0d6884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14648dabe7b44d1d87730bf339dd219e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "429031390bae42bdadc848ace866f49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xN-5B8npkdYp",
        "outputId": "3ad41784-a9fb-42f2-f264-c4d0270ede38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement du tokenizer et du modèle AraT5...\n",
            "Création des données d'entraînement avec thèmes islamiques et arabes (3000 exemples)...\n",
            "Augmentation des données...\n",
            "Division des données en ensembles d'entraînement, validation et test...\n",
            "Répartition des notes dans l'ensemble d'entraînement:\n",
            "Note 1/5: 868 exemples (20.1%)\n",
            "Note 2/5: 885 exemples (20.5%)\n",
            "Note 3/5: 850 exemples (19.7%)\n",
            "Note 4/5: 864 exemples (20.0%)\n",
            "Note 5/5: 853 exemples (19.7%)\n",
            "Utilisation de l'appareil: cuda\n",
            "Début de l'entraînement pour 15 époques maximum...\n",
            "Époque 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 270/270 [04:23<00:00,  1.03it/s, loss=107, lr=1.99e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 107.4019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 68/68 [00:55<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 103.3962, Accuracy: 0.1972\n",
            "Kappa: 0.0000, MAE: 1.2009\n",
            "Matrice de confusion:\n",
            "[[  0   0 217   0   0]\n",
            " [  0   0 221   0   0]\n",
            " [  0   0 213   0   0]\n",
            " [  0   0 216   0   0]\n",
            " [  0   0 213   0   0]]\n",
            "Meilleur modèle sauvegardé! Accuracy: 0.1972\n",
            "--------------------------------------------------\n",
            "Époque 2/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 270/270 [04:23<00:00,  1.03it/s, loss=63.3, lr=2.89e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 63.3169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 68/68 [00:55<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 22.8348, Accuracy: 0.1972\n",
            "Kappa: 0.0000, MAE: 1.2009\n",
            "Matrice de confusion:\n",
            "[[  0   0 217   0   0]\n",
            " [  0   0 221   0   0]\n",
            " [  0   0 213   0   0]\n",
            " [  0   0 216   0   0]\n",
            " [  0   0 213   0   0]]\n",
            "--------------------------------------------------\n",
            "Époque 3/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 270/270 [04:22<00:00,  1.03it/s, loss=14.4, lr=2.66e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 14.3995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 68/68 [00:54<00:00,  1.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 15.7572, Accuracy: 0.1972\n",
            "Kappa: 0.0000, MAE: 1.2009\n",
            "Matrice de confusion:\n",
            "[[  0   0 217   0   0]\n",
            " [  0   0 221   0   0]\n",
            " [  0   0 213   0   0]\n",
            " [  0   0 216   0   0]\n",
            " [  0   0 213   0   0]]\n",
            "--------------------------------------------------\n",
            "Époque 4/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 270/270 [04:22<00:00,  1.03it/s, loss=10.6, lr=2.44e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 10.5525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 68/68 [00:44<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 6.9498, Accuracy: 0.1972\n",
            "Kappa: 0.0000, MAE: 1.2009\n",
            "Matrice de confusion:\n",
            "[[  0   0 217   0   0]\n",
            " [  0   0 221   0   0]\n",
            " [  0   0 213   0   0]\n",
            " [  0   0 216   0   0]\n",
            " [  0   0 213   0   0]]\n",
            "--------------------------------------------------\n",
            "Époque 5/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 270/270 [04:22<00:00,  1.03it/s, loss=7.52, lr=2.22e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 7.5204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 68/68 [00:44<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 4.7796, Accuracy: 0.1972\n",
            "Kappa: 0.0000, MAE: 1.2009\n",
            "Matrice de confusion:\n",
            "[[  0   0 217   0   0]\n",
            " [  0   0 221   0   0]\n",
            " [  0   0 213   0   0]\n",
            " [  0   0 216   0   0]\n",
            " [  0   0 213   0   0]]\n",
            "--------------------------------------------------\n",
            "Époque 6/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 270/270 [04:22<00:00,  1.03it/s, loss=5.03, lr=1.99e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 5.0315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 68/68 [00:44<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1467, Accuracy: 0.2000\n",
            "Kappa: 0.0000, MAE: 1.4065\n",
            "Matrice de confusion:\n",
            "[[  0   0   0 217   0]\n",
            " [  0   0   0 221   0]\n",
            " [  0   0   0 213   0]\n",
            " [  0   0   0 216   0]\n",
            " [  0   0   0 213   0]]\n",
            "Meilleur modèle sauvegardé! Accuracy: 0.2000\n",
            "--------------------------------------------------\n",
            "Époque 7/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 270/270 [04:22<00:00,  1.03it/s, loss=1.86, lr=1.77e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.8628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 68/68 [00:44<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7951, Accuracy: 0.2556\n",
            "Kappa: 0.0667, MAE: 1.3963\n",
            "Matrice de confusion:\n",
            "[[ 96 102   0   0  19]\n",
            " [ 64 115   0   0  42]\n",
            " [ 26 130   1   0  56]\n",
            " [  8 163   0   0  45]\n",
            " [  4 145   0   0  64]]\n",
            "Meilleur modèle sauvegardé! Accuracy: 0.2556\n",
            "--------------------------------------------------\n",
            "Époque 8/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 270/270 [04:22<00:00,  1.03it/s, loss=1.02, lr=1.54e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.0158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 68/68 [00:44<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7575, Accuracy: 0.3824\n",
            "Kappa: 0.2294, MAE: 1.2546\n",
            "Matrice de confusion:\n",
            "[[ 58  48  12   1  98]\n",
            " [  8  79  15   2 117]\n",
            " [  0  27  47   0 139]\n",
            " [  0   0  11  21 184]\n",
            " [  0   0   5   0 208]]\n",
            "Meilleur modèle sauvegardé! Accuracy: 0.3824\n",
            "--------------------------------------------------\n",
            "Époque 9/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 270/270 [04:22<00:00,  1.03it/s, loss=0.873, lr=1.32e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.8734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 68/68 [00:44<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6153, Accuracy: 0.5000\n",
            "Kappa: 0.3740, MAE: 0.6509\n",
            "Matrice de confusion:\n",
            "[[211   6   0   0   0]\n",
            " [119  98   0   4   0]\n",
            " [  0 128  15  61   9]\n",
            " [  0  50   1 126  39]\n",
            " [  0  47   6  70  90]]\n",
            "Meilleur modèle sauvegardé! Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "Époque 10/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 270/270 [04:22<00:00,  1.03it/s, loss=0.742, lr=1.1e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.7420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 68/68 [00:44<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4473, Accuracy: 0.6296\n",
            "Kappa: 0.5374, MAE: 0.4296\n",
            "Matrice de confusion:\n",
            "[[215   2   0   0   0]\n",
            " [138  55  27   1   0]\n",
            " [  0   3 103  44  63]\n",
            " [  0   0   6 111  99]\n",
            " [  0   0   0  17 196]]\n",
            "Meilleur modèle sauvegardé! Accuracy: 0.6296\n",
            "--------------------------------------------------\n",
            "Époque 11/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 270/270 [04:22<00:00,  1.03it/s, loss=0.624, lr=8.73e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.6241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 68/68 [00:44<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3809, Accuracy: 0.6259\n",
            "Kappa: 0.5328, MAE: 0.4417\n",
            "Matrice de confusion:\n",
            "[[209   8   0   0   0]\n",
            " [138  79   4   0   0]\n",
            " [  0   1  95  44  73]\n",
            " [  0   0   0  94 122]\n",
            " [  0   0   0  14 199]]\n",
            "--------------------------------------------------\n",
            "Époque 12/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 270/270 [04:22<00:00,  1.03it/s, loss=0.521, lr=6.49e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.5206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 68/68 [00:44<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3452, Accuracy: 0.6639\n",
            "Kappa: 0.5802, MAE: 0.3981\n",
            "Matrice de confusion:\n",
            "[[210   7   0   0   0]\n",
            " [142  77   2   0   0]\n",
            " [  0   1 130  15  67]\n",
            " [  0   0   0  91 125]\n",
            " [  0   0   0   4 209]]\n",
            "Meilleur modèle sauvegardé! Accuracy: 0.6639\n",
            "--------------------------------------------------\n",
            "Époque 13/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 270/270 [04:22<00:00,  1.03it/s, loss=0.47, lr=4.25e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.4697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 68/68 [00:44<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3422, Accuracy: 0.6583\n",
            "Kappa: 0.5733, MAE: 0.3954\n",
            "Matrice de confusion:\n",
            "[[210   7   0   0   0]\n",
            " [140  81   0   0   0]\n",
            " [  0   1 114  40  58]\n",
            " [  0   0   0  93 123]\n",
            " [  0   0   0   0 213]]\n",
            "--------------------------------------------------\n",
            "Époque 14/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 270/270 [04:22<00:00,  1.03it/s, loss=0.434, lr=2.01e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.4338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 68/68 [00:44<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3366, Accuracy: 0.6556\n",
            "Kappa: 0.5698, MAE: 0.3917\n",
            "Matrice de confusion:\n",
            "[[210   7   0   0   0]\n",
            " [151  70   0   0   0]\n",
            " [  0   1 121  40  51]\n",
            " [  0   0   0  94 122]\n",
            " [  0   0   0   0 213]]\n",
            "--------------------------------------------------\n",
            "Époque 15/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 270/270 [04:22<00:00,  1.03it/s, loss=0.419, lr=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.4189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 68/68 [00:44<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3260, Accuracy: 0.6602\n",
            "Kappa: 0.5756, MAE: 0.3843\n",
            "Matrice de confusion:\n",
            "[[210   7   0   0   0]\n",
            " [151  70   0   0   0]\n",
            " [  0   1 126  38  48]\n",
            " [  0   0   0  94 122]\n",
            " [  0   0   0   0 213]]\n",
            "--------------------------------------------------\n",
            "Évaluation finale sur l'ensemble de test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 38/38 [00:24<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.3459, Test Accuracy: 0.6667\n",
            "Test Kappa: 0.5837, Test MAE: 0.3883\n",
            "Matrice de confusion finale:\n",
            "[[116   5   0   0   0]\n",
            " [ 75  46   2   0   0]\n",
            " [  0   0  81   4  33]\n",
            " [  0   0   0  43  77]\n",
            " [  0   0   0   4 114]]\n",
            "\n",
            "Tests sur des exemples réels...\n",
            "Test du modèle AraT5 sur des exemples réels:\n",
            "Exemple 1:\n",
            "Question: ما هي أركان الإسلام الخمسة؟\n",
            "Réponse (extrait): أركان الإسلام خمسة: شهادة أن لا إله إلا الله وأن محمدًا رسول الله، وإقام الصلاة، وإيتاء الزكاة، وصوم...\n",
            "Note attendue: 5/5, Note prédite: 4/5\n",
            "Résultat: ✗\n",
            "--------------------------------------------------\n",
            "Exemple 2:\n",
            "Question: ما هي أركان الإسلام الخمسة؟\n",
            "Réponse (extrait): الشهادتين والصلاة والزكاة والصيام والحج....\n",
            "Note attendue: 3/5, Note prédite: 2/5\n",
            "Résultat: ✗\n",
            "--------------------------------------------------\n",
            "Exemple 3:\n",
            "Question: ما هي أركان الإسلام الخمسة؟\n",
            "Réponse (extrait): الصلاة والصيام والحج....\n",
            "Note attendue: 2/5, Note prédite: 1/5\n",
            "Résultat: ✗\n",
            "--------------------------------------------------\n",
            "Exemple 4:\n",
            "Question: ما هي أركان الإسلام الخمسة؟\n",
            "Réponse (extrait): لا أعرف بالضبط....\n",
            "Note attendue: 1/5, Note prédite: 1/5\n",
            "Résultat: ✓\n",
            "--------------------------------------------------\n",
            "Exemple 5:\n",
            "Question: ما هي شروط الصلاة؟\n",
            "Réponse (extrait): شروط الصلاة هي: الإسلام، والعقل، والتمييز، ودخول الوقت، ورفع الحدث، وإزالة النجاسة، وستر العورة، واس...\n",
            "Note attendue: 5/5, Note prédite: 4/5\n",
            "Résultat: ✗\n",
            "--------------------------------------------------\n",
            "Exemple 6:\n",
            "Question: ما هي شروط الصلاة؟\n",
            "Réponse (extrait): من شروط الصلاة الطهارة واستقبال القبلة وستر العورة....\n",
            "Note attendue: 3/5, Note prédite: 2/5\n",
            "Résultat: ✗\n",
            "--------------------------------------------------\n",
            "Exemple 7:\n",
            "Question: ما هي أقسام الكلام في اللغة العربية؟\n",
            "Réponse (extrait): تنقسم الكلمة في اللغة العربية إلى ثلاثة أقسام: اسم وفعل وحرف. الاسم هو ما دل على معنى في نفسه ولم يق...\n",
            "Note attendue: 5/5, Note prédite: 5/5\n",
            "Résultat: ✓\n",
            "--------------------------------------------------\n",
            "Exemple 8:\n",
            "Question: ما هي أقسام الكلام في اللغة العربية؟\n",
            "Réponse (extrait): أقسام الكلام في اللغة العربية هي: اسم وفعل وحرف....\n",
            "Note attendue: 3/5, Note prédite: 2/5\n",
            "Résultat: ✗\n",
            "--------------------------------------------------\n",
            "Exemple 9:\n",
            "Question: ما هي أقسام الكلام في اللغة العربية؟\n",
            "Réponse (extrait): اسم وفعل فقط....\n",
            "Note attendue: 2/5, Note prédite: 1/5\n",
            "Résultat: ✗\n",
            "--------------------------------------------------\n",
            "Exemple 10:\n",
            "Question: ما هي المفاعيل الخمسة في اللغة العربية؟\n",
            "Réponse (extrait): المفاعيل الخمسة في اللغة العربية هي: المفعول به، والمفعول المطلق، والمفعول فيه (ظرف الزمان وظرف المك...\n",
            "Note attendue: 5/5, Note prédite: 5/5\n",
            "Résultat: ✓\n",
            "--------------------------------------------------\n",
            "Exemple 11:\n",
            "Question: ما هي المفاعيل الخمسة في اللغة العربية؟\n",
            "Réponse (extrait): المفاعيل الخمسة هي: المفعول به، والمفعول المطلق، والمفعول فيه، والمفعول لأجله، والمفعول معه....\n",
            "Note attendue: 3/5, Note prédite: 3/5\n",
            "Résultat: ✓\n",
            "--------------------------------------------------\n",
            "Résultats finaux sur 11 exemples:\n",
            "Précision: 0.3636\n",
            "MAE: 0.6364\n",
            "\n",
            "Sauvegarde du modèle et des résultats...\n",
            "Modèle et résultats sauvegardés avec succès!\n",
            "Meilleure précision obtenue avec AraT5: 0.6639\n",
            "\n",
            "Exemples d'utilisation du modèle pour noter de nouvelles réponses:\n",
            "\n",
            "Exemple 1 - Réponse complète et précise:\n",
            "Question: ما هي أركان الإسلام الخمسة؟\n",
            "Réponse: أركان الإسلام خمسة: شهادة أن لا إله إلا الله وأن محمدًا رسول الله، وإقام الصلاة، وإيتاء الزكاة، وصوم...\n",
            "Note attribuée: 4/5 (confiance: 0.55)\n",
            "Explication: Cette réponse est bonne. Elle couvre la plupart des aspects importants du sujet avec une bonne précision.\n",
            "\n",
            "Exemple 2 - Réponse incomplète:\n",
            "Question: ما هي أركان الإسلام الخمسة؟\n",
            "Réponse: الصلاة والزكاة والصوم والحج.\n",
            "Note attribuée: 2/5 (confiance: 0.63)\n",
            "Explication: Cette réponse est insuffisante. Elle contient quelques éléments corrects mais manque de profondeur ou de précision.\n",
            "\n",
            "Exemple 3 - Réponse incorrecte:\n",
            "Question: ما هي أركان الإسلام الخمسة؟\n",
            "Réponse: لا أعرف بالضبط.\n",
            "Note attribuée: 1/5 (confiance: 0.85)\n",
            "Explication: Cette réponse est très insuffisante. Elle manque de contenu pertinent ou contient des erreurs graves.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import cohen_kappa_score, confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# 1. Préparation des données pour AraT5\n",
        "# -------------------------------------\n",
        "\n",
        "class AraT5NotationDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset pour le fine-tuning du modèle AraT5 pour la notation automatique\n",
        "    \"\"\"\n",
        "    def __init__(self, questions, reponses, notes, tokenizer, max_length=512):\n",
        "        self.questions = questions\n",
        "        self.reponses = reponses\n",
        "        self.notes = notes\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Pour T5, nous utilisons un format \"question: {question} réponse: {réponse}\"\n",
        "        input_text = f\"سؤال: {self.questions[idx]} إجابة: {self.reponses[idx]}\"\n",
        "\n",
        "        # Pour T5, la cible est la note en texte (convertie de 0-4 à 1-5)\n",
        "        target_text = str(self.notes[idx] + 1)  # Convertir en texte\n",
        "\n",
        "        input_encodings = self.tokenizer(\n",
        "            input_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        target_encodings = self.tokenizer(\n",
        "            target_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=10,  # Court pour la note\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Supprimer la dimension batch ajoutée par le tokenizer\n",
        "        input_ids = input_encodings.input_ids.squeeze()\n",
        "        attention_mask = input_encodings.attention_mask.squeeze()\n",
        "        labels = target_encodings.input_ids.squeeze()\n",
        "\n",
        "        # Remplacer les padding tokens dans les labels par -100 pour ignorer la loss\n",
        "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': labels\n",
        "        }\n",
        "\n",
        "# 2. Création des données d'entraînement avec des thèmes islamiques et arabes\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def creer_donnees_islamique_arabe(nb_exemples=2000):\n",
        "    \"\"\"\n",
        "    Crée des données d'entraînement avec des thèmes islamiques et arabes\n",
        "\n",
        "    Args:\n",
        "        nb_exemples (int): Nombre d'exemples à générer\n",
        "\n",
        "    Returns:\n",
        "        tuple: (questions, reponses, notes) où notes sont des valeurs entières de 0 à 4\n",
        "    \"\"\"\n",
        "    # Thèmes islamiques\n",
        "    themes_islamiques = [\n",
        "        \"أركان الإسلام\",  # Piliers de l'Islam\n",
        "        \"أركان الإيمان\",  # Piliers de la foi\n",
        "        \"الزكاة\",       # Zakat\n",
        "        \"الصيام\",       # Jeûne\n",
        "        \"الحج\",         # Pèlerinage\n",
        "        \"الصلاة\",       # Prière\n",
        "        \"القرآن\",       # Coran\n",
        "        \"السيرة النبوية\",  # Biographie du Prophète\n",
        "        \"الأخلاق الإسلامية\",  # Morale islamique\n",
        "        \"المعاملات الإسلامية\"  # Transactions islamiques\n",
        "    ]\n",
        "\n",
        "    # Thèmes arabes\n",
        "    themes_arabes = [\n",
        "        \"النحو العربي\",    # Grammaire arabe\n",
        "        \"البلاغة العربية\",  # Rhétorique arabe\n",
        "        \"الأدب العربي\",    # Littérature arabe\n",
        "        \"الشعر العربي\",    # Poésie arabe\n",
        "        \"الخط العربي\",     # Calligraphie arabe\n",
        "        \"اللهجات العربية\",  # Dialectes arabes\n",
        "        \"الترجمة\",        # Traduction\n",
        "        \"تاريخ اللغة العربية\"  # Histoire de la langue arabe\n",
        "    ]\n",
        "\n",
        "    # Combinaison des thèmes\n",
        "    tous_themes = themes_islamiques + themes_arabes\n",
        "\n",
        "    # Questions par thème\n",
        "    questions_par_theme = {\n",
        "        # Piliers de l'Islam\n",
        "        \"أركان الإسلام\": [\n",
        "            \"ما هي أركان الإسلام الخمسة؟\",\n",
        "            \"اشرح أهمية الشهادتين في الإسلام.\",\n",
        "            \"ما هو الركن الثالث من أركان الإسلام وما أهميته؟\",\n",
        "            \"كيف يؤثر الحج على حياة المسلم؟\",\n",
        "            \"ما هي شروط الصلاة وما أهميتها للمسلم؟\"\n",
        "        ],\n",
        "\n",
        "        # Piliers de la foi\n",
        "        \"أركان الإيمان\": [\n",
        "            \"اذكر أركان الإيمان الستة.\",\n",
        "            \"اشرح معنى الإيمان بالقضاء والقدر.\",\n",
        "            \"ما المقصود بالإيمان بالملائكة؟\",\n",
        "            \"كيف يؤثر الإيمان باليوم الآخر على سلوك المسلم؟\",\n",
        "            \"ما هي الكتب السماوية التي يؤمن بها المسلم؟\"\n",
        "        ],\n",
        "\n",
        "        # Zakat\n",
        "        \"الزكاة\": [\n",
        "            \"ما هو مفهوم الزكاة وما حكمها في الإسلام؟\",\n",
        "            \"ما هي شروط وجوب الزكاة؟\",\n",
        "            \"اذكر مصارف الزكاة الثمانية.\",\n",
        "            \"ما هو النصاب في الزكاة وكيف يُحسب؟\",\n",
        "            \"ما هي زكاة الفطر وما حكمها؟\"\n",
        "        ],\n",
        "\n",
        "        # Jeûne\n",
        "        \"الصيام\": [\n",
        "            \"ما هو الصيام ومتى فُرض على المسلمين؟\",\n",
        "            \"ما هي فوائد الصيام الروحية والصحية؟\",\n",
        "            \"اذكر مفسدات الصيام.\",\n",
        "            \"من هم الأشخاص المعفيون من الصيام؟\",\n",
        "            \"ما الفرق بين صيام الفرض وصيام النافلة؟\"\n",
        "        ],\n",
        "\n",
        "        # Pèlerinage\n",
        "        \"الحج\": [\n",
        "            \"ما هي أركان الحج؟\",\n",
        "            \"اشرح الفرق بين الحج والعمرة.\",\n",
        "            \"ما هي شروط وجوب الحج؟\",\n",
        "            \"اشرح مناسك الحج بالترتيب.\",\n",
        "            \"ما هي أنواع النسك في الحج؟\"\n",
        "        ],\n",
        "\n",
        "        # Prière\n",
        "        \"الصلاة\": [\n",
        "            \"ما هي الصلوات الخمس المفروضة وأوقاتها؟\",\n",
        "            \"اشرح أركان الصلاة.\",\n",
        "            \"ما هي سنن الصلاة؟\",\n",
        "            \"ما هي مبطلات الصلاة؟\",\n",
        "            \"كيف تؤدى صلاة الجماعة؟\"\n",
        "        ],\n",
        "\n",
        "        # Coran\n",
        "        \"القرآن\": [\n",
        "            \"كم عدد سور القرآن الكريم؟\",\n",
        "            \"ما هي أسباب النزول؟\",\n",
        "            \"اشرح مفهوم الإعجاز في القرآن الكريم.\",\n",
        "            \"ما الفرق بين السور المكية والسور المدنية؟\",\n",
        "            \"اذكر أسماء بعض كتب التفسير المشهورة.\"\n",
        "        ],\n",
        "\n",
        "        # Grammaire arabe\n",
        "        \"النحو العربي\": [\n",
        "            \"ما هي أقسام الكلام في اللغة العربية؟\",\n",
        "            \"اشرح أنواع المعرب والمبني.\",\n",
        "            \"ما هي علامات الإعراب الأصلية والفرعية؟\",\n",
        "            \"اشرح الفرق بين الجملة الاسمية والجملة الفعلية.\",\n",
        "            \"ما هي المنصوبات في اللغة العربية؟\"\n",
        "        ],\n",
        "\n",
        "        # Rhétorique arabe\n",
        "        \"البلاغة العربية\": [\n",
        "            \"ما هي أقسام البلاغة العربية؟\",\n",
        "            \"اشرح مفهوم التشبيه وأركانه وأنواعه.\",\n",
        "            \"ما هو السجع وما أنواعه؟\",\n",
        "            \"اشرح الفرق بين الاستعارة والكناية.\",\n",
        "            \"ما هو علم المعاني وما أبرز موضوعاته؟\"\n",
        "        ],\n",
        "\n",
        "        # Littérature arabe\n",
        "        \"الأدب العربي\": [\n",
        "            \"ما هي العصور الأدبية في الأدب العربي؟\",\n",
        "            \"اذكر أشهر شعراء العصر الجاهلي.\",\n",
        "            \"ما المقصود بالأدب المهجري؟\",\n",
        "            \"اشرح تطور القصة القصيرة في الأدب العربي الحديث.\",\n",
        "            \"من هم رواد الرواية العربية؟\"\n",
        "        ],\n",
        "\n",
        "        # Poésie arabe\n",
        "        \"الشعر العربي\": [\n",
        "            \"ما هي بحور الشعر العربي؟\",\n",
        "            \"اشرح بنية القصيدة العربية التقليدية.\",\n",
        "            \"ما المقصود بشعر التفعيلة؟\",\n",
        "            \"اذكر المعلقات السبع وأصحابها.\",\n",
        "            \"ما أبرز خصائص الشعر العباسي؟\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Modèles de réponses pour différents niveaux de qualité (0-4)\n",
        "    modeles_reponses = {\n",
        "        # Très mauvaise réponse (note 0)\n",
        "        0: [\n",
        "            \"لا أعرف.\",\n",
        "            \"ليس لدي إجابة.\",\n",
        "            \"{جملة قصيرة غير مرتبطة بالموضوع}\",\n",
        "            \"{إجابة خاطئة تمامًا}\",\n",
        "            \"{كلام غير مفهوم}\"\n",
        "        ],\n",
        "\n",
        "        # Mauvaise réponse (note 1)\n",
        "        1: [\n",
        "            \"{معلومة واحدة صحيحة مع أخطاء كثيرة}\",\n",
        "            \"{إجابة قصيرة جدًا وناقصة}\",\n",
        "            \"{معلومات عامة دون تفاصيل}\",\n",
        "            \"{خلط بين المفاهيم المختلفة}\",\n",
        "            \"{إجابة مبهمة وغير دقيقة}\"\n",
        "        ],\n",
        "\n",
        "        # Réponse moyenne (note 2)\n",
        "        2: [\n",
        "            \"{بعض المعلومات الصحيحة مع بعض الأخطاء}\",\n",
        "            \"{إجابة مختصرة تغطي جزءًا من الموضوع}\",\n",
        "            \"{شرح أساسي دون تعمق}\",\n",
        "            \"{استخدام محدود للمصطلحات التخصصية}\",\n",
        "            \"{إجابة متوسطة الجودة دون أمثلة توضيحية}\"\n",
        "        ],\n",
        "\n",
        "        # Bonne réponse (note 3)\n",
        "        3: [\n",
        "            \"{إجابة شاملة مع تفاصيل جيدة}\",\n",
        "            \"{شرح واضح مع بعض الأمثلة}\",\n",
        "            \"{استخدام صحيح للمصطلحات التخصصية}\",\n",
        "            \"{إجابة منظمة تغطي معظم جوانب الموضوع}\",\n",
        "            \"{تحليل جيد مع بعض الاستشهادات}\"\n",
        "        ],\n",
        "\n",
        "        # Excellente réponse (note 4)\n",
        "        4: [\n",
        "            \"{إجابة شاملة ومفصلة تغطي جميع جوانب الموضوع}\",\n",
        "            \"{شرح ممتاز مع أمثلة توضيحية متعددة}\",\n",
        "            \"{استخدام دقيق للمصطلحات التخصصية مع شرحها}\",\n",
        "            \"{إجابة منظمة بشكل ممتاز مع مقدمة وخاتمة}\",\n",
        "            \"{تحليل عميق مع استشهادات من مصادر موثوقة}\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Exemples spécifiques de réponses par qualité et par thème\n",
        "    exemples_reponses = {\n",
        "        # Piliers de l'Islam\n",
        "        \"أركان الإسلام\": {\n",
        "            0: [\"الإسلام له ثلاثة أركان.\", \"الصلاة فقط.\"],\n",
        "            1: [\"الصلاة والصيام والحج.\", \"الشهادة والصلاة.\"],\n",
        "            2: [\"أركان الإسلام خمسة: الشهادة، الصلاة، الزكاة، الصيام، والحج.\", \"الإسلام يقوم على خمسة أركان تبدأ بالشهادتين.\"],\n",
        "            3: [\"أركان الإسلام خمسة: شهادة أن لا إله إلا الله وأن محمدًا رسول الله، وإقام الصلاة، وإيتاء الزكاة، وصوم رمضان، وحج البيت لمن استطاع إليه سبيلا. هذه الأركان هي أساس الإسلام.\", \"الأركان الخمسة للإسلام هي الشهادتين والصلاة والزكاة والصيام والحج. وتعتبر هذه الأركان الأساس الذي يقوم عليه الإسلام وتميزه.\"],\n",
        "            4: [\"أركان الإسلام خمسة كما ثبت في حديث النبي صلى الله عليه وسلم: شهادة أن لا إله إلا الله وأن محمداً رسول الله، وهي أساس العقيدة وشرط لصحة الأعمال. وإقام الصلاة، التي هي عمود الدين وتجب خمس مرات في اليوم والليلة. وإيتاء الزكاة، وهي حق المال وطهارة للنفس والمجتمع. وصوم رمضان، الذي هو شهر العبادة والتقوى. وحج البيت لمن استطاع إليه سبيلا، وهو فرض مرة واحدة في العمر لمن توفرت فيه الشروط.\",\n",
        "             \"الأركان الخمسة للإسلام تمثل الأسس التي يقوم عليها الدين، وتبدأ بالشهادتين التي تمثل الإقرار بالتوحيد والرسالة، ثم الصلاة التي هي صلة العبد بربه وتتكرر خمس مرات يوميًا، ثم الزكاة التي تحقق التكافل الاجتماعي وتطهر المال، ثم صيام شهر رمضان الذي يعزز التقوى والصبر، وأخيرًا الحج إلى بيت الله الحرام لمن استطاع إليه سبيلا وهو يجمع معظم العبادات. وقد ذكرت هذه الأركان في حديث النبي محمد صلى الله عليه وسلم: 'بني الإسلام على خمس...'.\"]\n",
        "        },\n",
        "\n",
        "        # Grammaire arabe\n",
        "        \"النحو العربي\": {\n",
        "            0: [\"النحو هو قواعد اللغة الإنجليزية.\", \"لا أعرف ما هو النحو.\"],\n",
        "            1: [\"النحو هو كيفية كتابة الكلمات.\", \"النحو هو رفع الفاعل.\"],\n",
        "            2: [\"النحو العربي هو علم يبحث في أحوال أواخر الكلم إعرابًا وبناءً. من أقسامه المرفوعات والمنصوبات.\", \"النحو يشمل الإعراب والبناء والفاعل والمفعول به.\"],\n",
        "            3: [\"النحو العربي هو علم يبحث في أحوال أواخر الكلم إعرابًا وبناءً. يشمل أقسام الكلام من اسم وفعل وحرف، والإعراب والبناء، والمرفوعات كالفاعل والمبتدأ، والمنصوبات كالمفعول به، والمجرورات كالمضاف إليه.\", \"النحو هو علم يدرس تركيب الجملة العربية وكيفية إعراب كلماتها. ينقسم الكلام إلى ثلاثة أقسام: اسم وفعل وحرف. وينقسم الإعراب إلى رفع ونصب وجر وجزم. من المرفوعات: الفاعل والمبتدأ والخبر. ومن المنصوبات: المفعول به والحال والتمييز.\"],\n",
        "            4: [\"النحو العربي هو علم يبحث في أحوال أواخر الكلم إعرابًا وبناءً، وقد وضع أسسه أبو الأسود الدؤلي بتوجيه من الإمام علي رضي الله عنه. ينقسم الكلام في اللغة العربية إلى ثلاثة أقسام: الاسم وعلامته قبول الجر والتنوين وأل، والفعل وينقسم إلى ماضٍ ومضارع وأمر، والحرف وهو ما لا يقبل علامات الاسم ولا الفعل. أما الإعراب فينقسم إلى: الرفع وعلامته الأصلية الضمة، والنصب وعلامته الأصلية الفتحة، والجر وعلامته الأصلية الكسرة، والجزم وعلامته الأصلية السكون. ومن المرفوعات: الفاعل والمبتدأ والخبر. ومن المنصوبات: المفعول به والحال والتمييز. ومن المجرورات: المضاف إليه والمجرور بحرف الجر.\", \"النحو العربي هو علم أساسي من علوم اللغة العربية، يُعنى بدراسة أحوال أواخر الكلم إعرابًا وبناءً. وضع أسسه أبو الأسود الدؤلي بتوجيه من الإمام علي، ثم تطور على يد الخليل بن أحمد الفراهيدي وسيبويه. ينقسم الكلام في العربية إلى: اسم (مثل: محمد، كتاب)، وفعل (مثل: كتب، يكتب، اكتب)، وحرف (مثل: في، على، من). والإعراب أربعة أنواع: رفع (علامته الضمة ☉ُ)، ونصب (علامته الفتحة ☉َ)، وجر (علامته الكسرة ☉ِ)، وجزم (علامته السكون ☉ْ). وتنقسم الكلمات بحسب إعرابها إلى مرفوعات مثل المبتدأ والخبر والفاعل، ومنصوبات مثل المفعول به والحال، ومجرورات مثل المضاف إليه.\"],\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Fonction pour générer une réponse selon la question et la qualité\n",
        "    def generer_reponse(theme, question, qualite):\n",
        "        # Vérifier si nous avons des exemples spécifiques pour ce thème\n",
        "        if theme in exemples_reponses and qualite in exemples_reponses[theme]:\n",
        "            return random.choice(exemples_reponses[theme][qualite])\n",
        "\n",
        "        # Si non, générer une réponse basée sur les modèles\n",
        "        if qualite == 0:\n",
        "            return random.choice(modeles_reponses[0])\n",
        "        elif qualite == 1:\n",
        "            if \"ما هي\" in question or \"اذكر\" in question:\n",
        "                return question.replace(\"ما هي\", \"هي\").replace(\"اذكر\", \"\") + \" \" + random.choice([\"وهذا كل ما أعرفه.\", \"فقط.\"])\n",
        "            else:\n",
        "                return random.choice(modeles_reponses[1])\n",
        "        elif qualite == 2:\n",
        "            if theme in [\"أركان الإسلام\", \"أركان الإيمان\", \"القرآن\"]:\n",
        "                return \"في الإسلام، \" + question.replace(\"ما هي\", \"\").replace(\"اشرح\", \"\").replace(\"؟\", \"\") + \" مهمة للمسلمين ويجب الالتزام بها.\"\n",
        "            elif theme in [\"النحو العربي\", \"البلاغة العربية\", \"الأدب العربي\"]:\n",
        "                return \"في اللغة العربية، \" + question.replace(\"ما هي\", \"\").replace(\"اشرح\", \"\").replace(\"؟\", \"\") + \" لها قواعد وأسس معينة تدرس في علوم اللغة.\"\n",
        "            else:\n",
        "                return random.choice(modeles_reponses[2])\n",
        "        elif qualite == 3:\n",
        "            # Réponses de qualité 3 génériques par thème\n",
        "            reponses_theme = {\n",
        "                \"أركان الإسلام\": \"أركان الإسلام خمسة وهي: الشهادتان، وإقام الصلاة، وإيتاء الزكاة، وصوم رمضان، وحج البيت لمن استطاع إليه سبيلا. هذه الأركان أساسية لكل مسلم ويجب الالتزام بها.\",\n",
        "                \"أركان الإيمان\": \"أركان الإيمان ستة وهي: الإيمان بالله، وملائكته، وكتبه، ورسله، واليوم الآخر، والقدر خيره وشره. ويعتبر الإيمان بها جميعًا ضروريًا للمسلم.\",\n",
        "                \"الزكاة\": \"الزكاة هي الركن الثالث من أركان الإسلام، وهي واجبة على كل مسلم يملك نصابًا وحال عليه الحول. نسبتها 2.5% من المال، ولها ثمانية مصارف ذكرت في القرآن الكريم.\",\n",
        "                \"الصيام\": \"الصيام هو الامتناع عن المفطرات من طلوع الفجر إلى غروب الشمس بنية التقرب إلى الله. ويجب صيام شهر رمضان على كل مسلم بالغ عاقل قادر.\",\n",
        "                \"النحو العربي\": \"النحو العربي هو علم يدرس أحوال أواخر الكلمات من حيث الإعراب والبناء. ينقسم الكلام إلى اسم وفعل وحرف، والإعراب إلى رفع ونصب وجر وجزم. من أهم كتبه: كتاب سيبويه وألفية ابن مالك.\"\n",
        "            }\n",
        "\n",
        "            if theme in reponses_theme:\n",
        "                return reponses_theme[theme]\n",
        "            else:\n",
        "                return random.choice(modeles_reponses[3])\n",
        "        else:  # qualite == 4\n",
        "            # Réponses excellentes génériques par thème\n",
        "            reponses_excellentes = {\n",
        "                \"أركان الإسلام\": \"أركان الإسلام خمسة كما وردت في حديث النبي صلى الله عليه وسلم: شهادة أن لا إله إلا الله وأن محمدًا رسول الله، وهي أساس الدين وبوابة الدخول إلى الإسلام. وإقام الصلاة، وهي عمود الدين وتقام خمس مرات في اليوم والليلة كصلة بين العبد وربه. وإيتاء الزكاة، وهي حق المال وتطهير له وتكافل بين أفراد المجتمع المسلم. وصوم رمضان، وهو امتناع عن المفطرات من طلوع الفجر إلى غروب الشمس طوال شهر رمضان تقربًا إلى الله وتعويدًا للنفس على الصبر. وحج البيت لمن استطاع إليه سبيلا، وهو زيارة البيت الحرام في مكة المكرمة لأداء مناسك معينة في أوقات محددة مرة واحدة في العمر لمن توفرت فيه شروط الاستطاعة.\",\n",
        "                \"النحو العربي\": \"النحو العربي هو علم يبحث في أحوال أواخر الكلم إعرابًا وبناءً، ويعد من أهم علوم اللغة العربية. نشأ في القرن الأول الهجري على يد أبي الأسود الدؤلي بتوجيه من الإمام علي رضي الله عنه للحفاظ على اللغة العربية من اللحن. ينقسم الكلام في اللغة العربية إلى ثلاثة أقسام: الاسم وعلامته قبول الجر والتنوين وأل (مثل: كتاب، مدرسة)، والفعل وينقسم إلى ماضٍ ومضارع وأمر (مثل: كَتَبَ، يَكْتُبُ، اُكْتُبْ)، والحرف وهو ما لا يقبل علامات الاسم ولا الفعل (مثل: في، على، لم). أما الإعراب فينقسم إلى: الرفع وعلامته الأصلية الضمة، والنصب وعلامته الأصلية الفتحة، والجر وعلامته الأصلية الكسرة، والجزم وعلامته الأصلية السكون. ومن أشهر مؤلفات النحو: كتاب سيبويه، وألفية ابن مالك، ومغني اللبيب لابن هشام.\"\n",
        "            }\n",
        "\n",
        "            if theme in reponses_excellentes:\n",
        "                return reponses_excellentes[theme]\n",
        "            else:\n",
        "                return random.choice(modeles_reponses[4])\n",
        "\n",
        "    # Générer les exemples\n",
        "    questions = []\n",
        "    reponses = []\n",
        "    notes = []\n",
        "\n",
        "    # S'assurer d'une répartition équilibrée des notes\n",
        "    notes_a_generer = {0: nb_exemples//5, 1: nb_exemples//5, 2: nb_exemples//5, 3: nb_exemples//5, 4: nb_exemples//5}\n",
        "\n",
        "    # Ajuster pour s'assurer que le total est correct\n",
        "    total = sum(notes_a_generer.values())\n",
        "    if total < nb_exemples:\n",
        "        notes_a_generer[4] += nb_exemples - total\n",
        "\n",
        "    # Générer les exemples pour chaque qualité de réponse\n",
        "    for qualite in range(5):\n",
        "        for _ in range(notes_a_generer[qualite]):\n",
        "            # Sélectionner un thème aléatoire\n",
        "            theme = random.choice(tous_themes)\n",
        "\n",
        "            # S'assurer que le thème a des questions définies\n",
        "            while theme not in questions_par_theme:\n",
        "                theme = random.choice(tous_themes)\n",
        "\n",
        "            # Sélectionner une question aléatoire pour ce thème\n",
        "            question = random.choice(questions_par_theme[theme])\n",
        "\n",
        "            # Générer la réponse correspondant à la qualité\n",
        "            reponse = generer_reponse(theme, question, qualite)\n",
        "\n",
        "            questions.append(question)\n",
        "            reponses.append(reponse)\n",
        "            notes.append(qualite)\n",
        "\n",
        "    # Mélanger les données pour éviter les biais d'ordre\n",
        "    donnees_combinees = list(zip(questions, reponses, notes))\n",
        "    random.shuffle(donnees_combinees)\n",
        "    questions, reponses, notes = zip(*donnees_combinees)\n",
        "\n",
        "    # Convertir en listes\n",
        "    questions = list(questions)\n",
        "    reponses = list(reponses)\n",
        "    notes = list(notes)\n",
        "\n",
        "    return questions, reponses, notes\n",
        "\n",
        "# 3. Augmentation des données\n",
        "# --------------------------\n",
        "\n",
        "def augmenter_donnees_ameliore(questions, reponses, notes):\n",
        "    \"\"\"\n",
        "    Version améliorée de l'augmentation de données avec plus de techniques\n",
        "\n",
        "    Args:\n",
        "        questions (list): Liste des questions originales\n",
        "        reponses (list): Liste des réponses originales\n",
        "        notes (list): Liste des notes originales (0-4)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (questions_augmentees, reponses_augmentees, notes_augmentees)\n",
        "    \"\"\"\n",
        "    questions_augmentees = questions.copy()\n",
        "    reponses_augmentees = reponses.copy()\n",
        "    notes_augmentees = notes.copy()\n",
        "\n",
        "    # Facteur d'augmentation: ajouter 100% plus d'exemples\n",
        "    nb_exemples_originaux = len(questions)\n",
        "    nb_exemples_a_ajouter = nb_exemples_originaux\n",
        "\n",
        "    # 1. Variantes de formulation pour les questions\n",
        "    prefixes_questions = [\n",
        "        \"هل يمكنك شرح \",\n",
        "        \"أريد معرفة \",\n",
        "        \"اشرح بالتفصيل \",\n",
        "        \"تحدث عن \",\n",
        "        \"ما رأيك في \",\n",
        "        \"ما معنى \",\n",
        "        \"كيف تفسر \",\n",
        "        \"وضح لي \",\n",
        "        \"ما المقصود بـ \"\n",
        "    ]\n",
        "\n",
        "    suffixes_questions = [\n",
        "        \" بشكل مفصل؟\",\n",
        "        \" باختصار؟\",\n",
        "        \" مع ذكر الأمثلة؟\",\n",
        "        \" من وجهة نظر إسلامية؟\",\n",
        "        \" في ضوء المصادر المعتمدة؟\",\n",
        "        \" مع ذكر الدليل؟\",\n",
        "        \" بأسلوبك الخاص؟\",\n",
        "        \" ولماذا؟\",\n",
        "        \" وما أهميته؟\"\n",
        "    ]\n",
        "\n",
        "    # 2. Substitution de mots pour les réponses (synonymes simples)\n",
        "    substitutions_mots = {\n",
        "        \"مهم\": [\"ضروري\", \"أساسي\", \"جوهري\"],\n",
        "        \"كبير\": [\"عظيم\", \"ضخم\", \"واسع\"],\n",
        "        \"جيد\": [\"ممتاز\", \"رائع\", \"جميل\"],\n",
        "        \"قال\": [\"ذكر\", \"أفاد\", \"أوضح\"],\n",
        "        \"يجب\": [\"ينبغي\", \"لا بد\", \"من الضروري\"],\n",
        "        \"كثير\": [\"عديد\", \"وفير\", \"غزير\"],\n",
        "        \"مفهوم\": [\"معنى\", \"تعريف\", \"مصطلح\"]\n",
        "    }\n",
        "\n",
        "    # 3. Techniques d'augmentation\n",
        "    techniques = [\n",
        "        \"reformuler_question\",  # Reformuler la question\n",
        "        \"modifier_reponse\",     # Modifier légèrement la réponse\n",
        "        \"combiner_exemples\"     # Combiner des exemples de même niveau\n",
        "    ]\n",
        "\n",
        "    # Fonction pour appliquer des substitutions aléatoires\n",
        "    def appliquer_substitutions(texte):\n",
        "        mots = texte.split()\n",
        "        for i, mot in enumerate(mots):\n",
        "            # Suppression des signes de ponctuation pour la correspondance\n",
        "            mot_clean = mot.strip(\"،.؟!:;\")\n",
        "            if mot_clean in substitutions_mots and random.random() < 0.3:  # 30% de chance\n",
        "                mots[i] = mot.replace(mot_clean, random.choice(substitutions_mots[mot_clean]))\n",
        "        return \" \".join(mots)\n",
        "\n",
        "    # Fonction pour combiner deux réponses de même niveau\n",
        "    def combiner_reponses(reponse1, reponse2):\n",
        "        # Prendre la première moitié de la première réponse\n",
        "        moitie1 = reponse1.split()\n",
        "        point_milieu1 = len(moitie1) // 2\n",
        "\n",
        "        # Et la deuxième moitié de la deuxième réponse\n",
        "        moitie2 = reponse2.split()\n",
        "        point_milieu2 = len(moitie2) // 2\n",
        "\n",
        "        # Combiner les deux moitiés avec une phrase de transition\n",
        "        phrases_transition = [\n",
        "            \" وبالإضافة إلى ذلك، \",\n",
        "            \" وعلاوة على ذلك، \",\n",
        "            \" ومن جهة أخرى، \",\n",
        "            \" وكذلك، \",\n",
        "            \" وأيضاً، \"\n",
        "        ]\n",
        "\n",
        "        combinaison = \" \".join(moitie1[:point_milieu1]) + random.choice(phrases_transition) + \" \".join(moitie2[point_milieu2:])\n",
        "        return combinaison\n",
        "\n",
        "    # Pour chaque exemple à ajouter\n",
        "    indices_utilises = set()\n",
        "    for i in range(nb_exemples_a_ajouter):\n",
        "        # Sélectionner une technique aléatoire\n",
        "        technique = random.choice(techniques)\n",
        "\n",
        "        if technique == \"reformuler_question\":\n",
        "            # Sélectionner un exemple aléatoire\n",
        "            idx = random.randint(0, nb_exemples_originaux - 1)\n",
        "            question_orig = questions[idx]\n",
        "\n",
        "            # Reformuler la question\n",
        "            if random.random() < 0.5:  # 50% du temps ajouter un préfixe\n",
        "                nouvelle_question = random.choice(prefixes_questions) + question_orig.replace(\"ما هي \", \"\").replace(\"اشرح \", \"\").replace(\"؟\", \"\")\n",
        "            else:  # 50% du temps ajouter un suffixe\n",
        "                nouvelle_question = question_orig.replace(\"؟\", \"\") + random.choice(suffixes_questions)\n",
        "\n",
        "            # Ajouter l'exemple augmenté\n",
        "            questions_augmentees.append(nouvelle_question)\n",
        "            reponses_augmentees.append(reponses[idx])\n",
        "            notes_augmentees.append(notes[idx])\n",
        "            indices_utilises.add(idx)\n",
        "\n",
        "        elif technique == \"modifier_reponse\":\n",
        "            # Sélectionner un exemple aléatoire non utilisé si possible\n",
        "            candidats = [j for j in range(nb_exemples_originaux) if j not in indices_utilises]\n",
        "            if not candidats:  # Si tous ont été utilisés, prendre n'importe lequel\n",
        "                candidats = list(range(nb_exemples_originaux))\n",
        "\n",
        "            idx = random.choice(candidats)\n",
        "\n",
        "            # Appliquer des substitutions à la réponse\n",
        "            nouvelle_reponse = appliquer_substitutions(reponses[idx])\n",
        "\n",
        "            # Ajouter l'exemple augmenté\n",
        "            questions_augmentees.append(questions[idx])\n",
        "            reponses_augmentees.append(nouvelle_reponse)\n",
        "            notes_augmentees.append(notes[idx])\n",
        "            indices_utilises.add(idx)\n",
        "\n",
        "        elif technique == \"combiner_exemples\":\n",
        "            # Trouver des paires d'exemples avec la même note\n",
        "            exemples_par_note = {}\n",
        "            for j in range(nb_exemples_originaux):\n",
        "                note = notes[j]\n",
        "                if note not in exemples_par_note:\n",
        "                    exemples_par_note[note] = []\n",
        "                exemples_par_note[note].append(j)\n",
        "\n",
        "            # Choisir une note qui a au moins deux exemples\n",
        "            notes_disponibles = [n for n in exemples_par_note if len(exemples_par_note[n]) >= 2]\n",
        "            if not notes_disponibles:\n",
        "                continue  # Passer à la prochaine itération si pas d'option viable\n",
        "\n",
        "            note_choisie = random.choice(notes_disponibles)\n",
        "\n",
        "            # Choisir deux exemples aléatoires avec cette note\n",
        "            idx1, idx2 = random.sample(exemples_par_note[note_choisie], 2)\n",
        "\n",
        "            # Combiner les réponses\n",
        "            reponse_combinee = combiner_reponses(reponses[idx1], reponses[idx2])\n",
        "\n",
        "            # Ajouter l'exemple augmenté (utiliser la question de idx1)\n",
        "            questions_augmentees.append(questions[idx1])\n",
        "            reponses_augmentees.append(reponse_combinee)\n",
        "            notes_augmentees.append(notes[idx1])\n",
        "            indices_utilises.add(idx1)\n",
        "            indices_utilises.add(idx2)\n",
        "\n",
        "    # Retourner les données augmentées\n",
        "    return questions_augmentees, reponses_augmentees, notes_augmentees\n",
        "\n",
        "# 4. Fonction pour adapter la sortie de T5 (conversion de texte en note numérique)\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def convert_t5_output_to_grade(prediction, tokenizer):\n",
        "    \"\"\"\n",
        "    Convertit la sortie du modèle T5 en note numérique\n",
        "\n",
        "    Args:\n",
        "        prediction: La prédiction brute du modèle\n",
        "        tokenizer: Le tokenizer utilisé\n",
        "\n",
        "    Returns:\n",
        "        int: La note prédite (1-5)\n",
        "    \"\"\"\n",
        "    decoded_prediction = tokenizer.decode(prediction, skip_special_tokens=True)\n",
        "\n",
        "    # Essayer de convertir en entier (note de 1 à 5)\n",
        "    try:\n",
        "        grade = int(decoded_prediction.strip())\n",
        "        # S'assurer que la note est bien dans l'intervalle 1-5\n",
        "        if grade < 1:\n",
        "            grade = 1\n",
        "        elif grade > 5:\n",
        "            grade = 5\n",
        "    except:\n",
        "        # Si la conversion échoue, attribuer la note moyenne\n",
        "        grade = 3\n",
        "\n",
        "    return grade\n",
        "\n",
        "# 5. Fonction d'évaluation détaillée pour AraT5\n",
        "# -------------------------------------------\n",
        "\n",
        "def evaluate_arat5(model, dataloader, tokenizer, device):\n",
        "    \"\"\"\n",
        "    Évalue le modèle AraT5 sur un jeu de données\n",
        "\n",
        "    Args:\n",
        "        model: Le modèle à évaluer\n",
        "        dataloader: Le chargeur de données\n",
        "        tokenizer: Le tokenizer utilisé\n",
        "        device: L'appareil de calcul (CPU/GPU)\n",
        "\n",
        "    Returns:\n",
        "        dict: Les métriques d'évaluation\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Générer les prédictions\n",
        "            predictions = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=10\n",
        "            )\n",
        "\n",
        "            # Convertir les prédictions et les labels en notes numériques\n",
        "            for pred, lab in zip(predictions, labels):\n",
        "                # Supprimer les valeurs -100 des labels et décoder\n",
        "                label_ids = lab.clone()\n",
        "                label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "                decoded_label = tokenizer.decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "                try:\n",
        "                    true_grade = int(decoded_label.strip())\n",
        "                    # Ajuster à l'intervalle 0-4 pour les métriques\n",
        "                    true_grade = max(1, min(true_grade, 5)) - 1\n",
        "                except:\n",
        "                    # Si la conversion échoue, ignorer cet exemple\n",
        "                    continue\n",
        "\n",
        "                pred_grade = convert_t5_output_to_grade(pred, tokenizer) - 1  # Ajuster à 0-4\n",
        "\n",
        "                all_preds.append(pred_grade)\n",
        "                all_labels.append(true_grade)\n",
        "\n",
        "    if len(all_preds) == 0:\n",
        "        return {\n",
        "            \"loss\": total_loss / len(dataloader) if len(dataloader) > 0 else 0,\n",
        "            \"accuracy\": 0,\n",
        "            \"kappa\": 0,\n",
        "            \"confusion_matrix\": np.zeros((5, 5)),\n",
        "            \"mae\": 0\n",
        "        }\n",
        "\n",
        "    # Calcul de l'exactitude\n",
        "    accuracy = sum(1 for p, l in zip(all_preds, all_labels) if p == l) / len(all_preds)\n",
        "\n",
        "    # Calcul du Kappa de Cohen\n",
        "    kappa = cohen_kappa_score(all_labels, all_preds)\n",
        "\n",
        "    # Matrice de confusion\n",
        "    conf_matrix = confusion_matrix(all_labels, all_preds, labels=range(5))\n",
        "\n",
        "    # Écart moyen absolu\n",
        "    mae = sum(abs(p - l) for p, l in zip(all_preds, all_labels)) / len(all_preds)\n",
        "\n",
        "    return {\n",
        "        \"loss\": total_loss / len(dataloader),\n",
        "        \"accuracy\": accuracy,\n",
        "        \"kappa\": kappa,\n",
        "        \"confusion_matrix\": conf_matrix,\n",
        "        \"mae\": mae\n",
        "    }\n",
        "\n",
        "# 6. Fonction principale pour l'entraînement du modèle AraT5\n",
        "# --------------------------------------------------------\n",
        "\n",
        "def entrainer_arat5_model(nb_exemples=3000, batch_size=4, num_epochs=15,\n",
        "                        learning_rate=3e-5, warmup_ratio=0.1,\n",
        "                        patience=5, max_length=256, gradient_accumulation_steps=4):\n",
        "    \"\"\"\n",
        "    Fonction améliorée pour entraîner le modèle AraT5 avec de meilleures performances\n",
        "\n",
        "    Args:\n",
        "        nb_exemples (int): Nombre d'exemples à générer pour l'entraînement\n",
        "        batch_size (int): Taille du batch pour le chargement des données\n",
        "        num_epochs (int): Nombre maximal d'époques d'entraînement\n",
        "        learning_rate (float): Taux d'apprentissage initial\n",
        "        warmup_ratio (float): Ratio d'échauffement du scheduler\n",
        "        patience (int): Nombre d'époques sans amélioration avant l'arrêt précoce\n",
        "        max_length (int): Longueur maximale des séquences\n",
        "        gradient_accumulation_steps (int): Nombre d'étapes pour l'accumulation de gradient\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, tokenizer, best_val_acc, history)\n",
        "    \"\"\"\n",
        "    print(\"Chargement du tokenizer et du modèle AraT5...\")\n",
        "    # Utiliser le modèle AraT5 pour la notation\n",
        "    model_name = \"UBC-NLP/AraT5-base\"\n",
        "    # Utiliser explicitement la version slow du tokenizer pour éviter les erreurs avec le tokenizer fast\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "    # 1. Création de données de meilleure qualité\n",
        "    print(f\"Création des données d'entraînement avec thèmes islamiques et arabes ({nb_exemples} exemples)...\")\n",
        "    questions, reponses, notes = creer_donnees_islamique_arabe(nb_exemples)\n",
        "\n",
        "    # 2. Augmentation des données plus diversifiée\n",
        "    print(\"Augmentation des données...\")\n",
        "    questions_aug, reponses_aug, notes_aug = augmenter_donnees_ameliore(questions, reponses, notes)\n",
        "\n",
        "    # 3. Division stratifiée des données avec validation croisée\n",
        "    print(\"Division des données en ensembles d'entraînement, validation et test...\")\n",
        "    # Réservation d'un ensemble de test (10%)\n",
        "    q_temp, q_test, r_temp, r_test, n_temp, n_test = train_test_split(\n",
        "        questions_aug, reponses_aug, notes_aug,\n",
        "        test_size=0.1, random_state=42, stratify=notes_aug\n",
        "    )\n",
        "\n",
        "    # Division entraînement/validation (80%/20% des données restantes)\n",
        "    q_train, q_val, r_train, r_val, n_train, n_val = train_test_split(\n",
        "        q_temp, r_temp, n_temp,\n",
        "        test_size=0.2, random_state=42, stratify=n_temp\n",
        "    )\n",
        "\n",
        "    print(f\"Répartition des notes dans l'ensemble d'entraînement:\")\n",
        "    for note in range(5):\n",
        "        count = n_train.count(note)\n",
        "        print(f\"Note {note+1}/5: {count} exemples ({count/len(n_train)*100:.1f}%)\")\n",
        "\n",
        "    # 4. Création des datasets\n",
        "    train_dataset = AraT5NotationDataset(q_train, r_train, n_train, tokenizer, max_length=max_length)\n",
        "    val_dataset = AraT5NotationDataset(q_val, r_val, n_val, tokenizer, max_length=max_length)\n",
        "    test_dataset = AraT5NotationDataset(q_test, r_test, n_test, tokenizer, max_length=max_length)\n",
        "\n",
        "    # 5. Création des dataloaders (utilisons num_workers=0 pour éviter d'éventuels problèmes multiprocessing)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=0)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=0)\n",
        "\n",
        "    # 6. Configuration de l'optimiseur avec un meilleur learning rate\n",
        "    # Utilisation du regroupement des paramètres pour un training efficace\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": 0.01,\n",
        "        },\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": 0.0,\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "\n",
        "    # 7. Configuration du scheduler avec warmup\n",
        "    total_steps = len(train_loader) * num_epochs // gradient_accumulation_steps\n",
        "    warmup_steps = int(total_steps * warmup_ratio)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=warmup_steps,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    # 8. Déplacer le modèle sur GPU si disponible\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Utilisation de l'appareil: {device}\")\n",
        "    model.to(device)\n",
        "\n",
        "    # 9. Entraînement avec early stopping et accumulation de gradient\n",
        "    best_val_acc = 0\n",
        "    patience_counter = 0\n",
        "    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": [], \"val_kappa\": [], \"val_mae\": []}\n",
        "\n",
        "    print(f\"Début de l'entraînement pour {num_epochs} époques maximum...\")\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Époque {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        # Phase d'entraînement\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=\"Training\")\n",
        "        optimizer.zero_grad()  # Réinitialiser les gradients au début de l'époque\n",
        "\n",
        "        for step, batch in enumerate(progress_bar):\n",
        "            # Déplacer les tenseurs vers le GPU\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "\n",
        "            loss = outputs.loss\n",
        "\n",
        "            # Normaliser la perte en fonction des étapes d'accumulation\n",
        "            loss = loss / gradient_accumulation_steps\n",
        "            loss.backward()\n",
        "\n",
        "            total_train_loss += loss.item() * gradient_accumulation_steps\n",
        "\n",
        "            # Mise à jour des paramètres après accumulation du gradient\n",
        "            if (step + 1) % gradient_accumulation_steps == 0:\n",
        "                # Clip gradient norm pour éviter l'explosion des gradients\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "                # Mise à jour des poids et du scheduler\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            # Mettre à jour la barre de progression\n",
        "            progress_bar.set_postfix({\n",
        "                'loss': total_train_loss / (progress_bar.n + 1),\n",
        "                'lr': scheduler.get_last_lr()[0]\n",
        "            })\n",
        "\n",
        "        # S'assurer que tous les gradients sont mis à jour même si le dernier batch est incomplet\n",
        "        if len(train_loader) % gradient_accumulation_steps != 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        history[\"train_loss\"].append(avg_train_loss)\n",
        "\n",
        "        print(f\"Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Phase d'évaluation\n",
        "        eval_results = evaluate_arat5(model, val_loader, tokenizer, device)\n",
        "        val_loss = eval_results[\"loss\"]\n",
        "        val_acc = eval_results[\"accuracy\"]\n",
        "        val_kappa = eval_results[\"kappa\"]\n",
        "        val_mae = eval_results[\"mae\"]\n",
        "\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        history[\"val_kappa\"].append(val_kappa)\n",
        "        history[\"val_mae\"].append(val_mae)\n",
        "\n",
        "        print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
        "        print(f\"Kappa: {val_kappa:.4f}, MAE: {val_mae:.4f}\")\n",
        "        print(\"Matrice de confusion:\")\n",
        "        print(eval_results[\"confusion_matrix\"])\n",
        "\n",
        "        # Sauvegarder le meilleur modèle (basé sur précision)\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            # Sauvegarder le modèle entier plutôt que juste les state_dict\n",
        "            model.save_pretrained(\"best_arat5_model\")\n",
        "            tokenizer.save_pretrained(\"best_arat5_model\")\n",
        "            print(f\"Meilleur modèle sauvegardé! Accuracy: {val_acc:.4f}\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping après {epoch+1} époques\")\n",
        "            break\n",
        "\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Charger le meilleur modèle pour l'évaluation finale\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"best_arat5_model\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Évaluation sur l'ensemble de test\n",
        "    print(\"Évaluation finale sur l'ensemble de test...\")\n",
        "    test_results = evaluate_arat5(model, test_loader, tokenizer, device)\n",
        "    print(f\"Test Loss: {test_results['loss']:.4f}, Test Accuracy: {test_results['accuracy']:.4f}\")\n",
        "    print(f\"Test Kappa: {test_results['kappa']:.4f}, Test MAE: {test_results['mae']:.4f}\")\n",
        "    print(\"Matrice de confusion finale:\")\n",
        "    print(test_results[\"confusion_matrix\"])\n",
        "\n",
        "    return model, tokenizer, best_val_acc, history\n",
        "\n",
        "# 7. Fonction pour tester le modèle sur des exemples réels\n",
        "# ------------------------------------------------------\n",
        "\n",
        "def tester_arat5_model(model, tokenizer, device):\n",
        "    \"\"\"\n",
        "    Teste le modèle AraT5 sur des exemples réels et variés\n",
        "    \"\"\"\n",
        "    # Définir des exemples de test islamiques\n",
        "    exemples_test_islamique = [\n",
        "        {\n",
        "            \"question\": \"ما هي أركان الإسلام الخمسة؟\",\n",
        "            \"reponse\": \"أركان الإسلام خمسة: شهادة أن لا إله إلا الله وأن محمدًا رسول الله، وإقام الصلاة، وإيتاء الزكاة، وصوم رمضان، وحج البيت لمن استطاع إليه سبيلا.\",\n",
        "            \"note_attendue\": 4\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي أركان الإسلام الخمسة؟\",\n",
        "            \"reponse\": \"الشهادتين والصلاة والزكاة والصيام والحج.\",\n",
        "            \"note_attendue\": 2\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي أركان الإسلام الخمسة؟\",\n",
        "            \"reponse\": \"الصلاة والصيام والحج.\",\n",
        "            \"note_attendue\": 1\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي أركان الإسلام الخمسة؟\",\n",
        "            \"reponse\": \"لا أعرف بالضبط.\",\n",
        "            \"note_attendue\": 0\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي شروط الصلاة؟\",\n",
        "            \"reponse\": \"شروط الصلاة هي: الإسلام، والعقل، والتمييز، ودخول الوقت، ورفع الحدث، وإزالة النجاسة، وستر العورة، واستقبال القبلة، والنية.\",\n",
        "            \"note_attendue\": 4\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي شروط الصلاة؟\",\n",
        "            \"reponse\": \"من شروط الصلاة الطهارة واستقبال القبلة وستر العورة.\",\n",
        "            \"note_attendue\": 2\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Définir des exemples de test de langue arabe\n",
        "    exemples_test_arabe = [\n",
        "        {\n",
        "            \"question\": \"ما هي أقسام الكلام في اللغة العربية؟\",\n",
        "            \"reponse\": \"تنقسم الكلمة في اللغة العربية إلى ثلاثة أقسام: اسم وفعل وحرف. الاسم هو ما دل على معنى في نفسه ولم يقترن بزمن مثل: كتاب، قلم، محمد. والفعل هو ما دل على معنى في نفسه واقترن بزمن مثل: كتب، يكتب، اكتب. والحرف هو ما دل على معنى في غيره مثل: في، على، من.\",\n",
        "            \"note_attendue\": 4\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي أقسام الكلام في اللغة العربية؟\",\n",
        "            \"reponse\": \"أقسام الكلام في اللغة العربية هي: اسم وفعل وحرف.\",\n",
        "            \"note_attendue\": 2\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي أقسام الكلام في اللغة العربية؟\",\n",
        "            \"reponse\": \"اسم وفعل فقط.\",\n",
        "            \"note_attendue\": 1\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي المفاعيل الخمسة في اللغة العربية؟\",\n",
        "            \"reponse\": \"المفاعيل الخمسة في اللغة العربية هي: المفعول به، والمفعول المطلق، والمفعول فيه (ظرف الزمان وظرف المكان)، والمفعول لأجله، والمفعول معه. المفعول به هو ما وقع عليه فعل الفاعل. المفعول المطلق هو مصدر يذكر لتوكيد الفعل أو بيان نوعه أو عدده. المفعول فيه هو اسم منصوب يدل على زمان وقوع الفعل أو مكانه. المفعول لأجله هو مصدر قلبي يذكر لبيان سبب حدوث الفعل. المفعول معه هو اسم فضلة يذكر بعد واو بمعنى 'مع' مسبوقة بفعل أو ما فيه معناه للدلالة على المصاحبة.\",\n",
        "            \"note_attendue\": 4\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي المفاعيل الخمسة في اللغة العربية؟\",\n",
        "            \"reponse\": \"المفاعيل الخمسة هي: المفعول به، والمفعول المطلق، والمفعول فيه، والمفعول لأجله، والمفعول معه.\",\n",
        "            \"note_attendue\": 2\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    tous_exemples = exemples_test_islamique + exemples_test_arabe\n",
        "\n",
        "    resultats = []\n",
        "    print(\"Test du modèle AraT5 sur des exemples réels:\")\n",
        "\n",
        "    # On va stocker d'abord toutes les lignes dans une liste\n",
        "    lignes_resultats = []\n",
        "\n",
        "    for i, exemple in enumerate(tous_exemples):\n",
        "        question = exemple[\"question\"]\n",
        "        reponse = exemple[\"reponse\"]\n",
        "        note_attendue = exemple[\"note_attendue\"]\n",
        "\n",
        "        input_text = f\"سؤال: {question} إجابة: {reponse}\"\n",
        "\n",
        "        inputs = tokenizer(\n",
        "            input_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        input_ids = inputs.input_ids.to(device)\n",
        "        attention_mask = inputs.attention_mask.to(device)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            prediction = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=10\n",
        "            )\n",
        "\n",
        "        note_predite = convert_t5_output_to_grade(prediction[0], tokenizer) - 1\n",
        "\n",
        "        correct = note_predite == note_attendue\n",
        "\n",
        "        resultat = {\n",
        "            \"question\": question,\n",
        "            \"reponse\": reponse,\n",
        "            \"note_attendue\": note_attendue,\n",
        "            \"note_predite\": note_predite,\n",
        "            \"correct\": correct\n",
        "        }\n",
        "        resultats.append(resultat)\n",
        "\n",
        "        # On ajoute dans la liste pour construire le DataFrame plus tard\n",
        "        lignes_resultats.append({\n",
        "            'Question': question,\n",
        "            'Réponse': reponse[:50] + \"...\" if len(reponse) > 50 else reponse,\n",
        "            'Note attendue': note_attendue + 1,\n",
        "            'Note prédite': note_predite + 1,\n",
        "            'Correct': correct\n",
        "        })\n",
        "\n",
        "        print(f\"Exemple {i+1}:\")\n",
        "        print(f\"Question: {question}\")\n",
        "        print(f\"Réponse (extrait): {reponse[:100]}...\")\n",
        "        print(f\"Note attendue: {note_attendue + 1}/5, Note prédite: {note_predite + 1}/5\")\n",
        "        print(f\"Résultat: {'✓' if correct else '✗'}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Maintenant on crée le DataFrame à partir de la liste\n",
        "    df_resultats = pd.DataFrame(lignes_resultats)\n",
        "\n",
        "    accuracy = sum(r[\"correct\"] for r in resultats) / len(resultats)\n",
        "    mae = sum(abs(r[\"note_predite\"] - r[\"note_attendue\"]) for r in resultats) / len(resultats)\n",
        "\n",
        "    print(f\"Résultats finaux sur {len(resultats)} exemples:\")\n",
        "    print(f\"Précision: {accuracy:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "\n",
        "    return resultats, df_resultats\n",
        "\n",
        "# 8. Fonction pour visualiser les résultats d'entraînement\n",
        "# ------------------------------------------------------\n",
        "\n",
        "def visualiser_resultats_arat5(history):\n",
        "    \"\"\"\n",
        "    Visualise les métriques d'entraînement du modèle AraT5\n",
        "\n",
        "    Args:\n",
        "        history (dict): Historique d'entraînement contenant les métriques\n",
        "    \"\"\"\n",
        "    # Créer la figure avec 3 sous-graphiques\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    # Graphique des pertes\n",
        "    ax1.plot(history[\"train_loss\"], 'b-', label=\"Train\")\n",
        "    ax1.plot(history[\"val_loss\"], 'r-', label=\"Validation\")\n",
        "    ax1.set_title(\"Évolution de la perte\")\n",
        "    ax1.set_xlabel(\"Époque\")\n",
        "    ax1.set_ylabel(\"Perte\")\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    # Graphique de l'exactitude et du kappa\n",
        "    ax2.plot(history[\"val_acc\"], 'g-', label=\"Accuracy\")\n",
        "    ax2.plot(history[\"val_kappa\"], 'm-', label=\"Kappa\")\n",
        "    ax2.set_title(\"Accuracy et Kappa\")\n",
        "    ax2.set_xlabel(\"Époque\")\n",
        "    ax2.set_ylabel(\"Valeur\")\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    # Graphique de MAE\n",
        "    ax3.plot(history[\"val_mae\"], 'c-', label=\"MAE\")\n",
        "    ax3.set_title(\"Erreur moyenne absolue (MAE)\")\n",
        "    ax3.set_xlabel(\"Époque\")\n",
        "    ax3.set_ylabel(\"MAE\")\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"resultats_entrainement_arat5.png\", dpi=300)\n",
        "\n",
        "    return fig\n",
        "\n",
        "# 9. Fonction pour analyser les performances du modèle en détail\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "def analyser_performances_arat5(model, tokenizer, test_loader, device):\n",
        "    \"\"\"\n",
        "    Analyse détaillée des performances du modèle AraT5 sur un ensemble de test\n",
        "\n",
        "    Args:\n",
        "        model: Modèle AraT5 entraîné\n",
        "        tokenizer: Tokenizer du modèle\n",
        "        test_loader: DataLoader pour l'ensemble de test\n",
        "        device: Appareil de calcul (CPU/GPU)\n",
        "\n",
        "    Returns:\n",
        "        dict: Rapport détaillé des performances\n",
        "    \"\"\"\n",
        "    # Évaluation du modèle\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_confs = []  # Confiance des prédictions\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=\"Évaluation détaillée\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Générer les prédictions\n",
        "            outputs = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=10,\n",
        "                return_dict_in_generate=True,\n",
        "                output_scores=True\n",
        "            )\n",
        "\n",
        "            # Convertir les prédictions et les labels en notes numériques\n",
        "            for i, (pred_seq, lab) in enumerate(zip(outputs.sequences, labels)):\n",
        "                # Supprimer les valeurs -100 des labels et décoder\n",
        "                label_ids = lab.clone()\n",
        "                label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "                decoded_label = tokenizer.decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "                try:\n",
        "                    true_grade = int(decoded_label.strip())\n",
        "                    # Ajuster à l'intervalle 0-4 pour les métriques\n",
        "                    true_grade = max(1, min(true_grade, 5)) - 1\n",
        "                except:\n",
        "                    # Si la conversion échoue, ignorer cet exemple\n",
        "                    continue\n",
        "\n",
        "                # Obtenir la prédiction\n",
        "                pred_grade = convert_t5_output_to_grade(pred_seq, tokenizer) - 1  # Ajuster à 0-4\n",
        "\n",
        "                # Calcul approximatif de la confiance du modèle\n",
        "                sequence_scores = outputs.scores[0][i]  # Prendre les scores de la première position générée\n",
        "                token_probs = torch.nn.functional.softmax(sequence_scores, dim=-1)\n",
        "                confidence = token_probs[torch.argmax(token_probs)].item()  # Probabilité du token le plus probable\n",
        "\n",
        "                all_preds.append(pred_grade)\n",
        "                all_labels.append(true_grade)\n",
        "                all_confs.append(confidence)\n",
        "\n",
        "    if not all_preds:\n",
        "        return {\"error\": \"Aucune prédiction valide\"}\n",
        "\n",
        "    # Calculer les métriques de performance\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    kappa = cohen_kappa_score(all_labels, all_preds, weights='quadratic')\n",
        "    mae = np.mean(np.abs(np.array(all_preds) - np.array(all_labels)))\n",
        "\n",
        "    # Classification report\n",
        "    class_names = ['1/5', '2/5', '3/5', '4/5', '5/5']  # Convertir à l'échelle 1-5 pour l'affichage\n",
        "    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
        "\n",
        "    # Matrice de confusion\n",
        "    cm = confusion_matrix(all_labels, all_preds, labels=range(5))\n",
        "\n",
        "    # Créer des visualisations\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # 1. Matrice de confusion\n",
        "    plt.subplot(2, 2, 1)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Matrice de confusion')\n",
        "    plt.xlabel('Prédiction')\n",
        "    plt.ylabel('Valeur réelle')\n",
        "\n",
        "    # 2. Distribution des notes réelles vs prédites\n",
        "    plt.subplot(2, 2, 2)\n",
        "    df = pd.DataFrame({'Réelle': [class_names[i] for i in all_labels],\n",
        "                      'Prédite': [class_names[i] for i in all_preds]})\n",
        "    real_counts = df['Réelle'].value_counts().sort_index()\n",
        "    pred_counts = df['Prédite'].value_counts().sort_index()\n",
        "\n",
        "    combined = pd.DataFrame({'Réelle': real_counts, 'Prédite': pred_counts}).fillna(0)\n",
        "    combined.plot(kind='bar', ax=plt.gca())\n",
        "    plt.title('Distribution des notes')\n",
        "    plt.xlabel('Note')\n",
        "    plt.ylabel(\"Nombre d'exemples\")\n",
        "\n",
        "    # 3. Précision par note\n",
        "    plt.subplot(2, 2, 3)\n",
        "    per_class_acc = [report[name]['precision'] for name in class_names]\n",
        "    plt.bar(class_names, per_class_acc)\n",
        "    plt.title('Précision par note')\n",
        "    plt.xlabel('Note')\n",
        "    plt.ylabel('Précision')\n",
        "\n",
        "    # 4. Relation entre confiance et précision\n",
        "    plt.subplot(2, 2, 4)\n",
        "    correct = np.array(all_preds) == np.array(all_labels)\n",
        "    confidence_correct = pd.DataFrame({'Confiance': all_confs, 'Correct': correct})\n",
        "\n",
        "    # Regrouper par plages de confiance\n",
        "    confidence_bins = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "    confidence_correct['Bin'] = pd.cut(confidence_correct['Confiance'], bins=confidence_bins)\n",
        "    binned_accuracy = confidence_correct.groupby('Bin')['Correct'].mean()\n",
        "\n",
        "    binned_accuracy.plot(kind='bar', ax=plt.gca())\n",
        "    plt.title('Précision vs Confiance')\n",
        "    plt.xlabel('Confiance')\n",
        "    plt.ylabel('Précision')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('analyse_performances_arat5.png')\n",
        "\n",
        "    # Résumé des résultats\n",
        "    results = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"kappa\": kappa,\n",
        "        \"mae\": mae,\n",
        "        \"classification_report\": report,\n",
        "        \"confusion_matrix\": cm,\n",
        "        \"analysis_plot\": 'analyse_performances_arat5.png'\n",
        "    }\n",
        "\n",
        "    # Imprimer les principaux résultats\n",
        "    print(f\"Accuracy globale: {accuracy:.4f}\")\n",
        "    print(f\"Kappa de Cohen: {kappa:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(\"\\nRapport de classification:\")\n",
        "    print(pd.DataFrame(report).transpose())\n",
        "\n",
        "    return results\n",
        "\n",
        "# 10. Fonction pour noter une nouvelle réponse\n",
        "# ------------------------------------------\n",
        "\n",
        "def noter_nouvelle_reponse(question, reponse, model, tokenizer, device=None):\n",
        "    \"\"\"\n",
        "    Utilise le modèle AraT5 entraîné pour noter une nouvelle réponse\n",
        "\n",
        "    Args:\n",
        "        question (str): La question posée\n",
        "        reponse (str): La réponse à évaluer\n",
        "        model: Le modèle AraT5 entraîné\n",
        "        tokenizer: Le tokenizer du modèle\n",
        "        device: L'appareil de calcul (CPU/GPU)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (note, confiance)\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Préparation de l'entrée\n",
        "    input_text = f\"سؤال: {question} إجابة: {reponse}\"\n",
        "\n",
        "    # Tokenisation\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # Déplacer les entrées vers l'appareil approprié\n",
        "    input_ids = inputs.input_ids.to(device)\n",
        "    attention_mask = inputs.attention_mask.to(device)\n",
        "\n",
        "    # Génération avec les scores pour calculer la confiance\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=10,\n",
        "            return_dict_in_generate=True,\n",
        "            output_scores=True\n",
        "        )\n",
        "\n",
        "    # Obtenir la prédiction\n",
        "    prediction = outputs.sequences[0]\n",
        "    note = convert_t5_output_to_grade(prediction, tokenizer)\n",
        "\n",
        "    # Calculer la confiance (probabilité du token prédit)\n",
        "    scores = outputs.scores[0][0]  # Scores pour le premier token généré\n",
        "    probs = torch.nn.functional.softmax(scores, dim=-1)\n",
        "    max_prob = torch.max(probs).item()\n",
        "\n",
        "    # Affichage détaillé\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Réponse: {reponse[:100]}...\" if len(reponse) > 100 else f\"Réponse: {reponse}\")\n",
        "    print(f\"Note attribuée: {note}/5 (confiance: {max_prob:.2f})\")\n",
        "\n",
        "    # Explication de la note\n",
        "    explications = {\n",
        "        1: \"Cette réponse est très insuffisante. Elle manque de contenu pertinent ou contient des erreurs graves.\",\n",
        "        2: \"Cette réponse est insuffisante. Elle contient quelques éléments corrects mais manque de profondeur ou de précision.\",\n",
        "        3: \"Cette réponse est moyenne. Elle couvre partiellement le sujet mais pourrait être plus développée ou plus précise.\",\n",
        "        4: \"Cette réponse est bonne. Elle couvre la plupart des aspects importants du sujet avec une bonne précision.\",\n",
        "        5: \"Cette réponse est excellente. Elle est complète, précise et bien structurée.\"\n",
        "    }\n",
        "\n",
        "    print(f\"Explication: {explications[note]}\")\n",
        "\n",
        "    return note, max_prob\n",
        "\n",
        "# 11. Fonction principale pour exécuter tout le processus\n",
        "# ----------------------------------------------------\n",
        "\n",
        "def main_arat5_ameliore():\n",
        "    \"\"\"\n",
        "    Fonction principale améliorée pour l'entraînement et l'évaluation du modèle AraT5\n",
        "    pour la notation automatique des réponses en arabe\n",
        "    \"\"\"\n",
        "    # 1. Entraînement du modèle avec les fonctions améliorées\n",
        "    model, tokenizer, best_val_acc, history = entrainer_arat5_model(\n",
        "        nb_exemples=3000,        # Plus d'exemples\n",
        "        batch_size=16,           # Adapté selon la mémoire disponible\n",
        "        num_epochs=15,\n",
        "        learning_rate=3e-5,\n",
        "        patience=5,\n",
        "        gradient_accumulation_steps=4  # Pour simuler des batches plus grands\n",
        "    )\n",
        "\n",
        "    # 2. Visualisation des résultats d'entraînement\n",
        "    fig = visualiser_resultats_arat5(history)\n",
        "    plt.close(fig)\n",
        "\n",
        "    # 3. Charger le meilleur modèle pour les tests\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    best_model = T5ForConditionalGeneration.from_pretrained(\"best_arat5_model\")\n",
        "    best_model.to(device)\n",
        "\n",
        "    # 4. Effectuer des tests sur des exemples réels et variés\n",
        "    print(\"\\nTests sur des exemples réels...\")\n",
        "    try:\n",
        "        resultats_test, df_resultats = tester_arat5_model(best_model, tokenizer, device)\n",
        "\n",
        "        # 5. Créer un graphique comparant les notes attendues et prédites\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        # Tracer les barres\n",
        "        width = 0.35\n",
        "        x = np.arange(len(df_resultats))\n",
        "        plt.bar(x - width/2, df_resultats['Note attendue'], width, label='Note attendue')\n",
        "        plt.bar(x + width/2, df_resultats['Note prédite'], width, label='Note prédite')\n",
        "\n",
        "        # Ajouter des étiquettes et des titres\n",
        "        plt.xlabel('Exemple de test')\n",
        "        plt.ylabel('Note (échelle 1-5)')\n",
        "        plt.title('Comparaison des notes attendues et prédites')\n",
        "        plt.xticks(x, [f'Ex{i+1}' for i in range(len(df_resultats))])\n",
        "        plt.yticks([1, 2, 3, 4, 5])\n",
        "        plt.legend()\n",
        "\n",
        "        # Ajouter des symboles pour indiquer les prédictions correctes/incorrectes\n",
        "        for i, correct in enumerate(df_resultats['Correct']):\n",
        "            plt.text(i, 5.2, '✓' if correct else '✗', ha='center',\n",
        "                    color='green' if correct else 'red', fontsize=12)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('resultats_test_arat5.png', dpi=300)\n",
        "\n",
        "        # 6. Sauvegarder le modèle et les résultats\n",
        "        print(\"\\nSauvegarde du modèle et des résultats...\")\n",
        "\n",
        "        # Sauvegarde du modèle final\n",
        "        best_model.save_pretrained(\"arat5_notation_final_ameliore\")\n",
        "        tokenizer.save_pretrained(\"arat5_notation_final_ameliore\")\n",
        "\n",
        "        # Sauvegarde des résultats de test\n",
        "        df_resultats.to_csv(\"resultats_test_arat5.csv\", index=False)\n",
        "\n",
        "        # Sauvegarde de l'historique d'entraînement\n",
        "        pd.DataFrame(history).to_csv(\"historique_entrainement_arat5.csv\", index=False)\n",
        "\n",
        "        print(\"Modèle et résultats sauvegardés avec succès!\")\n",
        "        print(f\"Meilleure précision obtenue avec AraT5: {best_val_acc:.4f}\")\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        print(f\"Une erreur s'est produite pendant la phase de test : {e}\")\n",
        "        traceback.print_exc()\n",
        "        print(\"\\nContinuation avec les exemples individuels...\")\n",
        "\n",
        "    # 7. Exemples d'utilisation du modèle\n",
        "    print(\"\\nExemples d'utilisation du modèle pour noter de nouvelles réponses:\")\n",
        "\n",
        "    # Exemple 1 - Bonne réponse\n",
        "    print(\"\\nExemple 1 - Réponse complète et précise:\")\n",
        "    noter_nouvelle_reponse(\n",
        "        \"ما هي أركان الإسلام الخمسة؟\",\n",
        "        \"أركان الإسلام خمسة: شهادة أن لا إله إلا الله وأن محمدًا رسول الله، وإقام الصلاة، وإيتاء الزكاة، وصوم رمضان، وحج البيت لمن استطاع إليه سبيلا.\",\n",
        "        best_model,\n",
        "        tokenizer,\n",
        "        device\n",
        "    )\n",
        "\n",
        "    # Exemple 2 - Réponse incomplète\n",
        "    print(\"\\nExemple 2 - Réponse incomplète:\")\n",
        "    noter_nouvelle_reponse(\n",
        "        \"ما هي أركان الإسلام الخمسة؟\",\n",
        "        \"الصلاة والزكاة والصوم والحج.\",\n",
        "        best_model,\n",
        "        tokenizer,\n",
        "        device\n",
        "    )\n",
        "\n",
        "    # Exemple 3 - Mauvaise réponse\n",
        "    print(\"\\nExemple 3 - Réponse incorrecte:\")\n",
        "    noter_nouvelle_reponse(\n",
        "        \"ما هي أركان الإسلام الخمسة؟\",\n",
        "        \"لا أعرف بالضبط.\",\n",
        "        best_model,\n",
        "        tokenizer,\n",
        "        device\n",
        "    )\n",
        "\n",
        "    return best_model, tokenizer, history, df_resultats\n",
        "\n",
        "# Exécution du code principal si exécuté comme script\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main_arat5_ameliore()\n",
        "    except Exception as e:\n",
        "        # Afficher plus d'informations sur l'erreur pour faciliter le débogage\n",
        "        import traceback\n",
        "        print(f\"Une erreur s'est produite : {e}\")\n",
        "        print(\"\\nTraceback complet :\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "        # Si c'est une erreur de CUDA, suggérer des solutions\n",
        "        if \"CUDA\" in str(e):\n",
        "            print(\"\\nSuggestion : Il semble y avoir un problème avec CUDA. Essayez de réduire la taille du batch ou utilisez CPU.\")\n",
        "            print(\"Pour utiliser CPU uniquement, ajoutez : os.environ['CUDA_VISIBLE_DEVICES'] = '-1' au début du script.\")\n",
        "\n",
        "        # Si c'est une erreur de mémoire\n",
        "        if \"memory\" in str(e).lower() or \"out of memory\" in str(e).lower():\n",
        "            print(\"\\nSuggestion : Problème de mémoire. Essayez de réduire :\")\n",
        "            print(\"1. batch_size (actuellement 16)\")\n",
        "            print(\"2. max_length (actuellement 512)\")\n",
        "            print(\"3. nb_exemples (actuellement 3000)\")\n",
        "            print(\"4. Utilisez une accumulation de gradient plus grande (actuellement 4)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "def telecharger_et_preparer_arat5(modele_id=\"UBC-NLP/AraT5-base\",\n",
        "                                chemin_modele_local=\"arat5_notation_modele\",\n",
        "                                utiliser_modele_local=True):\n",
        "    \"\"\"\n",
        "    Télécharge et prépare le modèle AraT5 pour la notation\n",
        "\n",
        "    Args:\n",
        "        modele_id (str): Identifiant du modèle AraT5 de base\n",
        "        chemin_modele_local (str): Chemin vers le modèle local entraîné\n",
        "        utiliser_modele_local (bool): Si True, utilise le modèle local s'il existe\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, tokenizer, device)\n",
        "    \"\"\"\n",
        "    # Vérifier si le GPU est disponible\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Utilisation de l'appareil: {device}\")\n",
        "\n",
        "    # Vérifier si un modèle local existe déjà\n",
        "    if utiliser_modele_local and os.path.exists(chemin_modele_local):\n",
        "        print(f\"Chargement du modèle local depuis {chemin_modele_local}...\")\n",
        "        try:\n",
        "            tokenizer = AutoTokenizer.from_pretrained(chemin_modele_local, use_fast=False)\n",
        "            model = T5ForConditionalGeneration.from_pretrained(chemin_modele_local)\n",
        "            model.to(device)\n",
        "            print(\"Modèle local chargé avec succès!\")\n",
        "            return model, tokenizer, device\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur lors du chargement du modèle local: {e}\")\n",
        "            print(\"Téléchargement du modèle de base à la place...\")\n",
        "\n",
        "    # Télécharger le modèle de base\n",
        "    print(f\"Téléchargement du modèle de base {modele_id}...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(modele_id, use_fast=False)\n",
        "    model = T5ForConditionalGeneration.from_pretrained(modele_id)\n",
        "    model.to(device)\n",
        "\n",
        "    print(\"Modèle téléchargé avec succès!\")\n",
        "    print(\"Note: Ce modèle n'est pas encore fine-tuné pour la notation. Utilisez un modèle entraîné pour de meilleurs résultats.\")\n",
        "\n",
        "    return model, tokenizer, device\n",
        "\n",
        "def convert_t5_output_to_grade(prediction, tokenizer):\n",
        "    \"\"\"\n",
        "    Convertit la sortie du modèle T5 en note numérique\n",
        "\n",
        "    Args:\n",
        "        prediction: La prédiction brute du modèle\n",
        "        tokenizer: Le tokenizer utilisé\n",
        "\n",
        "    Returns:\n",
        "        int: La note prédite (1-5)\n",
        "    \"\"\"\n",
        "    decoded_prediction = tokenizer.decode(prediction, skip_special_tokens=True)\n",
        "\n",
        "    # Essayer de convertir en entier (note de 1 à 5)\n",
        "    try:\n",
        "        grade = int(decoded_prediction.strip())\n",
        "        # S'assurer que la note est bien dans l'intervalle 1-5\n",
        "        if grade < 1:\n",
        "            grade = 1\n",
        "        elif grade > 5:\n",
        "            grade = 5\n",
        "    except:\n",
        "        # Si la conversion échoue, attribuer la note moyenne\n",
        "        grade = 3\n",
        "\n",
        "    return grade\n",
        "\n",
        "def noter_reponse_interactive(model, tokenizer, device):\n",
        "    \"\"\"\n",
        "    Interface interactive pour noter des réponses\n",
        "\n",
        "    Args:\n",
        "        model: Le modèle AraT5\n",
        "        tokenizer: Le tokenizer\n",
        "        device: L'appareil de calcul (CPU/GPU)\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"SYSTÈME DE NOTATION DE RÉPONSES EN ARABE\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Entrez votre question et la réponse à évaluer.\")\n",
        "    print(\"Entrez 'q' ou 'quit' pour quitter.\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Explication des notes\n",
        "    explications = {\n",
        "        1: \"TRÈS INSUFFISANT - Réponse incorrecte ou sans contenu pertinent.\",\n",
        "        2: \"INSUFFISANT - Réponse partiellement correcte mais très incomplète.\",\n",
        "        3: \"MOYEN - Réponse acceptable avec des éléments corrects mais manque de détails.\",\n",
        "        4: \"BON - Réponse correcte et assez complète.\",\n",
        "        5: \"EXCELLENT - Réponse complète, précise et bien structurée.\"\n",
        "    }\n",
        "\n",
        "    # Historique des notations pour afficher des statistiques\n",
        "    historique = []\n",
        "\n",
        "    while True:\n",
        "        # Saisie de la question\n",
        "        question = input(\"\\nQuestion (ou 'q' pour quitter): \")\n",
        "        if question.lower() in ['q', 'quit', 'exit']:\n",
        "            break\n",
        "\n",
        "        # Saisie de la réponse\n",
        "        reponse = input(\"Réponse à évaluer: \")\n",
        "        if reponse.lower() in ['q', 'quit', 'exit']:\n",
        "            break\n",
        "\n",
        "        # Option pour entrer une note attendue (pour comparaison)\n",
        "        note_attendue_str = input(\"Note attendue (1-5, ou laisser vide): \")\n",
        "        note_attendue = None\n",
        "        if note_attendue_str.strip():\n",
        "            try:\n",
        "                note_attendue = int(note_attendue_str)\n",
        "                if note_attendue < 1 or note_attendue > 5:\n",
        "                    print(\"Note hors plage, ignorée.\")\n",
        "                    note_attendue = None\n",
        "            except:\n",
        "                print(\"Format de note invalide, ignorée.\")\n",
        "\n",
        "        # Formater l'entrée\n",
        "        input_text = f\"سؤال: {question} إجابة: {reponse}\"\n",
        "        inputs = tokenizer(\n",
        "            input_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Déplacer les entrées sur l'appareil approprié\n",
        "        input_ids = inputs.input_ids.to(device)\n",
        "        attention_mask = inputs.attention_mask.to(device)\n",
        "\n",
        "        # Générer la prédiction\n",
        "        print(\"\\nAnalyse en cours...\")\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=10,\n",
        "                return_dict_in_generate=True,\n",
        "                output_scores=True\n",
        "            )\n",
        "\n",
        "        # Obtenir la prédiction\n",
        "        prediction = outputs.sequences[0]\n",
        "        note = convert_t5_output_to_grade(prediction, tokenizer)\n",
        "\n",
        "        # Calculer la confiance\n",
        "        scores = outputs.scores[0][0]\n",
        "        probs = torch.nn.functional.softmax(scores, dim=-1)\n",
        "        max_prob = torch.max(probs).item()\n",
        "\n",
        "        # Ajouter à l'historique\n",
        "        historique.append({\n",
        "            'question': question,\n",
        "            'reponse': reponse,\n",
        "            'note': note,\n",
        "            'confiance': max_prob,\n",
        "            'note_attendue': note_attendue\n",
        "        })\n",
        "\n",
        "        # Afficher le résultat\n",
        "        print(\"\\n\" + \"-\"*50)\n",
        "        print(f\"RÉSULTAT DE L'ÉVALUATION:\")\n",
        "        print(\"-\"*50)\n",
        "        print(f\"Note attribuée: {note}/5\")\n",
        "        print(f\"Confiance: {max_prob:.2f}\")\n",
        "        if note_attendue:\n",
        "            print(f\"Note attendue: {note_attendue}/5\")\n",
        "            print(f\"Écart: {abs(note - note_attendue)}\")\n",
        "            if note == note_attendue:\n",
        "                print(\"✓ La note correspond à la note attendue!\")\n",
        "            else:\n",
        "                print(\"✗ La note diffère de la note attendue.\")\n",
        "        print(f\"\\nExplication: {explications[note]}\")\n",
        "        print(\"-\"*50)\n",
        "\n",
        "        # Si nous avons évalué plusieurs réponses, afficher des statistiques\n",
        "        if len(historique) > 1:\n",
        "            print(\"\\nSTATISTIQUES DES NOTATIONS:\")\n",
        "            notes_donnees = [h['note'] for h in historique]\n",
        "            notes_moyennes = sum(notes_donnees) / len(notes_donnees)\n",
        "            print(f\"- Nombre d'évaluations: {len(historique)}\")\n",
        "            print(f\"- Note moyenne attribuée: {notes_moyennes:.2f}/5\")\n",
        "\n",
        "            # Si des notes attendues ont été fournies\n",
        "            notes_attendues = [h['note_attendue'] for h in historique if h['note_attendue'] is not None]\n",
        "            if notes_attendues:\n",
        "                ecarts = [abs(h['note'] - h['note_attendue']) for h in historique if h['note_attendue'] is not None]\n",
        "                ecart_moyen = sum(ecarts) / len(ecarts)\n",
        "                match_exact = sum(1 for e in ecarts if e == 0)\n",
        "                match_1 = sum(1 for e in ecarts if e <= 1)\n",
        "\n",
        "                print(f\"- Écart moyen avec les notes attendues: {ecart_moyen:.2f}\")\n",
        "                print(f\"- Correspondance exacte: {match_exact}/{len(notes_attendues)} ({match_exact/len(notes_attendues)*100:.1f}%)\")\n",
        "                print(f\"- Correspondance à ±1 point: {match_1}/{len(notes_attendues)} ({match_1/len(notes_attendues)*100:.1f}%)\")\n",
        "\n",
        "    # Afficher un résumé final des notations\n",
        "    if historique:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"RÉSUMÉ DES NOTATIONS\")\n",
        "        print(\"=\"*50)\n",
        "        print(f\"Nombre total d'évaluations: {len(historique)}\")\n",
        "\n",
        "        # Distribution des notes\n",
        "        print(\"\\nDistribution des notes:\")\n",
        "        notes_distribution = {}\n",
        "        for i in range(1, 6):\n",
        "            count = sum(1 for h in historique if h['note'] == i)\n",
        "            notes_distribution[i] = count\n",
        "            print(f\"  Note {i}/5: {count} réponses ({count/len(historique)*100:.1f}%)\")\n",
        "\n",
        "        # Comparaison avec notes attendues si disponibles\n",
        "        notes_attendues = [h['note_attendue'] for h in historique if h['note_attendue'] is not None]\n",
        "        if notes_attendues and len(notes_attendues) >= 3:\n",
        "            print(\"\\nComparaison avec les notes attendues:\")\n",
        "            ecarts = [abs(h['note'] - h['note_attendue']) for h in historique if h['note_attendue'] is not None]\n",
        "            ecart_moyen = sum(ecarts) / len(ecarts)\n",
        "            print(f\"  Écart moyen: {ecart_moyen:.2f}\")\n",
        "            print(f\"  Correspondance exacte: {sum(1 for e in ecarts if e == 0)/len(ecarts)*100:.1f}%\")\n",
        "            print(f\"  Correspondance à ±1 point: {sum(1 for e in ecarts if e <= 1)/len(ecarts)*100:.1f}%\")\n",
        "\n",
        "            # Visualiser la comparaison si nous avons suffisamment de données\n",
        "            try:\n",
        "                plt.figure(figsize=(12, 6))\n",
        "                indices = range(len(notes_attendues))\n",
        "                plt.plot(indices, [h['note_attendue'] for h in historique if h['note_attendue'] is not None], 'bo-', label='Note attendue')\n",
        "                plt.plot(indices, [h['note'] for h in historique if h['note_attendue'] is not None], 'ro-', label='Note prédite')\n",
        "                plt.ylim(0.5, 5.5)\n",
        "                plt.yticks([1, 2, 3, 4, 5])\n",
        "                plt.xlabel('Exemple')\n",
        "                plt.ylabel('Note (1-5)')\n",
        "                plt.title('Comparaison des notes attendues et prédites')\n",
        "                plt.legend()\n",
        "                plt.grid(True, linestyle='--', alpha=0.7)\n",
        "                plt.savefig('comparaison_notes.png')\n",
        "                print(\"\\nGraphique de comparaison sauvegardé sous 'comparaison_notes.png'\")\n",
        "            except Exception as e:\n",
        "                print(f\"Erreur lors de la création du graphique: {e}\")\n",
        "\n",
        "    print(\"\\nMerci d'avoir utilisé le système de notation!\")\n",
        "\n",
        "def tester_modele_avec_exemples(model, tokenizer, device, nb_exemples=5):\n",
        "    \"\"\"\n",
        "    Teste le modèle sur un ensemble d'exemples prédéfinis\n",
        "\n",
        "    Args:\n",
        "        model: Le modèle AraT5\n",
        "        tokenizer: Le tokenizer\n",
        "        device: L'appareil de calcul (CPU/GPU)\n",
        "        nb_exemples: Nombre d'exemples à tester\n",
        "    \"\"\"\n",
        "    # Exemples prédéfinis\n",
        "    exemples = [\n",
        "        {\n",
        "            \"question\": \"ما هي أركان الإسلام الخمسة؟\",\n",
        "            \"reponse\": \"أركان الإسلام خمسة: شهادة أن لا إله إلا الله وأن محمدًا رسول الله، وإقام الصلاة، وإيتاء الزكاة، وصوم رمضان، وحج البيت لمن استطاع إليه سبيلا.\",\n",
        "            \"note_attendue\": 5\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي أركان الإسلام الخمسة؟\",\n",
        "            \"reponse\": \"الشهادتين والصلاة والزكاة والصيام والحج.\",\n",
        "            \"note_attendue\": 3\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي أركان الإسلام الخمسة؟\",\n",
        "            \"reponse\": \"الصلاة والصيام والحج.\",\n",
        "            \"note_attendue\": 2\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي أركان الإسلام الخمسة؟\",\n",
        "            \"reponse\": \"لا أعرف بالضبط.\",\n",
        "            \"note_attendue\": 1\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي أقسام الكلام في اللغة العربية؟\",\n",
        "            \"reponse\": \"تنقسم الكلمة في اللغة العربية إلى ثلاثة أقسام: اسم وفعل وحرف. الاسم هو ما دل على معنى في نفسه ولم يقترن بزمن مثل: كتاب، قلم، محمد. والفعل هو ما دل على معنى في نفسه واقترن بزمن مثل: كتب، يكتب، اكتب. والحرف هو ما دل على معنى في غيره مثل: في، على، من.\",\n",
        "            \"note_attendue\": 5\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي أقسام الكلام في اللغة العربية؟\",\n",
        "            \"reponse\": \"أقسام الكلام في اللغة العربية هي: اسم وفعل وحرف.\",\n",
        "            \"note_attendue\": 3\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي شروط الصلاة؟\",\n",
        "            \"reponse\": \"شروط الصلاة هي: الإسلام، والعقل، والتمييز، ودخول الوقت، ورفع الحدث، وإزالة النجاسة، وستر العورة، واستقبال القبلة، والنية.\",\n",
        "            \"note_attendue\": 5\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي شروط الصلاة؟\",\n",
        "            \"reponse\": \"من شروط الصلاة الطهارة واستقبال القبلة وستر العورة.\",\n",
        "            \"note_attendue\": 3\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي المفاعيل الخمسة في اللغة العربية؟\",\n",
        "            \"reponse\": \"المفاعيل الخمسة في اللغة العربية هي: المفعول به، والمفعول المطلق، والمفعول فيه (ظرف الزمان وظرف المكان)، والمفعول لأجله، والمفعول معه.\",\n",
        "            \"note_attendue\": 4\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"ما هي المفاعيل الخمسة في اللغة العربية؟\",\n",
        "            \"reponse\": \"المفعول به والمفعول فيه.\",\n",
        "            \"note_attendue\": 2\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Limiter au nombre d'exemples demandé\n",
        "    exemples = exemples[:min(nb_exemples, len(exemples))]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"TEST DU MODÈLE SUR DES EXEMPLES PRÉDÉFINIS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    resultats = []\n",
        "\n",
        "    for i, exemple in enumerate(exemples):\n",
        "        print(f\"\\nExemple {i+1}/{len(exemples)}:\")\n",
        "        print(f\"Question: {exemple['question']}\")\n",
        "        print(f\"Réponse: {exemple['reponse'][:100]}...\" if len(exemple['reponse']) > 100 else f\"Réponse: {exemple['reponse']}\")\n",
        "\n",
        "        # Formater l'entrée\n",
        "        input_text = f\"سؤال: {exemple['question']} إجابة: {exemple['reponse']}\"\n",
        "        inputs = tokenizer(\n",
        "            input_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Déplacer les entrées sur l'appareil approprié\n",
        "        input_ids = inputs.input_ids.to(device)\n",
        "        attention_mask = inputs.attention_mask.to(device)\n",
        "\n",
        "        # Générer la prédiction\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=10,\n",
        "                return_dict_in_generate=True,\n",
        "                output_scores=True\n",
        "            )\n",
        "\n",
        "        # Obtenir la prédiction\n",
        "        prediction = outputs.sequences[0]\n",
        "        note_predite = convert_t5_output_to_grade(prediction, tokenizer)\n",
        "\n",
        "        # Calculer la confiance\n",
        "        scores = outputs.scores[0][0]\n",
        "        probs = torch.nn.functional.softmax(scores, dim=-1)\n",
        "        max_prob = torch.max(probs).item()\n",
        "\n",
        "        # Ajouter aux résultats\n",
        "        resultats.append({\n",
        "            'question': exemple['question'],\n",
        "            'reponse': exemple['reponse'],\n",
        "            'note_attendue': exemple['note_attendue'],\n",
        "            'note_predite': note_predite,\n",
        "            'confiance': max_prob,\n",
        "            'correct': note_predite == exemple['note_attendue'],\n",
        "            'ecart': abs(note_predite - exemple['note_attendue'])\n",
        "        })\n",
        "\n",
        "        # Afficher le résultat\n",
        "        print(f\"Note attendue: {exemple['note_attendue']}/5\")\n",
        "        print(f\"Note prédite: {note_predite}/5 (confiance: {max_prob:.2f})\")\n",
        "        print(\"Résultat: \" + (\"✓ Correct\" if note_predite == exemple['note_attendue'] else f\"✗ Incorrect (écart: {abs(note_predite - exemple['note_attendue'])})\"))\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    # Afficher les statistiques globales\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"RÉSULTATS DU TEST\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    exactitude = sum(r['correct'] for r in resultats) / len(resultats)\n",
        "    ecart_moyen = sum(r['ecart'] for r in resultats) / len(resultats)\n",
        "    dans_un_point = sum(1 for r in resultats if r['ecart'] <= 1) / len(resultats)\n",
        "\n",
        "    print(f\"Nombre d'exemples: {len(resultats)}\")\n",
        "    print(f\"Exactitude (prédiction exacte): {exactitude:.2f} ({sum(r['correct'] for r in resultats)}/{len(resultats)})\")\n",
        "    print(f\"Écart moyen: {ecart_moyen:.2f}\")\n",
        "    print(f\"Prédictions à ±1 point: {dans_un_point:.2f} ({sum(1 for r in resultats if r['ecart'] <= 1)}/{len(resultats)})\")\n",
        "\n",
        "    # Visualiser les résultats\n",
        "    try:\n",
        "        # Créer un graphique de comparaison\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        indices = range(len(resultats))\n",
        "        plt.plot(indices, [r['note_attendue'] for r in resultats], 'bo-', label='Note attendue')\n",
        "        plt.plot(indices, [r['note_predite'] for r in resultats], 'ro-', label='Note prédite')\n",
        "        plt.ylim(0.5, 5.5)\n",
        "        plt.yticks([1, 2, 3, 4, 5])\n",
        "        plt.xticks(indices, [f'Ex{i+1}' for i in indices])\n",
        "        plt.xlabel('Exemple')\n",
        "        plt.ylabel('Note (1-5)')\n",
        "        plt.title('Comparaison des notes attendues et prédites')\n",
        "        plt.legend()\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "        # Ajouter des indicateurs de correspondance\n",
        "        for i, r in enumerate(resultats):\n",
        "            plt.text(i, 5.2, '✓' if r['correct'] else '✗',\n",
        "                   ha='center', color='green' if r['correct'] else 'red', fontsize=12)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('resultats_test_examples.png')\n",
        "        print(\"\\nGraphique de comparaison sauvegardé sous 'resultats_test_examples.png'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur lors de la création du graphique: {e}\")\n",
        "\n",
        "    return resultats\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Fonction principale pour tester le modèle AraT5\n",
        "    \"\"\"\n",
        "    print(\"SYSTÈME DE NOTATION AUTOMATIQUE EN ARABE\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Télécharger et préparer le modèle\n",
        "    # Pour utiliser un modèle entraîné, spécifiez le chemin correct\n",
        "    model, tokenizer, device = telecharger_et_preparer_arat5(\n",
        "        chemin_modele_local=\"best_arat5_model\"  # Modifiez avec votre chemin\n",
        "    )\n",
        "\n",
        "    # Menu principal\n",
        "    while True:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"MENU PRINCIPAL\")\n",
        "        print(\"=\"*50)\n",
        "        print(\"1. Mode interactif (entrer des questions et réponses)\")\n",
        "        print(\"2. Tester le modèle sur des exemples prédéfinis\")\n",
        "        print(\"3. Quitter\")\n",
        "\n",
        "        choix = input(\"\\nVotre choix (1-3): \")\n",
        "\n",
        "        if choix == '1':\n",
        "            noter_reponse_interactive(model, tokenizer, device)\n",
        "        elif choix == '2':\n",
        "            nb_exemples = 5\n",
        "            try:\n",
        "                nb_input = input(\"Nombre d'exemples à tester (1-10, défaut=5): \")\n",
        "                if nb_input.strip():\n",
        "                    nb_exemples = int(nb_input)\n",
        "                    nb_exemples = max(1, min(10, nb_exemples))\n",
        "            except:\n",
        "                print(\"Valeur invalide, utilisation de la valeur par défaut (5)\")\n",
        "\n",
        "            tester_modele_avec_exemples(model, tokenizer, device, nb_exemples)\n",
        "        elif choix == '3':\n",
        "            print(\"\\nMerci d'avoir utilisé le système de notation automatique!\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"\\nChoix invalide. Veuillez entrer 1, 2, ou 3.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3afb562f0ddb45fd8580a8fa52ea46db",
            "d4447517179442188300a293a488a07d",
            "ebabf6f21d3743a5b91ce200c9583b9b",
            "b907a5524f5b4d8bb720a9caa0c8a49e",
            "043487af67e94a07a223c106e85dbe20",
            "978dd8179e54493b9b45b13c710247db",
            "fe69de0eab644cbbae558ab72d45dc1c",
            "585323f6ce6240da89bbe758a0c112f7",
            "52d287c068fa424abb89e70da8c405f1",
            "49982e8ce73145a9868f79c1683d4a70",
            "e638b01ecf6f4e6c88f09b5915428b8b",
            "7130a7ab461043e4af74af1015919a81",
            "9dda30c38ea74edbb13cfb820c9d3418",
            "64e37bc0b22242abab2f4472bc30c355",
            "9497be6b27f2457e87c271d94b341fa6",
            "abe798d94d91434ea78f2779470aaed1",
            "29c0c78a9ff245fbad2767bf968699f8",
            "976591eb0ff84caf847a0517c9885e86",
            "510da51030244aeaaabf02f3358e79af",
            "abf69c2690314697800082082bfbbb35",
            "952167dee6f644f2a52c054b026a6289",
            "08fcb8acbef9415e8e90ee3471b05417",
            "b84060cc44e04353ba0ca823deac0ae7",
            "0fe62f1eb349451e9d4a10e85c737a95",
            "ad8d6fa2a3ba4e6cbf7ed5241e935ace",
            "940e08289df74703a83e1b59c12e1180",
            "c10284631d8546b0a0d272725abee486",
            "9d90d36922ca48b0832e3871773476b3",
            "93df43cfe56c475da6036a4a898fcb77",
            "6aab6f51de9b4298b0b1a6d59a0b5ec7",
            "294a8b393b194d069e682c36d99ad333",
            "771ac60e36b04938ac84dd9e9d532e46",
            "5de50799b0cd45e9b18c7cd936023c63",
            "4cebe836690d471182ec1e8c48f7d79b",
            "1a095ca87b884693a2e00f9d4c483a8e",
            "07b5f3ce8c6e45a182f964e432993965",
            "735415fc2d3547c19da5ceaff1238423",
            "76b8a8dac6c54a95a13d88847eb227ac",
            "754520b5a1d94c858dadb54cd65cf842",
            "a08b94be7ef543bf8d667db6e76abbf9",
            "a1fc6e755aee46ef80e8ab4ac800898f",
            "ca9735659c6f48999c4ecb506e13c8d6",
            "af473c771236423fb6161d57a2523282",
            "6a17dc60093e4c10aa4f4fe8c15f0751",
            "137db1e3798c499c81a502e480322fd3",
            "64e7b3af4fab454e85f40b08ca41b1b4",
            "7a47aedc98e24c328139eb53e0aeafaa",
            "4f9ad940657547bebe0da53e22382313",
            "edf4ea668d574e36816508f4d9c93541",
            "59598302744945a3b20bbd9cf9e7d2c4",
            "6d12ce5f1c9b4a609e9eb027d1e53233",
            "d87c84f8df2b40faa5b7b71b2eff8dda",
            "24b8da519f2742b089f720ef90f121b9",
            "b7ab81c1e85c4e08972cab5e54113939",
            "78f5e99d982f4a019e964da218d1ace4",
            "cd142d8abbdd4568bde85bb1190b553b",
            "5d784f044a6a4e8eaa2dfaf765a197b1",
            "99e9b8c0f58448048cd7ad62acf00822",
            "1a26b8e7131a47b4ad17f5d2182a222e",
            "17363429dced43ad85b190a0e913becf",
            "7d732f5a84a242a4a945c62e448fd535",
            "04eb032b530c4de0844b1d24de28162e",
            "fb4975ccf04e44e5a4b806c368cdda1c",
            "56f858c1534f4d928f8fc476bd0d6884",
            "14648dabe7b44d1d87730bf339dd219e",
            "429031390bae42bdadc848ace866f49e"
          ]
        },
        "id": "k_0FfDEOtXyu",
        "outputId": "def4a9f1-83d4-4f8a-9ab4-19c23988443d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYSTÈME DE NOTATION AUTOMATIQUE EN ARABE\n",
            "==================================================\n",
            "Utilisation de l'appareil: cuda\n",
            "Téléchargement du modèle de base UBC-NLP/AraT5-base...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/81.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3afb562f0ddb45fd8580a8fa52ea46db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/541 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7130a7ab461043e4af74af1015919a81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/2.44M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b84060cc44e04353ba0ca823deac0ae7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/98.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cebe836690d471182ec1e8c48f7d79b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "137db1e3798c499c81a502e480322fd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd142d8abbdd4568bde85bb1190b553b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modèle téléchargé avec succès!\n",
            "Note: Ce modèle n'est pas encore fine-tuné pour la notation. Utilisez un modèle entraîné pour de meilleurs résultats.\n",
            "\n",
            "==================================================\n",
            "MENU PRINCIPAL\n",
            "==================================================\n",
            "1. Mode interactif (entrer des questions et réponses)\n",
            "2. Tester le modèle sur des exemples prédéfinis\n",
            "3. Quitter\n",
            "\n",
            "Votre choix (1-3): 1\n",
            "\n",
            "==================================================\n",
            "SYSTÈME DE NOTATION DE RÉPONSES EN ARABE\n",
            "==================================================\n",
            "Entrez votre question et la réponse à évaluer.\n",
            "Entrez 'q' ou 'quit' pour quitter.\n",
            "==================================================\n",
            "\n",
            "Question (ou 'q' pour quitter): ما رأيك في تأثير وسائل التواصل الاجتماعي على العلاقات الاجتماعية في المجتمع العربي؟\n",
            "Réponse à évaluer: وسائل التواصل الاجتماعي قرّبت المسافات وسهّلت التواصل، لكنها أضعفت العلاقات الحقيقية بين الناس. فهي مفيدة إذا استُخدمت بشكل إيجابي، لكن قد تسبب عزلة ومشاكل اجتماعية إذا أُسيء استخدامها.\n",
            "Note attendue (1-5, ou laisser vide): \n",
            "\n",
            "Analyse en cours...\n",
            "\n",
            "--------------------------------------------------\n",
            "RÉSULTAT DE L'ÉVALUATION:\n",
            "--------------------------------------------------\n",
            "Note attribuée: 3/5\n",
            "Confiance: 0.76\n",
            "\n",
            "Explication: MOYEN - Réponse acceptable avec des éléments corrects mais manque de détails.\n",
            "--------------------------------------------------\n",
            "\n",
            "Question (ou 'q' pour quitter): q\n",
            "\n",
            "==================================================\n",
            "RÉSUMÉ DES NOTATIONS\n",
            "==================================================\n",
            "Nombre total d'évaluations: 1\n",
            "\n",
            "Distribution des notes:\n",
            "  Note 1/5: 0 réponses (0.0%)\n",
            "  Note 2/5: 0 réponses (0.0%)\n",
            "  Note 3/5: 1 réponses (100.0%)\n",
            "  Note 4/5: 0 réponses (0.0%)\n",
            "  Note 5/5: 0 réponses (0.0%)\n",
            "\n",
            "Merci d'avoir utilisé le système de notation!\n",
            "\n",
            "==================================================\n",
            "MENU PRINCIPAL\n",
            "==================================================\n",
            "1. Mode interactif (entrer des questions et réponses)\n",
            "2. Tester le modèle sur des exemples prédéfinis\n",
            "3. Quitter\n",
            "\n",
            "Votre choix (1-3): 1\n",
            "\n",
            "==================================================\n",
            "SYSTÈME DE NOTATION DE RÉPONSES EN ARABE\n",
            "==================================================\n",
            "Entrez votre question et la réponse à évaluer.\n",
            "Entrez 'q' ou 'quit' pour quitter.\n",
            "==================================================\n",
            "\n",
            "Question (ou 'q' pour quitter): Q\n",
            "\n",
            "Merci d'avoir utilisé le système de notation!\n",
            "\n",
            "==================================================\n",
            "MENU PRINCIPAL\n",
            "==================================================\n",
            "1. Mode interactif (entrer des questions et réponses)\n",
            "2. Tester le modèle sur des exemples prédéfinis\n",
            "3. Quitter\n",
            "\n",
            "Votre choix (1-3): 3\n",
            "\n",
            "Merci d'avoir utilisé le système de notation automatique!\n"
          ]
        }
      ]
    }
  ]
}