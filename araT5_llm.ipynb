{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xN-5B8npkdYp",
        "outputId": "3ad41784-a9fb-42f2-f264-c4d0270ede38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement du tokenizer et du mod\u00e8le AraT5...\n",
            "Cr\u00e9ation des donn\u00e9es d'entra\u00eenement avec th\u00e8mes islamiques et arabes (3000 exemples)...\n",
            "Augmentation des donn\u00e9es...\n",
            "Division des donn\u00e9es en ensembles d'entra\u00eenement, validation et test...\n",
            "R\u00e9partition des notes dans l'ensemble d'entra\u00eenement:\n",
            "Note 1/5: 868 exemples (20.1%)\n",
            "Note 2/5: 885 exemples (20.5%)\n",
            "Note 3/5: 850 exemples (19.7%)\n",
            "Note 4/5: 864 exemples (20.0%)\n",
            "Note 5/5: 853 exemples (19.7%)\n",
            "Utilisation de l'appareil: cuda\n",
            "D\u00e9but de l'entra\u00eenement pour 15 \u00e9poques maximum...\n",
            "\u00c9poque 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 270/270 [04:23<00:00,  1.03it/s, loss=107, lr=1.99e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 107.4019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 68/68 [00:55<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 103.3962, Accuracy: 0.1972\n",
            "Kappa: 0.0000, MAE: 1.2009\n",
            "Matrice de confusion:\n",
            "[[  0   0 217   0   0]\n",
            " [  0   0 221   0   0]\n",
            " [  0   0 213   0   0]\n",
            " [  0   0 216   0   0]\n",
            " [  0   0 213   0   0]]\n",
            "Meilleur mod\u00e8le sauvegard\u00e9! Accuracy: 0.1972\n",
            "--------------------------------------------------\n",
            "\u00c9poque 2/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 270/270 [04:23<00:00,  1.03it/s, loss=63.3, lr=2.89e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 63.3169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 68/68 [00:55<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 22.8348, Accuracy: 0.1972\n",
            "Kappa: 0.0000, MAE: 1.2009\n",
            "Matrice de confusion:\n",
            "[[  0   0 217   0   0]\n",
            " [  0   0 221   0   0]\n",
            " [  0   0 213   0   0]\n",
            " [  0   0 216   0   0]\n",
            " [  0   0 213   0   0]]\n",
            "--------------------------------------------------\n",
            "\u00c9poque 3/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 270/270 [04:22<00:00,  1.03it/s, loss=14.4, lr=2.66e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 14.3995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 68/68 [00:54<00:00,  1.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 15.7572, Accuracy: 0.1972\n",
            "Kappa: 0.0000, MAE: 1.2009\n",
            "Matrice de confusion:\n",
            "[[  0   0 217   0   0]\n",
            " [  0   0 221   0   0]\n",
            " [  0   0 213   0   0]\n",
            " [  0   0 216   0   0]\n",
            " [  0   0 213   0   0]]\n",
            "--------------------------------------------------\n",
            "\u00c9poque 4/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 270/270 [04:22<00:00,  1.03it/s, loss=10.6, lr=2.44e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 10.5525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 68/68 [00:44<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 6.9498, Accuracy: 0.1972\n",
            "Kappa: 0.0000, MAE: 1.2009\n",
            "Matrice de confusion:\n",
            "[[  0   0 217   0   0]\n",
            " [  0   0 221   0   0]\n",
            " [  0   0 213   0   0]\n",
            " [  0   0 216   0   0]\n",
            " [  0   0 213   0   0]]\n",
            "--------------------------------------------------\n",
            "\u00c9poque 5/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 270/270 [04:22<00:00,  1.03it/s, loss=7.52, lr=2.22e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 7.5204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 68/68 [00:44<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 4.7796, Accuracy: 0.1972\n",
            "Kappa: 0.0000, MAE: 1.2009\n",
            "Matrice de confusion:\n",
            "[[  0   0 217   0   0]\n",
            " [  0   0 221   0   0]\n",
            " [  0   0 213   0   0]\n",
            " [  0   0 216   0   0]\n",
            " [  0   0 213   0   0]]\n",
            "--------------------------------------------------\n",
            "\u00c9poque 6/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 270/270 [04:22<00:00,  1.03it/s, loss=5.03, lr=1.99e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 5.0315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 68/68 [00:44<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1467, Accuracy: 0.2000\n",
            "Kappa: 0.0000, MAE: 1.4065\n",
            "Matrice de confusion:\n",
            "[[  0   0   0 217   0]\n",
            " [  0   0   0 221   0]\n",
            " [  0   0   0 213   0]\n",
            " [  0   0   0 216   0]\n",
            " [  0   0   0 213   0]]\n",
            "Meilleur mod\u00e8le sauvegard\u00e9! Accuracy: 0.2000\n",
            "--------------------------------------------------\n",
            "\u00c9poque 7/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 270/270 [04:22<00:00,  1.03it/s, loss=1.86, lr=1.77e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.8628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 68/68 [00:44<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7951, Accuracy: 0.2556\n",
            "Kappa: 0.0667, MAE: 1.3963\n",
            "Matrice de confusion:\n",
            "[[ 96 102   0   0  19]\n",
            " [ 64 115   0   0  42]\n",
            " [ 26 130   1   0  56]\n",
            " [  8 163   0   0  45]\n",
            " [  4 145   0   0  64]]\n",
            "Meilleur mod\u00e8le sauvegard\u00e9! Accuracy: 0.2556\n",
            "--------------------------------------------------\n",
            "\u00c9poque 8/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 270/270 [04:22<00:00,  1.03it/s, loss=1.02, lr=1.54e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.0158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 68/68 [00:44<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7575, Accuracy: 0.3824\n",
            "Kappa: 0.2294, MAE: 1.2546\n",
            "Matrice de confusion:\n",
            "[[ 58  48  12   1  98]\n",
            " [  8  79  15   2 117]\n",
            " [  0  27  47   0 139]\n",
            " [  0   0  11  21 184]\n",
            " [  0   0   5   0 208]]\n",
            "Meilleur mod\u00e8le sauvegard\u00e9! Accuracy: 0.3824\n",
            "--------------------------------------------------\n",
            "\u00c9poque 9/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 270/270 [04:22<00:00,  1.03it/s, loss=0.873, lr=1.32e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.8734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 68/68 [00:44<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6153, Accuracy: 0.5000\n",
            "Kappa: 0.3740, MAE: 0.6509\n",
            "Matrice de confusion:\n",
            "[[211   6   0   0   0]\n",
            " [119  98   0   4   0]\n",
            " [  0 128  15  61   9]\n",
            " [  0  50   1 126  39]\n",
            " [  0  47   6  70  90]]\n",
            "Meilleur mod\u00e8le sauvegard\u00e9! Accuracy: 0.5000\n",
            "--------------------------------------------------\n",
            "\u00c9poque 10/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 270/270 [04:22<00:00,  1.03it/s, loss=0.742, lr=1.1e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.7420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 68/68 [00:44<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4473, Accuracy: 0.6296\n",
            "Kappa: 0.5374, MAE: 0.4296\n",
            "Matrice de confusion:\n",
            "[[215   2   0   0   0]\n",
            " [138  55  27   1   0]\n",
            " [  0   3 103  44  63]\n",
            " [  0   0   6 111  99]\n",
            " [  0   0   0  17 196]]\n",
            "Meilleur mod\u00e8le sauvegard\u00e9! Accuracy: 0.6296\n",
            "--------------------------------------------------\n",
            "\u00c9poque 11/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 270/270 [04:22<00:00,  1.03it/s, loss=0.624, lr=8.73e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.6241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 68/68 [00:44<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3809, Accuracy: 0.6259\n",
            "Kappa: 0.5328, MAE: 0.4417\n",
            "Matrice de confusion:\n",
            "[[209   8   0   0   0]\n",
            " [138  79   4   0   0]\n",
            " [  0   1  95  44  73]\n",
            " [  0   0   0  94 122]\n",
            " [  0   0   0  14 199]]\n",
            "--------------------------------------------------\n",
            "\u00c9poque 12/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 270/270 [04:22<00:00,  1.03it/s, loss=0.521, lr=6.49e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.5206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 68/68 [00:44<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3452, Accuracy: 0.6639\n",
            "Kappa: 0.5802, MAE: 0.3981\n",
            "Matrice de confusion:\n",
            "[[210   7   0   0   0]\n",
            " [142  77   2   0   0]\n",
            " [  0   1 130  15  67]\n",
            " [  0   0   0  91 125]\n",
            " [  0   0   0   4 209]]\n",
            "Meilleur mod\u00e8le sauvegard\u00e9! Accuracy: 0.6639\n",
            "--------------------------------------------------\n",
            "\u00c9poque 13/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 270/270 [04:22<00:00,  1.03it/s, loss=0.47, lr=4.25e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.4697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 68/68 [00:44<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3422, Accuracy: 0.6583\n",
            "Kappa: 0.5733, MAE: 0.3954\n",
            "Matrice de confusion:\n",
            "[[210   7   0   0   0]\n",
            " [140  81   0   0   0]\n",
            " [  0   1 114  40  58]\n",
            " [  0   0   0  93 123]\n",
            " [  0   0   0   0 213]]\n",
            "--------------------------------------------------\n",
            "\u00c9poque 14/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 270/270 [04:22<00:00,  1.03it/s, loss=0.434, lr=2.01e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.4338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 68/68 [00:44<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3366, Accuracy: 0.6556\n",
            "Kappa: 0.5698, MAE: 0.3917\n",
            "Matrice de confusion:\n",
            "[[210   7   0   0   0]\n",
            " [151  70   0   0   0]\n",
            " [  0   1 121  40  51]\n",
            " [  0   0   0  94 122]\n",
            " [  0   0   0   0 213]]\n",
            "--------------------------------------------------\n",
            "\u00c9poque 15/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 270/270 [04:22<00:00,  1.03it/s, loss=0.419, lr=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.4189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 68/68 [00:44<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3260, Accuracy: 0.6602\n",
            "Kappa: 0.5756, MAE: 0.3843\n",
            "Matrice de confusion:\n",
            "[[210   7   0   0   0]\n",
            " [151  70   0   0   0]\n",
            " [  0   1 126  38  48]\n",
            " [  0   0   0  94 122]\n",
            " [  0   0   0   0 213]]\n",
            "--------------------------------------------------\n",
            "\u00c9valuation finale sur l'ensemble de test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 38/38 [00:24<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.3459, Test Accuracy: 0.6667\n",
            "Test Kappa: 0.5837, Test MAE: 0.3883\n",
            "Matrice de confusion finale:\n",
            "[[116   5   0   0   0]\n",
            " [ 75  46   2   0   0]\n",
            " [  0   0  81   4  33]\n",
            " [  0   0   0  43  77]\n",
            " [  0   0   0   4 114]]\n",
            "\n",
            "Tests sur des exemples r\u00e9els...\n",
            "Test du mod\u00e8le AraT5 sur des exemples r\u00e9els:\n",
            "Exemple 1:\n",
            "Question: \u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\n",
            "R\u00e9ponse (extrait): \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u062e\u0645\u0633\u0629: \u0634\u0647\u0627\u062f\u0629 \u0623\u0646 \u0644\u0627 \u0625\u0644\u0647 \u0625\u0644\u0627 \u0627\u0644\u0644\u0647 \u0648\u0623\u0646 \u0645\u062d\u0645\u062f\u064b\u0627 \u0631\u0633\u0648\u0644 \u0627\u0644\u0644\u0647\u060c \u0648\u0625\u0642\u0627\u0645 \u0627\u0644\u0635\u0644\u0627\u0629\u060c \u0648\u0625\u064a\u062a\u0627\u0621 \u0627\u0644\u0632\u0643\u0627\u0629\u060c \u0648\u0635\u0648\u0645...\n",
            "Note attendue: 5/5, Note pr\u00e9dite: 4/5\n",
            "R\u00e9sultat: \u2717\n",
            "--------------------------------------------------\n",
            "Exemple 2:\n",
            "Question: \u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\n",
            "R\u00e9ponse (extrait): \u0627\u0644\u0634\u0647\u0627\u062f\u062a\u064a\u0646 \u0648\u0627\u0644\u0635\u0644\u0627\u0629 \u0648\u0627\u0644\u0632\u0643\u0627\u0629 \u0648\u0627\u0644\u0635\u064a\u0627\u0645 \u0648\u0627\u0644\u062d\u062c....\n",
            "Note attendue: 3/5, Note pr\u00e9dite: 2/5\n",
            "R\u00e9sultat: \u2717\n",
            "--------------------------------------------------\n",
            "Exemple 3:\n",
            "Question: \u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\n",
            "R\u00e9ponse (extrait): \u0627\u0644\u0635\u0644\u0627\u0629 \u0648\u0627\u0644\u0635\u064a\u0627\u0645 \u0648\u0627\u0644\u062d\u062c....\n",
            "Note attendue: 2/5, Note pr\u00e9dite: 1/5\n",
            "R\u00e9sultat: \u2717\n",
            "--------------------------------------------------\n",
            "Exemple 4:\n",
            "Question: \u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\n",
            "R\u00e9ponse (extrait): \u0644\u0627 \u0623\u0639\u0631\u0641 \u0628\u0627\u0644\u0636\u0628\u0637....\n",
            "Note attendue: 1/5, Note pr\u00e9dite: 1/5\n",
            "R\u00e9sultat: \u2713\n",
            "--------------------------------------------------\n",
            "Exemple 5:\n",
            "Question: \u0645\u0627 \u0647\u064a \u0634\u0631\u0648\u0637 \u0627\u0644\u0635\u0644\u0627\u0629\u061f\n",
            "R\u00e9ponse (extrait): \u0634\u0631\u0648\u0637 \u0627\u0644\u0635\u0644\u0627\u0629 \u0647\u064a: \u0627\u0644\u0625\u0633\u0644\u0627\u0645\u060c \u0648\u0627\u0644\u0639\u0642\u0644\u060c \u0648\u0627\u0644\u062a\u0645\u064a\u064a\u0632\u060c \u0648\u062f\u062e\u0648\u0644 \u0627\u0644\u0648\u0642\u062a\u060c \u0648\u0631\u0641\u0639 \u0627\u0644\u062d\u062f\u062b\u060c \u0648\u0625\u0632\u0627\u0644\u0629 \u0627\u0644\u0646\u062c\u0627\u0633\u0629\u060c \u0648\u0633\u062a\u0631 \u0627\u0644\u0639\u0648\u0631\u0629\u060c \u0648\u0627\u0633...\n",
            "Note attendue: 5/5, Note pr\u00e9dite: 4/5\n",
            "R\u00e9sultat: \u2717\n",
            "--------------------------------------------------\n",
            "Exemple 6:\n",
            "Question: \u0645\u0627 \u0647\u064a \u0634\u0631\u0648\u0637 \u0627\u0644\u0635\u0644\u0627\u0629\u061f\n",
            "R\u00e9ponse (extrait): \u0645\u0646 \u0634\u0631\u0648\u0637 \u0627\u0644\u0635\u0644\u0627\u0629 \u0627\u0644\u0637\u0647\u0627\u0631\u0629 \u0648\u0627\u0633\u062a\u0642\u0628\u0627\u0644 \u0627\u0644\u0642\u0628\u0644\u0629 \u0648\u0633\u062a\u0631 \u0627\u0644\u0639\u0648\u0631\u0629....\n",
            "Note attendue: 3/5, Note pr\u00e9dite: 2/5\n",
            "R\u00e9sultat: \u2717\n",
            "--------------------------------------------------\n",
            "Exemple 7:\n",
            "Question: \u0645\u0627 \u0647\u064a \u0623\u0642\u0633\u0627\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\n",
            "R\u00e9ponse (extrait): \u062a\u0646\u0642\u0633\u0645 \u0627\u0644\u0643\u0644\u0645\u0629 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0625\u0644\u0649 \u062b\u0644\u0627\u062b\u0629 \u0623\u0642\u0633\u0627\u0645: \u0627\u0633\u0645 \u0648\u0641\u0639\u0644 \u0648\u062d\u0631\u0641. \u0627\u0644\u0627\u0633\u0645 \u0647\u0648 \u0645\u0627 \u062f\u0644 \u0639\u0644\u0649 \u0645\u0639\u0646\u0649 \u0641\u064a \u0646\u0641\u0633\u0647 \u0648\u0644\u0645 \u064a\u0642...\n",
            "Note attendue: 5/5, Note pr\u00e9dite: 5/5\n",
            "R\u00e9sultat: \u2713\n",
            "--------------------------------------------------\n",
            "Exemple 8:\n",
            "Question: \u0645\u0627 \u0647\u064a \u0623\u0642\u0633\u0627\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\n",
            "R\u00e9ponse (extrait): \u0623\u0642\u0633\u0627\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0647\u064a: \u0627\u0633\u0645 \u0648\u0641\u0639\u0644 \u0648\u062d\u0631\u0641....\n",
            "Note attendue: 3/5, Note pr\u00e9dite: 2/5\n",
            "R\u00e9sultat: \u2717\n",
            "--------------------------------------------------\n",
            "Exemple 9:\n",
            "Question: \u0645\u0627 \u0647\u064a \u0623\u0642\u0633\u0627\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\n",
            "R\u00e9ponse (extrait): \u0627\u0633\u0645 \u0648\u0641\u0639\u0644 \u0641\u0642\u0637....\n",
            "Note attendue: 2/5, Note pr\u00e9dite: 1/5\n",
            "R\u00e9sultat: \u2717\n",
            "--------------------------------------------------\n",
            "Exemple 10:\n",
            "Question: \u0645\u0627 \u0647\u064a \u0627\u0644\u0645\u0641\u0627\u0639\u064a\u0644 \u0627\u0644\u062e\u0645\u0633\u0629 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\n",
            "R\u00e9ponse (extrait): \u0627\u0644\u0645\u0641\u0627\u0639\u064a\u0644 \u0627\u0644\u062e\u0645\u0633\u0629 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0647\u064a: \u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0628\u0647\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0627\u0644\u0645\u0637\u0644\u0642\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0641\u064a\u0647 (\u0638\u0631\u0641 \u0627\u0644\u0632\u0645\u0627\u0646 \u0648\u0638\u0631\u0641 \u0627\u0644\u0645\u0643...\n",
            "Note attendue: 5/5, Note pr\u00e9dite: 5/5\n",
            "R\u00e9sultat: \u2713\n",
            "--------------------------------------------------\n",
            "Exemple 11:\n",
            "Question: \u0645\u0627 \u0647\u064a \u0627\u0644\u0645\u0641\u0627\u0639\u064a\u0644 \u0627\u0644\u062e\u0645\u0633\u0629 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\n",
            "R\u00e9ponse (extrait): \u0627\u0644\u0645\u0641\u0627\u0639\u064a\u0644 \u0627\u0644\u062e\u0645\u0633\u0629 \u0647\u064a: \u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0628\u0647\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0627\u0644\u0645\u0637\u0644\u0642\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0641\u064a\u0647\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0644\u0623\u062c\u0644\u0647\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0645\u0639\u0647....\n",
            "Note attendue: 3/5, Note pr\u00e9dite: 3/5\n",
            "R\u00e9sultat: \u2713\n",
            "--------------------------------------------------\n",
            "R\u00e9sultats finaux sur 11 exemples:\n",
            "Pr\u00e9cision: 0.3636\n",
            "MAE: 0.6364\n",
            "\n",
            "Sauvegarde du mod\u00e8le et des r\u00e9sultats...\n",
            "Mod\u00e8le et r\u00e9sultats sauvegard\u00e9s avec succ\u00e8s!\n",
            "Meilleure pr\u00e9cision obtenue avec AraT5: 0.6639\n",
            "\n",
            "Exemples d'utilisation du mod\u00e8le pour noter de nouvelles r\u00e9ponses:\n",
            "\n",
            "Exemple 1 - R\u00e9ponse compl\u00e8te et pr\u00e9cise:\n",
            "Question: \u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\n",
            "R\u00e9ponse: \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u062e\u0645\u0633\u0629: \u0634\u0647\u0627\u062f\u0629 \u0623\u0646 \u0644\u0627 \u0625\u0644\u0647 \u0625\u0644\u0627 \u0627\u0644\u0644\u0647 \u0648\u0623\u0646 \u0645\u062d\u0645\u062f\u064b\u0627 \u0631\u0633\u0648\u0644 \u0627\u0644\u0644\u0647\u060c \u0648\u0625\u0642\u0627\u0645 \u0627\u0644\u0635\u0644\u0627\u0629\u060c \u0648\u0625\u064a\u062a\u0627\u0621 \u0627\u0644\u0632\u0643\u0627\u0629\u060c \u0648\u0635\u0648\u0645...\n",
            "Note attribu\u00e9e: 4/5 (confiance: 0.55)\n",
            "Explication: Cette r\u00e9ponse est bonne. Elle couvre la plupart des aspects importants du sujet avec une bonne pr\u00e9cision.\n",
            "\n",
            "Exemple 2 - R\u00e9ponse incompl\u00e8te:\n",
            "Question: \u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\n",
            "R\u00e9ponse: \u0627\u0644\u0635\u0644\u0627\u0629 \u0648\u0627\u0644\u0632\u0643\u0627\u0629 \u0648\u0627\u0644\u0635\u0648\u0645 \u0648\u0627\u0644\u062d\u062c.\n",
            "Note attribu\u00e9e: 2/5 (confiance: 0.63)\n",
            "Explication: Cette r\u00e9ponse est insuffisante. Elle contient quelques \u00e9l\u00e9ments corrects mais manque de profondeur ou de pr\u00e9cision.\n",
            "\n",
            "Exemple 3 - R\u00e9ponse incorrecte:\n",
            "Question: \u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\n",
            "R\u00e9ponse: \u0644\u0627 \u0623\u0639\u0631\u0641 \u0628\u0627\u0644\u0636\u0628\u0637.\n",
            "Note attribu\u00e9e: 1/5 (confiance: 0.85)\n",
            "Explication: Cette r\u00e9ponse est tr\u00e8s insuffisante. Elle manque de contenu pertinent ou contient des erreurs graves.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import cohen_kappa_score, confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# 1. Pr\u00e9paration des donn\u00e9es pour AraT5\n",
        "# -------------------------------------\n",
        "\n",
        "class AraT5NotationDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset pour le fine-tuning du mod\u00e8le AraT5 pour la notation automatique\n",
        "    \"\"\"\n",
        "    def __init__(self, questions, reponses, notes, tokenizer, max_length=512):\n",
        "        self.questions = questions\n",
        "        self.reponses = reponses\n",
        "        self.notes = notes\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Pour T5, nous utilisons un format \"question: {question} r\u00e9ponse: {r\u00e9ponse}\"\n",
        "        input_text = f\"\u0633\u0624\u0627\u0644: {self.questions[idx]} \u0625\u062c\u0627\u0628\u0629: {self.reponses[idx]}\"\n",
        "\n",
        "        # Pour T5, la cible est la note en texte (convertie de 0-4 \u00e0 1-5)\n",
        "        target_text = str(self.notes[idx] + 1)  # Convertir en texte\n",
        "\n",
        "        input_encodings = self.tokenizer(\n",
        "            input_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        target_encodings = self.tokenizer(\n",
        "            target_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=10,  # Court pour la note\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Supprimer la dimension batch ajout\u00e9e par le tokenizer\n",
        "        input_ids = input_encodings.input_ids.squeeze()\n",
        "        attention_mask = input_encodings.attention_mask.squeeze()\n",
        "        labels = target_encodings.input_ids.squeeze()\n",
        "\n",
        "        # Remplacer les padding tokens dans les labels par -100 pour ignorer la loss\n",
        "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': labels\n",
        "        }\n",
        "\n",
        "# 2. Cr\u00e9ation des donn\u00e9es d'entra\u00eenement avec des th\u00e8mes islamiques et arabes\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def creer_donnees_islamique_arabe(nb_exemples=2000):\n",
        "    \"\"\"\n",
        "    Cr\u00e9e des donn\u00e9es d'entra\u00eenement avec des th\u00e8mes islamiques et arabes\n",
        "\n",
        "    Args:\n",
        "        nb_exemples (int): Nombre d'exemples \u00e0 g\u00e9n\u00e9rer\n",
        "\n",
        "    Returns:\n",
        "        tuple: (questions, reponses, notes) o\u00f9 notes sont des valeurs enti\u00e8res de 0 \u00e0 4\n",
        "    \"\"\"\n",
        "    # Th\u00e8mes islamiques\n",
        "    themes_islamiques = [\n",
        "        \"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645\",  # Piliers de l'Islam\n",
        "        \"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u064a\u0645\u0627\u0646\",  # Piliers de la foi\n",
        "        \"\u0627\u0644\u0632\u0643\u0627\u0629\",       # Zakat\n",
        "        \"\u0627\u0644\u0635\u064a\u0627\u0645\",       # Je\u00fbne\n",
        "        \"\u0627\u0644\u062d\u062c\",         # P\u00e8lerinage\n",
        "        \"\u0627\u0644\u0635\u0644\u0627\u0629\",       # Pri\u00e8re\n",
        "        \"\u0627\u0644\u0642\u0631\u0622\u0646\",       # Coran\n",
        "        \"\u0627\u0644\u0633\u064a\u0631\u0629 \u0627\u0644\u0646\u0628\u0648\u064a\u0629\",  # Biographie du Proph\u00e8te\n",
        "        \"\u0627\u0644\u0623\u062e\u0644\u0627\u0642 \u0627\u0644\u0625\u0633\u0644\u0627\u0645\u064a\u0629\",  # Morale islamique\n",
        "        \"\u0627\u0644\u0645\u0639\u0627\u0645\u0644\u0627\u062a \u0627\u0644\u0625\u0633\u0644\u0627\u0645\u064a\u0629\"  # Transactions islamiques\n",
        "    ]\n",
        "\n",
        "    # Th\u00e8mes arabes\n",
        "    themes_arabes = [\n",
        "        \"\u0627\u0644\u0646\u062d\u0648 \u0627\u0644\u0639\u0631\u0628\u064a\",    # Grammaire arabe\n",
        "        \"\u0627\u0644\u0628\u0644\u0627\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\",  # Rh\u00e9torique arabe\n",
        "        \"\u0627\u0644\u0623\u062f\u0628 \u0627\u0644\u0639\u0631\u0628\u064a\",    # Litt\u00e9rature arabe\n",
        "        \"\u0627\u0644\u0634\u0639\u0631 \u0627\u0644\u0639\u0631\u0628\u064a\",    # Po\u00e9sie arabe\n",
        "        \"\u0627\u0644\u062e\u0637 \u0627\u0644\u0639\u0631\u0628\u064a\",     # Calligraphie arabe\n",
        "        \"\u0627\u0644\u0644\u0647\u062c\u0627\u062a \u0627\u0644\u0639\u0631\u0628\u064a\u0629\",  # Dialectes arabes\n",
        "        \"\u0627\u0644\u062a\u0631\u062c\u0645\u0629\",        # Traduction\n",
        "        \"\u062a\u0627\u0631\u064a\u062e \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\"  # Histoire de la langue arabe\n",
        "    ]\n",
        "\n",
        "    # Combinaison des th\u00e8mes\n",
        "    tous_themes = themes_islamiques + themes_arabes\n",
        "\n",
        "    # Questions par th\u00e8me\n",
        "    questions_par_theme = {\n",
        "        # Piliers de l'Islam\n",
        "        \"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645\": [\n",
        "            \"\u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\",\n",
        "            \"\u0627\u0634\u0631\u062d \u0623\u0647\u0645\u064a\u0629 \u0627\u0644\u0634\u0647\u0627\u062f\u062a\u064a\u0646 \u0641\u064a \u0627\u0644\u0625\u0633\u0644\u0627\u0645.\",\n",
        "            \"\u0645\u0627 \u0647\u0648 \u0627\u0644\u0631\u0643\u0646 \u0627\u0644\u062b\u0627\u0644\u062b \u0645\u0646 \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0648\u0645\u0627 \u0623\u0647\u0645\u064a\u062a\u0647\u061f\",\n",
        "            \"\u0643\u064a\u0641 \u064a\u0624\u062b\u0631 \u0627\u0644\u062d\u062c \u0639\u0644\u0649 \u062d\u064a\u0627\u0629 \u0627\u0644\u0645\u0633\u0644\u0645\u061f\",\n",
        "            \"\u0645\u0627 \u0647\u064a \u0634\u0631\u0648\u0637 \u0627\u0644\u0635\u0644\u0627\u0629 \u0648\u0645\u0627 \u0623\u0647\u0645\u064a\u062a\u0647\u0627 \u0644\u0644\u0645\u0633\u0644\u0645\u061f\"\n",
        "        ],\n",
        "\n",
        "        # Piliers de la foi\n",
        "        \"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u064a\u0645\u0627\u0646\": [\n",
        "            \"\u0627\u0630\u0643\u0631 \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u064a\u0645\u0627\u0646 \u0627\u0644\u0633\u062a\u0629.\",\n",
        "            \"\u0627\u0634\u0631\u062d \u0645\u0639\u0646\u0649 \u0627\u0644\u0625\u064a\u0645\u0627\u0646 \u0628\u0627\u0644\u0642\u0636\u0627\u0621 \u0648\u0627\u0644\u0642\u062f\u0631.\",\n",
        "            \"\u0645\u0627 \u0627\u0644\u0645\u0642\u0635\u0648\u062f \u0628\u0627\u0644\u0625\u064a\u0645\u0627\u0646 \u0628\u0627\u0644\u0645\u0644\u0627\u0626\u0643\u0629\u061f\",\n",
        "            \"\u0643\u064a\u0641 \u064a\u0624\u062b\u0631 \u0627\u0644\u0625\u064a\u0645\u0627\u0646 \u0628\u0627\u0644\u064a\u0648\u0645 \u0627\u0644\u0622\u062e\u0631 \u0639\u0644\u0649 \u0633\u0644\u0648\u0643 \u0627\u0644\u0645\u0633\u0644\u0645\u061f\",\n",
        "            \"\u0645\u0627 \u0647\u064a \u0627\u0644\u0643\u062a\u0628 \u0627\u0644\u0633\u0645\u0627\u0648\u064a\u0629 \u0627\u0644\u062a\u064a \u064a\u0624\u0645\u0646 \u0628\u0647\u0627 \u0627\u0644\u0645\u0633\u0644\u0645\u061f\"\n",
        "        ],\n",
        "\n",
        "        # Zakat\n",
        "        \"\u0627\u0644\u0632\u0643\u0627\u0629\": [\n",
        "            \"\u0645\u0627 \u0647\u0648 \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u0632\u0643\u0627\u0629 \u0648\u0645\u0627 \u062d\u0643\u0645\u0647\u0627 \u0641\u064a \u0627\u0644\u0625\u0633\u0644\u0627\u0645\u061f\",\n",
        "            \"\u0645\u0627 \u0647\u064a \u0634\u0631\u0648\u0637 \u0648\u062c\u0648\u0628 \u0627\u0644\u0632\u0643\u0627\u0629\u061f\",\n",
        "            \"\u0627\u0630\u0643\u0631 \u0645\u0635\u0627\u0631\u0641 \u0627\u0644\u0632\u0643\u0627\u0629 \u0627\u0644\u062b\u0645\u0627\u0646\u064a\u0629.\",\n",
        "            \"\u0645\u0627 \u0647\u0648 \u0627\u0644\u0646\u0635\u0627\u0628 \u0641\u064a \u0627\u0644\u0632\u0643\u0627\u0629 \u0648\u0643\u064a\u0641 \u064a\u064f\u062d\u0633\u0628\u061f\",\n",
        "            \"\u0645\u0627 \u0647\u064a \u0632\u0643\u0627\u0629 \u0627\u0644\u0641\u0637\u0631 \u0648\u0645\u0627 \u062d\u0643\u0645\u0647\u0627\u061f\"\n",
        "        ],\n",
        "\n",
        "        # Je\u00fbne\n",
        "        \"\u0627\u0644\u0635\u064a\u0627\u0645\": [\n",
        "            \"\u0645\u0627 \u0647\u0648 \u0627\u0644\u0635\u064a\u0627\u0645 \u0648\u0645\u062a\u0649 \u0641\u064f\u0631\u0636 \u0639\u0644\u0649 \u0627\u0644\u0645\u0633\u0644\u0645\u064a\u0646\u061f\",\n",
        "            \"\u0645\u0627 \u0647\u064a \u0641\u0648\u0627\u0626\u062f \u0627\u0644\u0635\u064a\u0627\u0645 \u0627\u0644\u0631\u0648\u062d\u064a\u0629 \u0648\u0627\u0644\u0635\u062d\u064a\u0629\u061f\",\n",
        "            \"\u0627\u0630\u0643\u0631 \u0645\u0641\u0633\u062f\u0627\u062a \u0627\u0644\u0635\u064a\u0627\u0645.\",\n",
        "            \"\u0645\u0646 \u0647\u0645 \u0627\u0644\u0623\u0634\u062e\u0627\u0635 \u0627\u0644\u0645\u0639\u0641\u064a\u0648\u0646 \u0645\u0646 \u0627\u0644\u0635\u064a\u0627\u0645\u061f\",\n",
        "            \"\u0645\u0627 \u0627\u0644\u0641\u0631\u0642 \u0628\u064a\u0646 \u0635\u064a\u0627\u0645 \u0627\u0644\u0641\u0631\u0636 \u0648\u0635\u064a\u0627\u0645 \u0627\u0644\u0646\u0627\u0641\u0644\u0629\u061f\"\n",
        "        ],\n",
        "\n",
        "        # P\u00e8lerinage\n",
        "        \"\u0627\u0644\u062d\u062c\": [\n",
        "            \"\u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u062d\u062c\u061f\",\n",
        "            \"\u0627\u0634\u0631\u062d \u0627\u0644\u0641\u0631\u0642 \u0628\u064a\u0646 \u0627\u0644\u062d\u062c \u0648\u0627\u0644\u0639\u0645\u0631\u0629.\",\n",
        "            \"\u0645\u0627 \u0647\u064a \u0634\u0631\u0648\u0637 \u0648\u062c\u0648\u0628 \u0627\u0644\u062d\u062c\u061f\",\n",
        "            \"\u0627\u0634\u0631\u062d \u0645\u0646\u0627\u0633\u0643 \u0627\u0644\u062d\u062c \u0628\u0627\u0644\u062a\u0631\u062a\u064a\u0628.\",\n",
        "            \"\u0645\u0627 \u0647\u064a \u0623\u0646\u0648\u0627\u0639 \u0627\u0644\u0646\u0633\u0643 \u0641\u064a \u0627\u0644\u062d\u062c\u061f\"\n",
        "        ],\n",
        "\n",
        "        # Pri\u00e8re\n",
        "        \"\u0627\u0644\u0635\u0644\u0627\u0629\": [\n",
        "            \"\u0645\u0627 \u0647\u064a \u0627\u0644\u0635\u0644\u0648\u0627\u062a \u0627\u0644\u062e\u0645\u0633 \u0627\u0644\u0645\u0641\u0631\u0648\u0636\u0629 \u0648\u0623\u0648\u0642\u0627\u062a\u0647\u0627\u061f\",\n",
        "            \"\u0627\u0634\u0631\u062d \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0635\u0644\u0627\u0629.\",\n",
        "            \"\u0645\u0627 \u0647\u064a \u0633\u0646\u0646 \u0627\u0644\u0635\u0644\u0627\u0629\u061f\",\n",
        "            \"\u0645\u0627 \u0647\u064a \u0645\u0628\u0637\u0644\u0627\u062a \u0627\u0644\u0635\u0644\u0627\u0629\u061f\",\n",
        "            \"\u0643\u064a\u0641 \u062a\u0624\u062f\u0649 \u0635\u0644\u0627\u0629 \u0627\u0644\u062c\u0645\u0627\u0639\u0629\u061f\"\n",
        "        ],\n",
        "\n",
        "        # Coran\n",
        "        \"\u0627\u0644\u0642\u0631\u0622\u0646\": [\n",
        "            \"\u0643\u0645 \u0639\u062f\u062f \u0633\u0648\u0631 \u0627\u0644\u0642\u0631\u0622\u0646 \u0627\u0644\u0643\u0631\u064a\u0645\u061f\",\n",
        "            \"\u0645\u0627 \u0647\u064a \u0623\u0633\u0628\u0627\u0628 \u0627\u0644\u0646\u0632\u0648\u0644\u061f\",\n",
        "            \"\u0627\u0634\u0631\u062d \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u0625\u0639\u062c\u0627\u0632 \u0641\u064a \u0627\u0644\u0642\u0631\u0622\u0646 \u0627\u0644\u0643\u0631\u064a\u0645.\",\n",
        "            \"\u0645\u0627 \u0627\u0644\u0641\u0631\u0642 \u0628\u064a\u0646 \u0627\u0644\u0633\u0648\u0631 \u0627\u0644\u0645\u0643\u064a\u0629 \u0648\u0627\u0644\u0633\u0648\u0631 \u0627\u0644\u0645\u062f\u0646\u064a\u0629\u061f\",\n",
        "            \"\u0627\u0630\u0643\u0631 \u0623\u0633\u0645\u0627\u0621 \u0628\u0639\u0636 \u0643\u062a\u0628 \u0627\u0644\u062a\u0641\u0633\u064a\u0631 \u0627\u0644\u0645\u0634\u0647\u0648\u0631\u0629.\"\n",
        "        ],\n",
        "\n",
        "        # Grammaire arabe\n",
        "        \"\u0627\u0644\u0646\u062d\u0648 \u0627\u0644\u0639\u0631\u0628\u064a\": [\n",
        "            \"\u0645\u0627 \u0647\u064a \u0623\u0642\u0633\u0627\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\",\n",
        "            \"\u0627\u0634\u0631\u062d \u0623\u0646\u0648\u0627\u0639 \u0627\u0644\u0645\u0639\u0631\u0628 \u0648\u0627\u0644\u0645\u0628\u0646\u064a.\",\n",
        "            \"\u0645\u0627 \u0647\u064a \u0639\u0644\u0627\u0645\u0627\u062a \u0627\u0644\u0625\u0639\u0631\u0627\u0628 \u0627\u0644\u0623\u0635\u0644\u064a\u0629 \u0648\u0627\u0644\u0641\u0631\u0639\u064a\u0629\u061f\",\n",
        "            \"\u0627\u0634\u0631\u062d \u0627\u0644\u0641\u0631\u0642 \u0628\u064a\u0646 \u0627\u0644\u062c\u0645\u0644\u0629 \u0627\u0644\u0627\u0633\u0645\u064a\u0629 \u0648\u0627\u0644\u062c\u0645\u0644\u0629 \u0627\u0644\u0641\u0639\u0644\u064a\u0629.\",\n",
        "            \"\u0645\u0627 \u0647\u064a \u0627\u0644\u0645\u0646\u0635\u0648\u0628\u0627\u062a \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\"\n",
        "        ],\n",
        "\n",
        "        # Rh\u00e9torique arabe\n",
        "        \"\u0627\u0644\u0628\u0644\u0627\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\": [\n",
        "            \"\u0645\u0627 \u0647\u064a \u0623\u0642\u0633\u0627\u0645 \u0627\u0644\u0628\u0644\u0627\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\",\n",
        "            \"\u0627\u0634\u0631\u062d \u0645\u0641\u0647\u0648\u0645 \u0627\u0644\u062a\u0634\u0628\u064a\u0647 \u0648\u0623\u0631\u0643\u0627\u0646\u0647 \u0648\u0623\u0646\u0648\u0627\u0639\u0647.\",\n",
        "            \"\u0645\u0627 \u0647\u0648 \u0627\u0644\u0633\u062c\u0639 \u0648\u0645\u0627 \u0623\u0646\u0648\u0627\u0639\u0647\u061f\",\n",
        "            \"\u0627\u0634\u0631\u062d \u0627\u0644\u0641\u0631\u0642 \u0628\u064a\u0646 \u0627\u0644\u0627\u0633\u062a\u0639\u0627\u0631\u0629 \u0648\u0627\u0644\u0643\u0646\u0627\u064a\u0629.\",\n",
        "            \"\u0645\u0627 \u0647\u0648 \u0639\u0644\u0645 \u0627\u0644\u0645\u0639\u0627\u0646\u064a \u0648\u0645\u0627 \u0623\u0628\u0631\u0632 \u0645\u0648\u0636\u0648\u0639\u0627\u062a\u0647\u061f\"\n",
        "        ],\n",
        "\n",
        "        # Litt\u00e9rature arabe\n",
        "        \"\u0627\u0644\u0623\u062f\u0628 \u0627\u0644\u0639\u0631\u0628\u064a\": [\n",
        "            \"\u0645\u0627 \u0647\u064a \u0627\u0644\u0639\u0635\u0648\u0631 \u0627\u0644\u0623\u062f\u0628\u064a\u0629 \u0641\u064a \u0627\u0644\u0623\u062f\u0628 \u0627\u0644\u0639\u0631\u0628\u064a\u061f\",\n",
        "            \"\u0627\u0630\u0643\u0631 \u0623\u0634\u0647\u0631 \u0634\u0639\u0631\u0627\u0621 \u0627\u0644\u0639\u0635\u0631 \u0627\u0644\u062c\u0627\u0647\u0644\u064a.\",\n",
        "            \"\u0645\u0627 \u0627\u0644\u0645\u0642\u0635\u0648\u062f \u0628\u0627\u0644\u0623\u062f\u0628 \u0627\u0644\u0645\u0647\u062c\u0631\u064a\u061f\",\n",
        "            \"\u0627\u0634\u0631\u062d \u062a\u0637\u0648\u0631 \u0627\u0644\u0642\u0635\u0629 \u0627\u0644\u0642\u0635\u064a\u0631\u0629 \u0641\u064a \u0627\u0644\u0623\u062f\u0628 \u0627\u0644\u0639\u0631\u0628\u064a \u0627\u0644\u062d\u062f\u064a\u062b.\",\n",
        "            \"\u0645\u0646 \u0647\u0645 \u0631\u0648\u0627\u062f \u0627\u0644\u0631\u0648\u0627\u064a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\"\n",
        "        ],\n",
        "\n",
        "        # Po\u00e9sie arabe\n",
        "        \"\u0627\u0644\u0634\u0639\u0631 \u0627\u0644\u0639\u0631\u0628\u064a\": [\n",
        "            \"\u0645\u0627 \u0647\u064a \u0628\u062d\u0648\u0631 \u0627\u0644\u0634\u0639\u0631 \u0627\u0644\u0639\u0631\u0628\u064a\u061f\",\n",
        "            \"\u0627\u0634\u0631\u062d \u0628\u0646\u064a\u0629 \u0627\u0644\u0642\u0635\u064a\u062f\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0627\u0644\u062a\u0642\u0644\u064a\u062f\u064a\u0629.\",\n",
        "            \"\u0645\u0627 \u0627\u0644\u0645\u0642\u0635\u0648\u062f \u0628\u0634\u0639\u0631 \u0627\u0644\u062a\u0641\u0639\u064a\u0644\u0629\u061f\",\n",
        "            \"\u0627\u0630\u0643\u0631 \u0627\u0644\u0645\u0639\u0644\u0642\u0627\u062a \u0627\u0644\u0633\u0628\u0639 \u0648\u0623\u0635\u062d\u0627\u0628\u0647\u0627.\",\n",
        "            \"\u0645\u0627 \u0623\u0628\u0631\u0632 \u062e\u0635\u0627\u0626\u0635 \u0627\u0644\u0634\u0639\u0631 \u0627\u0644\u0639\u0628\u0627\u0633\u064a\u061f\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Mod\u00e8les de r\u00e9ponses pour diff\u00e9rents niveaux de qualit\u00e9 (0-4)\n",
        "    modeles_reponses = {\n",
        "        # Tr\u00e8s mauvaise r\u00e9ponse (note 0)\n",
        "        0: [\n",
        "            \"\u0644\u0627 \u0623\u0639\u0631\u0641.\",\n",
        "            \"\u0644\u064a\u0633 \u0644\u062f\u064a \u0625\u062c\u0627\u0628\u0629.\",\n",
        "            \"{\u062c\u0645\u0644\u0629 \u0642\u0635\u064a\u0631\u0629 \u063a\u064a\u0631 \u0645\u0631\u062a\u0628\u0637\u0629 \u0628\u0627\u0644\u0645\u0648\u0636\u0648\u0639}\",\n",
        "            \"{\u0625\u062c\u0627\u0628\u0629 \u062e\u0627\u0637\u0626\u0629 \u062a\u0645\u0627\u0645\u064b\u0627}\",\n",
        "            \"{\u0643\u0644\u0627\u0645 \u063a\u064a\u0631 \u0645\u0641\u0647\u0648\u0645}\"\n",
        "        ],\n",
        "\n",
        "        # Mauvaise r\u00e9ponse (note 1)\n",
        "        1: [\n",
        "            \"{\u0645\u0639\u0644\u0648\u0645\u0629 \u0648\u0627\u062d\u062f\u0629 \u0635\u062d\u064a\u062d\u0629 \u0645\u0639 \u0623\u062e\u0637\u0627\u0621 \u0643\u062b\u064a\u0631\u0629}\",\n",
        "            \"{\u0625\u062c\u0627\u0628\u0629 \u0642\u0635\u064a\u0631\u0629 \u062c\u062f\u064b\u0627 \u0648\u0646\u0627\u0642\u0635\u0629}\",\n",
        "            \"{\u0645\u0639\u0644\u0648\u0645\u0627\u062a \u0639\u0627\u0645\u0629 \u062f\u0648\u0646 \u062a\u0641\u0627\u0635\u064a\u0644}\",\n",
        "            \"{\u062e\u0644\u0637 \u0628\u064a\u0646 \u0627\u0644\u0645\u0641\u0627\u0647\u064a\u0645 \u0627\u0644\u0645\u062e\u062a\u0644\u0641\u0629}\",\n",
        "            \"{\u0625\u062c\u0627\u0628\u0629 \u0645\u0628\u0647\u0645\u0629 \u0648\u063a\u064a\u0631 \u062f\u0642\u064a\u0642\u0629}\"\n",
        "        ],\n",
        "\n",
        "        # R\u00e9ponse moyenne (note 2)\n",
        "        2: [\n",
        "            \"{\u0628\u0639\u0636 \u0627\u0644\u0645\u0639\u0644\u0648\u0645\u0627\u062a \u0627\u0644\u0635\u062d\u064a\u062d\u0629 \u0645\u0639 \u0628\u0639\u0636 \u0627\u0644\u0623\u062e\u0637\u0627\u0621}\",\n",
        "            \"{\u0625\u062c\u0627\u0628\u0629 \u0645\u062e\u062a\u0635\u0631\u0629 \u062a\u063a\u0637\u064a \u062c\u0632\u0621\u064b\u0627 \u0645\u0646 \u0627\u0644\u0645\u0648\u0636\u0648\u0639}\",\n",
        "            \"{\u0634\u0631\u062d \u0623\u0633\u0627\u0633\u064a \u062f\u0648\u0646 \u062a\u0639\u0645\u0642}\",\n",
        "            \"{\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0645\u062d\u062f\u0648\u062f \u0644\u0644\u0645\u0635\u0637\u0644\u062d\u0627\u062a \u0627\u0644\u062a\u062e\u0635\u0635\u064a\u0629}\",\n",
        "            \"{\u0625\u062c\u0627\u0628\u0629 \u0645\u062a\u0648\u0633\u0637\u0629 \u0627\u0644\u062c\u0648\u062f\u0629 \u062f\u0648\u0646 \u0623\u0645\u062b\u0644\u0629 \u062a\u0648\u0636\u064a\u062d\u064a\u0629}\"\n",
        "        ],\n",
        "\n",
        "        # Bonne r\u00e9ponse (note 3)\n",
        "        3: [\n",
        "            \"{\u0625\u062c\u0627\u0628\u0629 \u0634\u0627\u0645\u0644\u0629 \u0645\u0639 \u062a\u0641\u0627\u0635\u064a\u0644 \u062c\u064a\u062f\u0629}\",\n",
        "            \"{\u0634\u0631\u062d \u0648\u0627\u0636\u062d \u0645\u0639 \u0628\u0639\u0636 \u0627\u0644\u0623\u0645\u062b\u0644\u0629}\",\n",
        "            \"{\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0635\u062d\u064a\u062d \u0644\u0644\u0645\u0635\u0637\u0644\u062d\u0627\u062a \u0627\u0644\u062a\u062e\u0635\u0635\u064a\u0629}\",\n",
        "            \"{\u0625\u062c\u0627\u0628\u0629 \u0645\u0646\u0638\u0645\u0629 \u062a\u063a\u0637\u064a \u0645\u0639\u0638\u0645 \u062c\u0648\u0627\u0646\u0628 \u0627\u0644\u0645\u0648\u0636\u0648\u0639}\",\n",
        "            \"{\u062a\u062d\u0644\u064a\u0644 \u062c\u064a\u062f \u0645\u0639 \u0628\u0639\u0636 \u0627\u0644\u0627\u0633\u062a\u0634\u0647\u0627\u062f\u0627\u062a}\"\n",
        "        ],\n",
        "\n",
        "        # Excellente r\u00e9ponse (note 4)\n",
        "        4: [\n",
        "            \"{\u0625\u062c\u0627\u0628\u0629 \u0634\u0627\u0645\u0644\u0629 \u0648\u0645\u0641\u0635\u0644\u0629 \u062a\u063a\u0637\u064a \u062c\u0645\u064a\u0639 \u062c\u0648\u0627\u0646\u0628 \u0627\u0644\u0645\u0648\u0636\u0648\u0639}\",\n",
        "            \"{\u0634\u0631\u062d \u0645\u0645\u062a\u0627\u0632 \u0645\u0639 \u0623\u0645\u062b\u0644\u0629 \u062a\u0648\u0636\u064a\u062d\u064a\u0629 \u0645\u062a\u0639\u062f\u062f\u0629}\",\n",
        "            \"{\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u062f\u0642\u064a\u0642 \u0644\u0644\u0645\u0635\u0637\u0644\u062d\u0627\u062a \u0627\u0644\u062a\u062e\u0635\u0635\u064a\u0629 \u0645\u0639 \u0634\u0631\u062d\u0647\u0627}\",\n",
        "            \"{\u0625\u062c\u0627\u0628\u0629 \u0645\u0646\u0638\u0645\u0629 \u0628\u0634\u0643\u0644 \u0645\u0645\u062a\u0627\u0632 \u0645\u0639 \u0645\u0642\u062f\u0645\u0629 \u0648\u062e\u0627\u062a\u0645\u0629}\",\n",
        "            \"{\u062a\u062d\u0644\u064a\u0644 \u0639\u0645\u064a\u0642 \u0645\u0639 \u0627\u0633\u062a\u0634\u0647\u0627\u062f\u0627\u062a \u0645\u0646 \u0645\u0635\u0627\u062f\u0631 \u0645\u0648\u062b\u0648\u0642\u0629}\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Exemples sp\u00e9cifiques de r\u00e9ponses par qualit\u00e9 et par th\u00e8me\n",
        "    exemples_reponses = {\n",
        "        # Piliers de l'Islam\n",
        "        \"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645\": {\n",
        "            0: [\"\u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0644\u0647 \u062b\u0644\u0627\u062b\u0629 \u0623\u0631\u0643\u0627\u0646.\", \"\u0627\u0644\u0635\u0644\u0627\u0629 \u0641\u0642\u0637.\"],\n",
        "            1: [\"\u0627\u0644\u0635\u0644\u0627\u0629 \u0648\u0627\u0644\u0635\u064a\u0627\u0645 \u0648\u0627\u0644\u062d\u062c.\", \"\u0627\u0644\u0634\u0647\u0627\u062f\u0629 \u0648\u0627\u0644\u0635\u0644\u0627\u0629.\"],\n",
        "            2: [\"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u062e\u0645\u0633\u0629: \u0627\u0644\u0634\u0647\u0627\u062f\u0629\u060c \u0627\u0644\u0635\u0644\u0627\u0629\u060c \u0627\u0644\u0632\u0643\u0627\u0629\u060c \u0627\u0644\u0635\u064a\u0627\u0645\u060c \u0648\u0627\u0644\u062d\u062c.\", \"\u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u064a\u0642\u0648\u0645 \u0639\u0644\u0649 \u062e\u0645\u0633\u0629 \u0623\u0631\u0643\u0627\u0646 \u062a\u0628\u062f\u0623 \u0628\u0627\u0644\u0634\u0647\u0627\u062f\u062a\u064a\u0646.\"],\n",
        "            3: [\"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u062e\u0645\u0633\u0629: \u0634\u0647\u0627\u062f\u0629 \u0623\u0646 \u0644\u0627 \u0625\u0644\u0647 \u0625\u0644\u0627 \u0627\u0644\u0644\u0647 \u0648\u0623\u0646 \u0645\u062d\u0645\u062f\u064b\u0627 \u0631\u0633\u0648\u0644 \u0627\u0644\u0644\u0647\u060c \u0648\u0625\u0642\u0627\u0645 \u0627\u0644\u0635\u0644\u0627\u0629\u060c \u0648\u0625\u064a\u062a\u0627\u0621 \u0627\u0644\u0632\u0643\u0627\u0629\u060c \u0648\u0635\u0648\u0645 \u0631\u0645\u0636\u0627\u0646\u060c \u0648\u062d\u062c \u0627\u0644\u0628\u064a\u062a \u0644\u0645\u0646 \u0627\u0633\u062a\u0637\u0627\u0639 \u0625\u0644\u064a\u0647 \u0633\u0628\u064a\u0644\u0627. \u0647\u0630\u0647 \u0627\u0644\u0623\u0631\u0643\u0627\u0646 \u0647\u064a \u0623\u0633\u0627\u0633 \u0627\u0644\u0625\u0633\u0644\u0627\u0645.\", \"\u0627\u0644\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u062e\u0645\u0633\u0629 \u0644\u0644\u0625\u0633\u0644\u0627\u0645 \u0647\u064a \u0627\u0644\u0634\u0647\u0627\u062f\u062a\u064a\u0646 \u0648\u0627\u0644\u0635\u0644\u0627\u0629 \u0648\u0627\u0644\u0632\u0643\u0627\u0629 \u0648\u0627\u0644\u0635\u064a\u0627\u0645 \u0648\u0627\u0644\u062d\u062c. \u0648\u062a\u0639\u062a\u0628\u0631 \u0647\u0630\u0647 \u0627\u0644\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0623\u0633\u0627\u0633 \u0627\u0644\u0630\u064a \u064a\u0642\u0648\u0645 \u0639\u0644\u064a\u0647 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0648\u062a\u0645\u064a\u0632\u0647.\"],\n",
        "            4: [\"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u062e\u0645\u0633\u0629 \u0643\u0645\u0627 \u062b\u0628\u062a \u0641\u064a \u062d\u062f\u064a\u062b \u0627\u0644\u0646\u0628\u064a \u0635\u0644\u0649 \u0627\u0644\u0644\u0647 \u0639\u0644\u064a\u0647 \u0648\u0633\u0644\u0645: \u0634\u0647\u0627\u062f\u0629 \u0623\u0646 \u0644\u0627 \u0625\u0644\u0647 \u0625\u0644\u0627 \u0627\u0644\u0644\u0647 \u0648\u0623\u0646 \u0645\u062d\u0645\u062f\u0627\u064b \u0631\u0633\u0648\u0644 \u0627\u0644\u0644\u0647\u060c \u0648\u0647\u064a \u0623\u0633\u0627\u0633 \u0627\u0644\u0639\u0642\u064a\u062f\u0629 \u0648\u0634\u0631\u0637 \u0644\u0635\u062d\u0629 \u0627\u0644\u0623\u0639\u0645\u0627\u0644. \u0648\u0625\u0642\u0627\u0645 \u0627\u0644\u0635\u0644\u0627\u0629\u060c \u0627\u0644\u062a\u064a \u0647\u064a \u0639\u0645\u0648\u062f \u0627\u0644\u062f\u064a\u0646 \u0648\u062a\u062c\u0628 \u062e\u0645\u0633 \u0645\u0631\u0627\u062a \u0641\u064a \u0627\u0644\u064a\u0648\u0645 \u0648\u0627\u0644\u0644\u064a\u0644\u0629. \u0648\u0625\u064a\u062a\u0627\u0621 \u0627\u0644\u0632\u0643\u0627\u0629\u060c \u0648\u0647\u064a \u062d\u0642 \u0627\u0644\u0645\u0627\u0644 \u0648\u0637\u0647\u0627\u0631\u0629 \u0644\u0644\u0646\u0641\u0633 \u0648\u0627\u0644\u0645\u062c\u062a\u0645\u0639. \u0648\u0635\u0648\u0645 \u0631\u0645\u0636\u0627\u0646\u060c \u0627\u0644\u0630\u064a \u0647\u0648 \u0634\u0647\u0631 \u0627\u0644\u0639\u0628\u0627\u062f\u0629 \u0648\u0627\u0644\u062a\u0642\u0648\u0649. \u0648\u062d\u062c \u0627\u0644\u0628\u064a\u062a \u0644\u0645\u0646 \u0627\u0633\u062a\u0637\u0627\u0639 \u0625\u0644\u064a\u0647 \u0633\u0628\u064a\u0644\u0627\u060c \u0648\u0647\u0648 \u0641\u0631\u0636 \u0645\u0631\u0629 \u0648\u0627\u062d\u062f\u0629 \u0641\u064a \u0627\u0644\u0639\u0645\u0631 \u0644\u0645\u0646 \u062a\u0648\u0641\u0631\u062a \u0641\u064a\u0647 \u0627\u0644\u0634\u0631\u0648\u0637.\",\n",
        "             \"\u0627\u0644\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u062e\u0645\u0633\u0629 \u0644\u0644\u0625\u0633\u0644\u0627\u0645 \u062a\u0645\u062b\u0644 \u0627\u0644\u0623\u0633\u0633 \u0627\u0644\u062a\u064a \u064a\u0642\u0648\u0645 \u0639\u0644\u064a\u0647\u0627 \u0627\u0644\u062f\u064a\u0646\u060c \u0648\u062a\u0628\u062f\u0623 \u0628\u0627\u0644\u0634\u0647\u0627\u062f\u062a\u064a\u0646 \u0627\u0644\u062a\u064a \u062a\u0645\u062b\u0644 \u0627\u0644\u0625\u0642\u0631\u0627\u0631 \u0628\u0627\u0644\u062a\u0648\u062d\u064a\u062f \u0648\u0627\u0644\u0631\u0633\u0627\u0644\u0629\u060c \u062b\u0645 \u0627\u0644\u0635\u0644\u0627\u0629 \u0627\u0644\u062a\u064a \u0647\u064a \u0635\u0644\u0629 \u0627\u0644\u0639\u0628\u062f \u0628\u0631\u0628\u0647 \u0648\u062a\u062a\u0643\u0631\u0631 \u062e\u0645\u0633 \u0645\u0631\u0627\u062a \u064a\u0648\u0645\u064a\u064b\u0627\u060c \u062b\u0645 \u0627\u0644\u0632\u0643\u0627\u0629 \u0627\u0644\u062a\u064a \u062a\u062d\u0642\u0642 \u0627\u0644\u062a\u0643\u0627\u0641\u0644 \u0627\u0644\u0627\u062c\u062a\u0645\u0627\u0639\u064a \u0648\u062a\u0637\u0647\u0631 \u0627\u0644\u0645\u0627\u0644\u060c \u062b\u0645 \u0635\u064a\u0627\u0645 \u0634\u0647\u0631 \u0631\u0645\u0636\u0627\u0646 \u0627\u0644\u0630\u064a \u064a\u0639\u0632\u0632 \u0627\u0644\u062a\u0642\u0648\u0649 \u0648\u0627\u0644\u0635\u0628\u0631\u060c \u0648\u0623\u062e\u064a\u0631\u064b\u0627 \u0627\u0644\u062d\u062c \u0625\u0644\u0649 \u0628\u064a\u062a \u0627\u0644\u0644\u0647 \u0627\u0644\u062d\u0631\u0627\u0645 \u0644\u0645\u0646 \u0627\u0633\u062a\u0637\u0627\u0639 \u0625\u0644\u064a\u0647 \u0633\u0628\u064a\u0644\u0627 \u0648\u0647\u0648 \u064a\u062c\u0645\u0639 \u0645\u0639\u0638\u0645 \u0627\u0644\u0639\u0628\u0627\u062f\u0627\u062a. \u0648\u0642\u062f \u0630\u0643\u0631\u062a \u0647\u0630\u0647 \u0627\u0644\u0623\u0631\u0643\u0627\u0646 \u0641\u064a \u062d\u062f\u064a\u062b \u0627\u0644\u0646\u0628\u064a \u0645\u062d\u0645\u062f \u0635\u0644\u0649 \u0627\u0644\u0644\u0647 \u0639\u0644\u064a\u0647 \u0648\u0633\u0644\u0645: '\u0628\u0646\u064a \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0639\u0644\u0649 \u062e\u0645\u0633...'.\"]\n",
        "        },\n",
        "\n",
        "        # Grammaire arabe\n",
        "        \"\u0627\u0644\u0646\u062d\u0648 \u0627\u0644\u0639\u0631\u0628\u064a\": {\n",
        "            0: [\"\u0627\u0644\u0646\u062d\u0648 \u0647\u0648 \u0642\u0648\u0627\u0639\u062f \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0625\u0646\u062c\u0644\u064a\u0632\u064a\u0629.\", \"\u0644\u0627 \u0623\u0639\u0631\u0641 \u0645\u0627 \u0647\u0648 \u0627\u0644\u0646\u062d\u0648.\"],\n",
        "            1: [\"\u0627\u0644\u0646\u062d\u0648 \u0647\u0648 \u0643\u064a\u0641\u064a\u0629 \u0643\u062a\u0627\u0628\u0629 \u0627\u0644\u0643\u0644\u0645\u0627\u062a.\", \"\u0627\u0644\u0646\u062d\u0648 \u0647\u0648 \u0631\u0641\u0639 \u0627\u0644\u0641\u0627\u0639\u0644.\"],\n",
        "            2: [\"\u0627\u0644\u0646\u062d\u0648 \u0627\u0644\u0639\u0631\u0628\u064a \u0647\u0648 \u0639\u0644\u0645 \u064a\u0628\u062d\u062b \u0641\u064a \u0623\u062d\u0648\u0627\u0644 \u0623\u0648\u0627\u062e\u0631 \u0627\u0644\u0643\u0644\u0645 \u0625\u0639\u0631\u0627\u0628\u064b\u0627 \u0648\u0628\u0646\u0627\u0621\u064b. \u0645\u0646 \u0623\u0642\u0633\u0627\u0645\u0647 \u0627\u0644\u0645\u0631\u0641\u0648\u0639\u0627\u062a \u0648\u0627\u0644\u0645\u0646\u0635\u0648\u0628\u0627\u062a.\", \"\u0627\u0644\u0646\u062d\u0648 \u064a\u0634\u0645\u0644 \u0627\u0644\u0625\u0639\u0631\u0627\u0628 \u0648\u0627\u0644\u0628\u0646\u0627\u0621 \u0648\u0627\u0644\u0641\u0627\u0639\u0644 \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0628\u0647.\"],\n",
        "            3: [\"\u0627\u0644\u0646\u062d\u0648 \u0627\u0644\u0639\u0631\u0628\u064a \u0647\u0648 \u0639\u0644\u0645 \u064a\u0628\u062d\u062b \u0641\u064a \u0623\u062d\u0648\u0627\u0644 \u0623\u0648\u0627\u062e\u0631 \u0627\u0644\u0643\u0644\u0645 \u0625\u0639\u0631\u0627\u0628\u064b\u0627 \u0648\u0628\u0646\u0627\u0621\u064b. \u064a\u0634\u0645\u0644 \u0623\u0642\u0633\u0627\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0645\u0646 \u0627\u0633\u0645 \u0648\u0641\u0639\u0644 \u0648\u062d\u0631\u0641\u060c \u0648\u0627\u0644\u0625\u0639\u0631\u0627\u0628 \u0648\u0627\u0644\u0628\u0646\u0627\u0621\u060c \u0648\u0627\u0644\u0645\u0631\u0641\u0648\u0639\u0627\u062a \u0643\u0627\u0644\u0641\u0627\u0639\u0644 \u0648\u0627\u0644\u0645\u0628\u062a\u062f\u0623\u060c \u0648\u0627\u0644\u0645\u0646\u0635\u0648\u0628\u0627\u062a \u0643\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0628\u0647\u060c \u0648\u0627\u0644\u0645\u062c\u0631\u0648\u0631\u0627\u062a \u0643\u0627\u0644\u0645\u0636\u0627\u0641 \u0625\u0644\u064a\u0647.\", \"\u0627\u0644\u0646\u062d\u0648 \u0647\u0648 \u0639\u0644\u0645 \u064a\u062f\u0631\u0633 \u062a\u0631\u0643\u064a\u0628 \u0627\u0644\u062c\u0645\u0644\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0648\u0643\u064a\u0641\u064a\u0629 \u0625\u0639\u0631\u0627\u0628 \u0643\u0644\u0645\u0627\u062a\u0647\u0627. \u064a\u0646\u0642\u0633\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0625\u0644\u0649 \u062b\u0644\u0627\u062b\u0629 \u0623\u0642\u0633\u0627\u0645: \u0627\u0633\u0645 \u0648\u0641\u0639\u0644 \u0648\u062d\u0631\u0641. \u0648\u064a\u0646\u0642\u0633\u0645 \u0627\u0644\u0625\u0639\u0631\u0627\u0628 \u0625\u0644\u0649 \u0631\u0641\u0639 \u0648\u0646\u0635\u0628 \u0648\u062c\u0631 \u0648\u062c\u0632\u0645. \u0645\u0646 \u0627\u0644\u0645\u0631\u0641\u0648\u0639\u0627\u062a: \u0627\u0644\u0641\u0627\u0639\u0644 \u0648\u0627\u0644\u0645\u0628\u062a\u062f\u0623 \u0648\u0627\u0644\u062e\u0628\u0631. \u0648\u0645\u0646 \u0627\u0644\u0645\u0646\u0635\u0648\u0628\u0627\u062a: \u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0628\u0647 \u0648\u0627\u0644\u062d\u0627\u0644 \u0648\u0627\u0644\u062a\u0645\u064a\u064a\u0632.\"],\n",
        "            4: [\"\u0627\u0644\u0646\u062d\u0648 \u0627\u0644\u0639\u0631\u0628\u064a \u0647\u0648 \u0639\u0644\u0645 \u064a\u0628\u062d\u062b \u0641\u064a \u0623\u062d\u0648\u0627\u0644 \u0623\u0648\u0627\u062e\u0631 \u0627\u0644\u0643\u0644\u0645 \u0625\u0639\u0631\u0627\u0628\u064b\u0627 \u0648\u0628\u0646\u0627\u0621\u064b\u060c \u0648\u0642\u062f \u0648\u0636\u0639 \u0623\u0633\u0633\u0647 \u0623\u0628\u0648 \u0627\u0644\u0623\u0633\u0648\u062f \u0627\u0644\u062f\u0624\u0644\u064a \u0628\u062a\u0648\u062c\u064a\u0647 \u0645\u0646 \u0627\u0644\u0625\u0645\u0627\u0645 \u0639\u0644\u064a \u0631\u0636\u064a \u0627\u0644\u0644\u0647 \u0639\u0646\u0647. \u064a\u0646\u0642\u0633\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0625\u0644\u0649 \u062b\u0644\u0627\u062b\u0629 \u0623\u0642\u0633\u0627\u0645: \u0627\u0644\u0627\u0633\u0645 \u0648\u0639\u0644\u0627\u0645\u062a\u0647 \u0642\u0628\u0648\u0644 \u0627\u0644\u062c\u0631 \u0648\u0627\u0644\u062a\u0646\u0648\u064a\u0646 \u0648\u0623\u0644\u060c \u0648\u0627\u0644\u0641\u0639\u0644 \u0648\u064a\u0646\u0642\u0633\u0645 \u0625\u0644\u0649 \u0645\u0627\u0636\u064d \u0648\u0645\u0636\u0627\u0631\u0639 \u0648\u0623\u0645\u0631\u060c \u0648\u0627\u0644\u062d\u0631\u0641 \u0648\u0647\u0648 \u0645\u0627 \u0644\u0627 \u064a\u0642\u0628\u0644 \u0639\u0644\u0627\u0645\u0627\u062a \u0627\u0644\u0627\u0633\u0645 \u0648\u0644\u0627 \u0627\u0644\u0641\u0639\u0644. \u0623\u0645\u0627 \u0627\u0644\u0625\u0639\u0631\u0627\u0628 \u0641\u064a\u0646\u0642\u0633\u0645 \u0625\u0644\u0649: \u0627\u0644\u0631\u0641\u0639 \u0648\u0639\u0644\u0627\u0645\u062a\u0647 \u0627\u0644\u0623\u0635\u0644\u064a\u0629 \u0627\u0644\u0636\u0645\u0629\u060c \u0648\u0627\u0644\u0646\u0635\u0628 \u0648\u0639\u0644\u0627\u0645\u062a\u0647 \u0627\u0644\u0623\u0635\u0644\u064a\u0629 \u0627\u0644\u0641\u062a\u062d\u0629\u060c \u0648\u0627\u0644\u062c\u0631 \u0648\u0639\u0644\u0627\u0645\u062a\u0647 \u0627\u0644\u0623\u0635\u0644\u064a\u0629 \u0627\u0644\u0643\u0633\u0631\u0629\u060c \u0648\u0627\u0644\u062c\u0632\u0645 \u0648\u0639\u0644\u0627\u0645\u062a\u0647 \u0627\u0644\u0623\u0635\u0644\u064a\u0629 \u0627\u0644\u0633\u0643\u0648\u0646. \u0648\u0645\u0646 \u0627\u0644\u0645\u0631\u0641\u0648\u0639\u0627\u062a: \u0627\u0644\u0641\u0627\u0639\u0644 \u0648\u0627\u0644\u0645\u0628\u062a\u062f\u0623 \u0648\u0627\u0644\u062e\u0628\u0631. \u0648\u0645\u0646 \u0627\u0644\u0645\u0646\u0635\u0648\u0628\u0627\u062a: \u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0628\u0647 \u0648\u0627\u0644\u062d\u0627\u0644 \u0648\u0627\u0644\u062a\u0645\u064a\u064a\u0632. \u0648\u0645\u0646 \u0627\u0644\u0645\u062c\u0631\u0648\u0631\u0627\u062a: \u0627\u0644\u0645\u0636\u0627\u0641 \u0625\u0644\u064a\u0647 \u0648\u0627\u0644\u0645\u062c\u0631\u0648\u0631 \u0628\u062d\u0631\u0641 \u0627\u0644\u062c\u0631.\", \"\u0627\u0644\u0646\u062d\u0648 \u0627\u0644\u0639\u0631\u0628\u064a \u0647\u0648 \u0639\u0644\u0645 \u0623\u0633\u0627\u0633\u064a \u0645\u0646 \u0639\u0644\u0648\u0645 \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u060c \u064a\u064f\u0639\u0646\u0649 \u0628\u062f\u0631\u0627\u0633\u0629 \u0623\u062d\u0648\u0627\u0644 \u0623\u0648\u0627\u062e\u0631 \u0627\u0644\u0643\u0644\u0645 \u0625\u0639\u0631\u0627\u0628\u064b\u0627 \u0648\u0628\u0646\u0627\u0621\u064b. \u0648\u0636\u0639 \u0623\u0633\u0633\u0647 \u0623\u0628\u0648 \u0627\u0644\u0623\u0633\u0648\u062f \u0627\u0644\u062f\u0624\u0644\u064a \u0628\u062a\u0648\u062c\u064a\u0647 \u0645\u0646 \u0627\u0644\u0625\u0645\u0627\u0645 \u0639\u0644\u064a\u060c \u062b\u0645 \u062a\u0637\u0648\u0631 \u0639\u0644\u0649 \u064a\u062f \u0627\u0644\u062e\u0644\u064a\u0644 \u0628\u0646 \u0623\u062d\u0645\u062f \u0627\u0644\u0641\u0631\u0627\u0647\u064a\u062f\u064a \u0648\u0633\u064a\u0628\u0648\u064a\u0647. \u064a\u0646\u0642\u0633\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0641\u064a \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0625\u0644\u0649: \u0627\u0633\u0645 (\u0645\u062b\u0644: \u0645\u062d\u0645\u062f\u060c \u0643\u062a\u0627\u0628)\u060c \u0648\u0641\u0639\u0644 (\u0645\u062b\u0644: \u0643\u062a\u0628\u060c \u064a\u0643\u062a\u0628\u060c \u0627\u0643\u062a\u0628)\u060c \u0648\u062d\u0631\u0641 (\u0645\u062b\u0644: \u0641\u064a\u060c \u0639\u0644\u0649\u060c \u0645\u0646). \u0648\u0627\u0644\u0625\u0639\u0631\u0627\u0628 \u0623\u0631\u0628\u0639\u0629 \u0623\u0646\u0648\u0627\u0639: \u0631\u0641\u0639 (\u0639\u0644\u0627\u0645\u062a\u0647 \u0627\u0644\u0636\u0645\u0629 \u2609\u064f)\u060c \u0648\u0646\u0635\u0628 (\u0639\u0644\u0627\u0645\u062a\u0647 \u0627\u0644\u0641\u062a\u062d\u0629 \u2609\u064e)\u060c \u0648\u062c\u0631 (\u0639\u0644\u0627\u0645\u062a\u0647 \u0627\u0644\u0643\u0633\u0631\u0629 \u2609\u0650)\u060c \u0648\u062c\u0632\u0645 (\u0639\u0644\u0627\u0645\u062a\u0647 \u0627\u0644\u0633\u0643\u0648\u0646 \u2609\u0652). \u0648\u062a\u0646\u0642\u0633\u0645 \u0627\u0644\u0643\u0644\u0645\u0627\u062a \u0628\u062d\u0633\u0628 \u0625\u0639\u0631\u0627\u0628\u0647\u0627 \u0625\u0644\u0649 \u0645\u0631\u0641\u0648\u0639\u0627\u062a \u0645\u062b\u0644 \u0627\u0644\u0645\u0628\u062a\u062f\u0623 \u0648\u0627\u0644\u062e\u0628\u0631 \u0648\u0627\u0644\u0641\u0627\u0639\u0644\u060c \u0648\u0645\u0646\u0635\u0648\u0628\u0627\u062a \u0645\u062b\u0644 \u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0628\u0647 \u0648\u0627\u0644\u062d\u0627\u0644\u060c \u0648\u0645\u062c\u0631\u0648\u0631\u0627\u062a \u0645\u062b\u0644 \u0627\u0644\u0645\u0636\u0627\u0641 \u0625\u0644\u064a\u0647.\"],\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Fonction pour g\u00e9n\u00e9rer une r\u00e9ponse selon la question et la qualit\u00e9\n",
        "    def generer_reponse(theme, question, qualite):\n",
        "        # V\u00e9rifier si nous avons des exemples sp\u00e9cifiques pour ce th\u00e8me\n",
        "        if theme in exemples_reponses and qualite in exemples_reponses[theme]:\n",
        "            return random.choice(exemples_reponses[theme][qualite])\n",
        "\n",
        "        # Si non, g\u00e9n\u00e9rer une r\u00e9ponse bas\u00e9e sur les mod\u00e8les\n",
        "        if qualite == 0:\n",
        "            return random.choice(modeles_reponses[0])\n",
        "        elif qualite == 1:\n",
        "            if \"\u0645\u0627 \u0647\u064a\" in question or \"\u0627\u0630\u0643\u0631\" in question:\n",
        "                return question.replace(\"\u0645\u0627 \u0647\u064a\", \"\u0647\u064a\").replace(\"\u0627\u0630\u0643\u0631\", \"\") + \" \" + random.choice([\"\u0648\u0647\u0630\u0627 \u0643\u0644 \u0645\u0627 \u0623\u0639\u0631\u0641\u0647.\", \"\u0641\u0642\u0637.\"])\n",
        "            else:\n",
        "                return random.choice(modeles_reponses[1])\n",
        "        elif qualite == 2:\n",
        "            if theme in [\"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645\", \"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u064a\u0645\u0627\u0646\", \"\u0627\u0644\u0642\u0631\u0622\u0646\"]:\n",
        "                return \"\u0641\u064a \u0627\u0644\u0625\u0633\u0644\u0627\u0645\u060c \" + question.replace(\"\u0645\u0627 \u0647\u064a\", \"\").replace(\"\u0627\u0634\u0631\u062d\", \"\").replace(\"\u061f\", \"\") + \" \u0645\u0647\u0645\u0629 \u0644\u0644\u0645\u0633\u0644\u0645\u064a\u0646 \u0648\u064a\u062c\u0628 \u0627\u0644\u0627\u0644\u062a\u0632\u0627\u0645 \u0628\u0647\u0627.\"\n",
        "            elif theme in [\"\u0627\u0644\u0646\u062d\u0648 \u0627\u0644\u0639\u0631\u0628\u064a\", \"\u0627\u0644\u0628\u0644\u0627\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\", \"\u0627\u0644\u0623\u062f\u0628 \u0627\u0644\u0639\u0631\u0628\u064a\"]:\n",
        "                return \"\u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u060c \" + question.replace(\"\u0645\u0627 \u0647\u064a\", \"\").replace(\"\u0627\u0634\u0631\u062d\", \"\").replace(\"\u061f\", \"\") + \" \u0644\u0647\u0627 \u0642\u0648\u0627\u0639\u062f \u0648\u0623\u0633\u0633 \u0645\u0639\u064a\u0646\u0629 \u062a\u062f\u0631\u0633 \u0641\u064a \u0639\u0644\u0648\u0645 \u0627\u0644\u0644\u063a\u0629.\"\n",
        "            else:\n",
        "                return random.choice(modeles_reponses[2])\n",
        "        elif qualite == 3:\n",
        "            # R\u00e9ponses de qualit\u00e9 3 g\u00e9n\u00e9riques par th\u00e8me\n",
        "            reponses_theme = {\n",
        "                \"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645\": \"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u062e\u0645\u0633\u0629 \u0648\u0647\u064a: \u0627\u0644\u0634\u0647\u0627\u062f\u062a\u0627\u0646\u060c \u0648\u0625\u0642\u0627\u0645 \u0627\u0644\u0635\u0644\u0627\u0629\u060c \u0648\u0625\u064a\u062a\u0627\u0621 \u0627\u0644\u0632\u0643\u0627\u0629\u060c \u0648\u0635\u0648\u0645 \u0631\u0645\u0636\u0627\u0646\u060c \u0648\u062d\u062c \u0627\u0644\u0628\u064a\u062a \u0644\u0645\u0646 \u0627\u0633\u062a\u0637\u0627\u0639 \u0625\u0644\u064a\u0647 \u0633\u0628\u064a\u0644\u0627. \u0647\u0630\u0647 \u0627\u0644\u0623\u0631\u0643\u0627\u0646 \u0623\u0633\u0627\u0633\u064a\u0629 \u0644\u0643\u0644 \u0645\u0633\u0644\u0645 \u0648\u064a\u062c\u0628 \u0627\u0644\u0627\u0644\u062a\u0632\u0627\u0645 \u0628\u0647\u0627.\",\n",
        "                \"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u064a\u0645\u0627\u0646\": \"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u064a\u0645\u0627\u0646 \u0633\u062a\u0629 \u0648\u0647\u064a: \u0627\u0644\u0625\u064a\u0645\u0627\u0646 \u0628\u0627\u0644\u0644\u0647\u060c \u0648\u0645\u0644\u0627\u0626\u0643\u062a\u0647\u060c \u0648\u0643\u062a\u0628\u0647\u060c \u0648\u0631\u0633\u0644\u0647\u060c \u0648\u0627\u0644\u064a\u0648\u0645 \u0627\u0644\u0622\u062e\u0631\u060c \u0648\u0627\u0644\u0642\u062f\u0631 \u062e\u064a\u0631\u0647 \u0648\u0634\u0631\u0647. \u0648\u064a\u0639\u062a\u0628\u0631 \u0627\u0644\u0625\u064a\u0645\u0627\u0646 \u0628\u0647\u0627 \u062c\u0645\u064a\u0639\u064b\u0627 \u0636\u0631\u0648\u0631\u064a\u064b\u0627 \u0644\u0644\u0645\u0633\u0644\u0645.\",\n",
        "                \"\u0627\u0644\u0632\u0643\u0627\u0629\": \"\u0627\u0644\u0632\u0643\u0627\u0629 \u0647\u064a \u0627\u0644\u0631\u0643\u0646 \u0627\u0644\u062b\u0627\u0644\u062b \u0645\u0646 \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645\u060c \u0648\u0647\u064a \u0648\u0627\u062c\u0628\u0629 \u0639\u0644\u0649 \u0643\u0644 \u0645\u0633\u0644\u0645 \u064a\u0645\u0644\u0643 \u0646\u0635\u0627\u0628\u064b\u0627 \u0648\u062d\u0627\u0644 \u0639\u0644\u064a\u0647 \u0627\u0644\u062d\u0648\u0644. \u0646\u0633\u0628\u062a\u0647\u0627 2.5% \u0645\u0646 \u0627\u0644\u0645\u0627\u0644\u060c \u0648\u0644\u0647\u0627 \u062b\u0645\u0627\u0646\u064a\u0629 \u0645\u0635\u0627\u0631\u0641 \u0630\u0643\u0631\u062a \u0641\u064a \u0627\u0644\u0642\u0631\u0622\u0646 \u0627\u0644\u0643\u0631\u064a\u0645.\",\n",
        "                \"\u0627\u0644\u0635\u064a\u0627\u0645\": \"\u0627\u0644\u0635\u064a\u0627\u0645 \u0647\u0648 \u0627\u0644\u0627\u0645\u062a\u0646\u0627\u0639 \u0639\u0646 \u0627\u0644\u0645\u0641\u0637\u0631\u0627\u062a \u0645\u0646 \u0637\u0644\u0648\u0639 \u0627\u0644\u0641\u062c\u0631 \u0625\u0644\u0649 \u063a\u0631\u0648\u0628 \u0627\u0644\u0634\u0645\u0633 \u0628\u0646\u064a\u0629 \u0627\u0644\u062a\u0642\u0631\u0628 \u0625\u0644\u0649 \u0627\u0644\u0644\u0647. \u0648\u064a\u062c\u0628 \u0635\u064a\u0627\u0645 \u0634\u0647\u0631 \u0631\u0645\u0636\u0627\u0646 \u0639\u0644\u0649 \u0643\u0644 \u0645\u0633\u0644\u0645 \u0628\u0627\u0644\u063a \u0639\u0627\u0642\u0644 \u0642\u0627\u062f\u0631.\",\n",
        "                \"\u0627\u0644\u0646\u062d\u0648 \u0627\u0644\u0639\u0631\u0628\u064a\": \"\u0627\u0644\u0646\u062d\u0648 \u0627\u0644\u0639\u0631\u0628\u064a \u0647\u0648 \u0639\u0644\u0645 \u064a\u062f\u0631\u0633 \u0623\u062d\u0648\u0627\u0644 \u0623\u0648\u0627\u062e\u0631 \u0627\u0644\u0643\u0644\u0645\u0627\u062a \u0645\u0646 \u062d\u064a\u062b \u0627\u0644\u0625\u0639\u0631\u0627\u0628 \u0648\u0627\u0644\u0628\u0646\u0627\u0621. \u064a\u0646\u0642\u0633\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0625\u0644\u0649 \u0627\u0633\u0645 \u0648\u0641\u0639\u0644 \u0648\u062d\u0631\u0641\u060c \u0648\u0627\u0644\u0625\u0639\u0631\u0627\u0628 \u0625\u0644\u0649 \u0631\u0641\u0639 \u0648\u0646\u0635\u0628 \u0648\u062c\u0631 \u0648\u062c\u0632\u0645. \u0645\u0646 \u0623\u0647\u0645 \u0643\u062a\u0628\u0647: \u0643\u062a\u0627\u0628 \u0633\u064a\u0628\u0648\u064a\u0647 \u0648\u0623\u0644\u0641\u064a\u0629 \u0627\u0628\u0646 \u0645\u0627\u0644\u0643.\"\n",
        "            }\n",
        "\n",
        "            if theme in reponses_theme:\n",
        "                return reponses_theme[theme]\n",
        "            else:\n",
        "                return random.choice(modeles_reponses[3])\n",
        "        else:  # qualite == 4\n",
        "            # R\u00e9ponses excellentes g\u00e9n\u00e9riques par th\u00e8me\n",
        "            reponses_excellentes = {\n",
        "                \"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645\": \"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u062e\u0645\u0633\u0629 \u0643\u0645\u0627 \u0648\u0631\u062f\u062a \u0641\u064a \u062d\u062f\u064a\u062b \u0627\u0644\u0646\u0628\u064a \u0635\u0644\u0649 \u0627\u0644\u0644\u0647 \u0639\u0644\u064a\u0647 \u0648\u0633\u0644\u0645: \u0634\u0647\u0627\u062f\u0629 \u0623\u0646 \u0644\u0627 \u0625\u0644\u0647 \u0625\u0644\u0627 \u0627\u0644\u0644\u0647 \u0648\u0623\u0646 \u0645\u062d\u0645\u062f\u064b\u0627 \u0631\u0633\u0648\u0644 \u0627\u0644\u0644\u0647\u060c \u0648\u0647\u064a \u0623\u0633\u0627\u0633 \u0627\u0644\u062f\u064a\u0646 \u0648\u0628\u0648\u0627\u0628\u0629 \u0627\u0644\u062f\u062e\u0648\u0644 \u0625\u0644\u0649 \u0627\u0644\u0625\u0633\u0644\u0627\u0645. \u0648\u0625\u0642\u0627\u0645 \u0627\u0644\u0635\u0644\u0627\u0629\u060c \u0648\u0647\u064a \u0639\u0645\u0648\u062f \u0627\u0644\u062f\u064a\u0646 \u0648\u062a\u0642\u0627\u0645 \u062e\u0645\u0633 \u0645\u0631\u0627\u062a \u0641\u064a \u0627\u0644\u064a\u0648\u0645 \u0648\u0627\u0644\u0644\u064a\u0644\u0629 \u0643\u0635\u0644\u0629 \u0628\u064a\u0646 \u0627\u0644\u0639\u0628\u062f \u0648\u0631\u0628\u0647. \u0648\u0625\u064a\u062a\u0627\u0621 \u0627\u0644\u0632\u0643\u0627\u0629\u060c \u0648\u0647\u064a \u062d\u0642 \u0627\u0644\u0645\u0627\u0644 \u0648\u062a\u0637\u0647\u064a\u0631 \u0644\u0647 \u0648\u062a\u0643\u0627\u0641\u0644 \u0628\u064a\u0646 \u0623\u0641\u0631\u0627\u062f \u0627\u0644\u0645\u062c\u062a\u0645\u0639 \u0627\u0644\u0645\u0633\u0644\u0645. \u0648\u0635\u0648\u0645 \u0631\u0645\u0636\u0627\u0646\u060c \u0648\u0647\u0648 \u0627\u0645\u062a\u0646\u0627\u0639 \u0639\u0646 \u0627\u0644\u0645\u0641\u0637\u0631\u0627\u062a \u0645\u0646 \u0637\u0644\u0648\u0639 \u0627\u0644\u0641\u062c\u0631 \u0625\u0644\u0649 \u063a\u0631\u0648\u0628 \u0627\u0644\u0634\u0645\u0633 \u0637\u0648\u0627\u0644 \u0634\u0647\u0631 \u0631\u0645\u0636\u0627\u0646 \u062a\u0642\u0631\u0628\u064b\u0627 \u0625\u0644\u0649 \u0627\u0644\u0644\u0647 \u0648\u062a\u0639\u0648\u064a\u062f\u064b\u0627 \u0644\u0644\u0646\u0641\u0633 \u0639\u0644\u0649 \u0627\u0644\u0635\u0628\u0631. \u0648\u062d\u062c \u0627\u0644\u0628\u064a\u062a \u0644\u0645\u0646 \u0627\u0633\u062a\u0637\u0627\u0639 \u0625\u0644\u064a\u0647 \u0633\u0628\u064a\u0644\u0627\u060c \u0648\u0647\u0648 \u0632\u064a\u0627\u0631\u0629 \u0627\u0644\u0628\u064a\u062a \u0627\u0644\u062d\u0631\u0627\u0645 \u0641\u064a \u0645\u0643\u0629 \u0627\u0644\u0645\u0643\u0631\u0645\u0629 \u0644\u0623\u062f\u0627\u0621 \u0645\u0646\u0627\u0633\u0643 \u0645\u0639\u064a\u0646\u0629 \u0641\u064a \u0623\u0648\u0642\u0627\u062a \u0645\u062d\u062f\u062f\u0629 \u0645\u0631\u0629 \u0648\u0627\u062d\u062f\u0629 \u0641\u064a \u0627\u0644\u0639\u0645\u0631 \u0644\u0645\u0646 \u062a\u0648\u0641\u0631\u062a \u0641\u064a\u0647 \u0634\u0631\u0648\u0637 \u0627\u0644\u0627\u0633\u062a\u0637\u0627\u0639\u0629.\",\n",
        "                \"\u0627\u0644\u0646\u062d\u0648 \u0627\u0644\u0639\u0631\u0628\u064a\": \"\u0627\u0644\u0646\u062d\u0648 \u0627\u0644\u0639\u0631\u0628\u064a \u0647\u0648 \u0639\u0644\u0645 \u064a\u0628\u062d\u062b \u0641\u064a \u0623\u062d\u0648\u0627\u0644 \u0623\u0648\u0627\u062e\u0631 \u0627\u0644\u0643\u0644\u0645 \u0625\u0639\u0631\u0627\u0628\u064b\u0627 \u0648\u0628\u0646\u0627\u0621\u064b\u060c \u0648\u064a\u0639\u062f \u0645\u0646 \u0623\u0647\u0645 \u0639\u0644\u0648\u0645 \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629. \u0646\u0634\u0623 \u0641\u064a \u0627\u0644\u0642\u0631\u0646 \u0627\u0644\u0623\u0648\u0644 \u0627\u0644\u0647\u062c\u0631\u064a \u0639\u0644\u0649 \u064a\u062f \u0623\u0628\u064a \u0627\u0644\u0623\u0633\u0648\u062f \u0627\u0644\u062f\u0624\u0644\u064a \u0628\u062a\u0648\u062c\u064a\u0647 \u0645\u0646 \u0627\u0644\u0625\u0645\u0627\u0645 \u0639\u0644\u064a \u0631\u0636\u064a \u0627\u0644\u0644\u0647 \u0639\u0646\u0647 \u0644\u0644\u062d\u0641\u0627\u0638 \u0639\u0644\u0649 \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0645\u0646 \u0627\u0644\u0644\u062d\u0646. \u064a\u0646\u0642\u0633\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0625\u0644\u0649 \u062b\u0644\u0627\u062b\u0629 \u0623\u0642\u0633\u0627\u0645: \u0627\u0644\u0627\u0633\u0645 \u0648\u0639\u0644\u0627\u0645\u062a\u0647 \u0642\u0628\u0648\u0644 \u0627\u0644\u062c\u0631 \u0648\u0627\u0644\u062a\u0646\u0648\u064a\u0646 \u0648\u0623\u0644 (\u0645\u062b\u0644: \u0643\u062a\u0627\u0628\u060c \u0645\u062f\u0631\u0633\u0629)\u060c \u0648\u0627\u0644\u0641\u0639\u0644 \u0648\u064a\u0646\u0642\u0633\u0645 \u0625\u0644\u0649 \u0645\u0627\u0636\u064d \u0648\u0645\u0636\u0627\u0631\u0639 \u0648\u0623\u0645\u0631 (\u0645\u062b\u0644: \u0643\u064e\u062a\u064e\u0628\u064e\u060c \u064a\u064e\u0643\u0652\u062a\u064f\u0628\u064f\u060c \u0627\u064f\u0643\u0652\u062a\u064f\u0628\u0652)\u060c \u0648\u0627\u0644\u062d\u0631\u0641 \u0648\u0647\u0648 \u0645\u0627 \u0644\u0627 \u064a\u0642\u0628\u0644 \u0639\u0644\u0627\u0645\u0627\u062a \u0627\u0644\u0627\u0633\u0645 \u0648\u0644\u0627 \u0627\u0644\u0641\u0639\u0644 (\u0645\u062b\u0644: \u0641\u064a\u060c \u0639\u0644\u0649\u060c \u0644\u0645). \u0623\u0645\u0627 \u0627\u0644\u0625\u0639\u0631\u0627\u0628 \u0641\u064a\u0646\u0642\u0633\u0645 \u0625\u0644\u0649: \u0627\u0644\u0631\u0641\u0639 \u0648\u0639\u0644\u0627\u0645\u062a\u0647 \u0627\u0644\u0623\u0635\u0644\u064a\u0629 \u0627\u0644\u0636\u0645\u0629\u060c \u0648\u0627\u0644\u0646\u0635\u0628 \u0648\u0639\u0644\u0627\u0645\u062a\u0647 \u0627\u0644\u0623\u0635\u0644\u064a\u0629 \u0627\u0644\u0641\u062a\u062d\u0629\u060c \u0648\u0627\u0644\u062c\u0631 \u0648\u0639\u0644\u0627\u0645\u062a\u0647 \u0627\u0644\u0623\u0635\u0644\u064a\u0629 \u0627\u0644\u0643\u0633\u0631\u0629\u060c \u0648\u0627\u0644\u062c\u0632\u0645 \u0648\u0639\u0644\u0627\u0645\u062a\u0647 \u0627\u0644\u0623\u0635\u0644\u064a\u0629 \u0627\u0644\u0633\u0643\u0648\u0646. \u0648\u0645\u0646 \u0623\u0634\u0647\u0631 \u0645\u0624\u0644\u0641\u0627\u062a \u0627\u0644\u0646\u062d\u0648: \u0643\u062a\u0627\u0628 \u0633\u064a\u0628\u0648\u064a\u0647\u060c \u0648\u0623\u0644\u0641\u064a\u0629 \u0627\u0628\u0646 \u0645\u0627\u0644\u0643\u060c \u0648\u0645\u063a\u0646\u064a \u0627\u0644\u0644\u0628\u064a\u0628 \u0644\u0627\u0628\u0646 \u0647\u0634\u0627\u0645.\"\n",
        "            }\n",
        "\n",
        "            if theme in reponses_excellentes:\n",
        "                return reponses_excellentes[theme]\n",
        "            else:\n",
        "                return random.choice(modeles_reponses[4])\n",
        "\n",
        "    # G\u00e9n\u00e9rer les exemples\n",
        "    questions = []\n",
        "    reponses = []\n",
        "    notes = []\n",
        "\n",
        "    # S'assurer d'une r\u00e9partition \u00e9quilibr\u00e9e des notes\n",
        "    notes_a_generer = {0: nb_exemples//5, 1: nb_exemples//5, 2: nb_exemples//5, 3: nb_exemples//5, 4: nb_exemples//5}\n",
        "\n",
        "    # Ajuster pour s'assurer que le total est correct\n",
        "    total = sum(notes_a_generer.values())\n",
        "    if total < nb_exemples:\n",
        "        notes_a_generer[4] += nb_exemples - total\n",
        "\n",
        "    # G\u00e9n\u00e9rer les exemples pour chaque qualit\u00e9 de r\u00e9ponse\n",
        "    for qualite in range(5):\n",
        "        for _ in range(notes_a_generer[qualite]):\n",
        "            # S\u00e9lectionner un th\u00e8me al\u00e9atoire\n",
        "            theme = random.choice(tous_themes)\n",
        "\n",
        "            # S'assurer que le th\u00e8me a des questions d\u00e9finies\n",
        "            while theme not in questions_par_theme:\n",
        "                theme = random.choice(tous_themes)\n",
        "\n",
        "            # S\u00e9lectionner une question al\u00e9atoire pour ce th\u00e8me\n",
        "            question = random.choice(questions_par_theme[theme])\n",
        "\n",
        "            # G\u00e9n\u00e9rer la r\u00e9ponse correspondant \u00e0 la qualit\u00e9\n",
        "            reponse = generer_reponse(theme, question, qualite)\n",
        "\n",
        "            questions.append(question)\n",
        "            reponses.append(reponse)\n",
        "            notes.append(qualite)\n",
        "\n",
        "    # M\u00e9langer les donn\u00e9es pour \u00e9viter les biais d'ordre\n",
        "    donnees_combinees = list(zip(questions, reponses, notes))\n",
        "    random.shuffle(donnees_combinees)\n",
        "    questions, reponses, notes = zip(*donnees_combinees)\n",
        "\n",
        "    # Convertir en listes\n",
        "    questions = list(questions)\n",
        "    reponses = list(reponses)\n",
        "    notes = list(notes)\n",
        "\n",
        "    return questions, reponses, notes\n",
        "\n",
        "# 3. Augmentation des donn\u00e9es\n",
        "# --------------------------\n",
        "\n",
        "def augmenter_donnees_ameliore(questions, reponses, notes):\n",
        "    \"\"\"\n",
        "    Version am\u00e9lior\u00e9e de l'augmentation de donn\u00e9es avec plus de techniques\n",
        "\n",
        "    Args:\n",
        "        questions (list): Liste des questions originales\n",
        "        reponses (list): Liste des r\u00e9ponses originales\n",
        "        notes (list): Liste des notes originales (0-4)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (questions_augmentees, reponses_augmentees, notes_augmentees)\n",
        "    \"\"\"\n",
        "    questions_augmentees = questions.copy()\n",
        "    reponses_augmentees = reponses.copy()\n",
        "    notes_augmentees = notes.copy()\n",
        "\n",
        "    # Facteur d'augmentation: ajouter 100% plus d'exemples\n",
        "    nb_exemples_originaux = len(questions)\n",
        "    nb_exemples_a_ajouter = nb_exemples_originaux\n",
        "\n",
        "    # 1. Variantes de formulation pour les questions\n",
        "    prefixes_questions = [\n",
        "        \"\u0647\u0644 \u064a\u0645\u0643\u0646\u0643 \u0634\u0631\u062d \",\n",
        "        \"\u0623\u0631\u064a\u062f \u0645\u0639\u0631\u0641\u0629 \",\n",
        "        \"\u0627\u0634\u0631\u062d \u0628\u0627\u0644\u062a\u0641\u0635\u064a\u0644 \",\n",
        "        \"\u062a\u062d\u062f\u062b \u0639\u0646 \",\n",
        "        \"\u0645\u0627 \u0631\u0623\u064a\u0643 \u0641\u064a \",\n",
        "        \"\u0645\u0627 \u0645\u0639\u0646\u0649 \",\n",
        "        \"\u0643\u064a\u0641 \u062a\u0641\u0633\u0631 \",\n",
        "        \"\u0648\u0636\u062d \u0644\u064a \",\n",
        "        \"\u0645\u0627 \u0627\u0644\u0645\u0642\u0635\u0648\u062f \u0628\u0640 \"\n",
        "    ]\n",
        "\n",
        "    suffixes_questions = [\n",
        "        \" \u0628\u0634\u0643\u0644 \u0645\u0641\u0635\u0644\u061f\",\n",
        "        \" \u0628\u0627\u062e\u062a\u0635\u0627\u0631\u061f\",\n",
        "        \" \u0645\u0639 \u0630\u0643\u0631 \u0627\u0644\u0623\u0645\u062b\u0644\u0629\u061f\",\n",
        "        \" \u0645\u0646 \u0648\u062c\u0647\u0629 \u0646\u0638\u0631 \u0625\u0633\u0644\u0627\u0645\u064a\u0629\u061f\",\n",
        "        \" \u0641\u064a \u0636\u0648\u0621 \u0627\u0644\u0645\u0635\u0627\u062f\u0631 \u0627\u0644\u0645\u0639\u062a\u0645\u062f\u0629\u061f\",\n",
        "        \" \u0645\u0639 \u0630\u0643\u0631 \u0627\u0644\u062f\u0644\u064a\u0644\u061f\",\n",
        "        \" \u0628\u0623\u0633\u0644\u0648\u0628\u0643 \u0627\u0644\u062e\u0627\u0635\u061f\",\n",
        "        \" \u0648\u0644\u0645\u0627\u0630\u0627\u061f\",\n",
        "        \" \u0648\u0645\u0627 \u0623\u0647\u0645\u064a\u062a\u0647\u061f\"\n",
        "    ]\n",
        "\n",
        "    # 2. Substitution de mots pour les r\u00e9ponses (synonymes simples)\n",
        "    substitutions_mots = {\n",
        "        \"\u0645\u0647\u0645\": [\"\u0636\u0631\u0648\u0631\u064a\", \"\u0623\u0633\u0627\u0633\u064a\", \"\u062c\u0648\u0647\u0631\u064a\"],\n",
        "        \"\u0643\u0628\u064a\u0631\": [\"\u0639\u0638\u064a\u0645\", \"\u0636\u062e\u0645\", \"\u0648\u0627\u0633\u0639\"],\n",
        "        \"\u062c\u064a\u062f\": [\"\u0645\u0645\u062a\u0627\u0632\", \"\u0631\u0627\u0626\u0639\", \"\u062c\u0645\u064a\u0644\"],\n",
        "        \"\u0642\u0627\u0644\": [\"\u0630\u0643\u0631\", \"\u0623\u0641\u0627\u062f\", \"\u0623\u0648\u0636\u062d\"],\n",
        "        \"\u064a\u062c\u0628\": [\"\u064a\u0646\u0628\u063a\u064a\", \"\u0644\u0627 \u0628\u062f\", \"\u0645\u0646 \u0627\u0644\u0636\u0631\u0648\u0631\u064a\"],\n",
        "        \"\u0643\u062b\u064a\u0631\": [\"\u0639\u062f\u064a\u062f\", \"\u0648\u0641\u064a\u0631\", \"\u063a\u0632\u064a\u0631\"],\n",
        "        \"\u0645\u0641\u0647\u0648\u0645\": [\"\u0645\u0639\u0646\u0649\", \"\u062a\u0639\u0631\u064a\u0641\", \"\u0645\u0635\u0637\u0644\u062d\"]\n",
        "    }\n",
        "\n",
        "    # 3. Techniques d'augmentation\n",
        "    techniques = [\n",
        "        \"reformuler_question\",  # Reformuler la question\n",
        "        \"modifier_reponse\",     # Modifier l\u00e9g\u00e8rement la r\u00e9ponse\n",
        "        \"combiner_exemples\"     # Combiner des exemples de m\u00eame niveau\n",
        "    ]\n",
        "\n",
        "    # Fonction pour appliquer des substitutions al\u00e9atoires\n",
        "    def appliquer_substitutions(texte):\n",
        "        mots = texte.split()\n",
        "        for i, mot in enumerate(mots):\n",
        "            # Suppression des signes de ponctuation pour la correspondance\n",
        "            mot_clean = mot.strip(\"\u060c.\u061f!:;\")\n",
        "            if mot_clean in substitutions_mots and random.random() < 0.3:  # 30% de chance\n",
        "                mots[i] = mot.replace(mot_clean, random.choice(substitutions_mots[mot_clean]))\n",
        "        return \" \".join(mots)\n",
        "\n",
        "    # Fonction pour combiner deux r\u00e9ponses de m\u00eame niveau\n",
        "    def combiner_reponses(reponse1, reponse2):\n",
        "        # Prendre la premi\u00e8re moiti\u00e9 de la premi\u00e8re r\u00e9ponse\n",
        "        moitie1 = reponse1.split()\n",
        "        point_milieu1 = len(moitie1) // 2\n",
        "\n",
        "        # Et la deuxi\u00e8me moiti\u00e9 de la deuxi\u00e8me r\u00e9ponse\n",
        "        moitie2 = reponse2.split()\n",
        "        point_milieu2 = len(moitie2) // 2\n",
        "\n",
        "        # Combiner les deux moiti\u00e9s avec une phrase de transition\n",
        "        phrases_transition = [\n",
        "            \" \u0648\u0628\u0627\u0644\u0625\u0636\u0627\u0641\u0629 \u0625\u0644\u0649 \u0630\u0644\u0643\u060c \",\n",
        "            \" \u0648\u0639\u0644\u0627\u0648\u0629 \u0639\u0644\u0649 \u0630\u0644\u0643\u060c \",\n",
        "            \" \u0648\u0645\u0646 \u062c\u0647\u0629 \u0623\u062e\u0631\u0649\u060c \",\n",
        "            \" \u0648\u0643\u0630\u0644\u0643\u060c \",\n",
        "            \" \u0648\u0623\u064a\u0636\u0627\u064b\u060c \"\n",
        "        ]\n",
        "\n",
        "        combinaison = \" \".join(moitie1[:point_milieu1]) + random.choice(phrases_transition) + \" \".join(moitie2[point_milieu2:])\n",
        "        return combinaison\n",
        "\n",
        "    # Pour chaque exemple \u00e0 ajouter\n",
        "    indices_utilises = set()\n",
        "    for i in range(nb_exemples_a_ajouter):\n",
        "        # S\u00e9lectionner une technique al\u00e9atoire\n",
        "        technique = random.choice(techniques)\n",
        "\n",
        "        if technique == \"reformuler_question\":\n",
        "            # S\u00e9lectionner un exemple al\u00e9atoire\n",
        "            idx = random.randint(0, nb_exemples_originaux - 1)\n",
        "            question_orig = questions[idx]\n",
        "\n",
        "            # Reformuler la question\n",
        "            if random.random() < 0.5:  # 50% du temps ajouter un pr\u00e9fixe\n",
        "                nouvelle_question = random.choice(prefixes_questions) + question_orig.replace(\"\u0645\u0627 \u0647\u064a \", \"\").replace(\"\u0627\u0634\u0631\u062d \", \"\").replace(\"\u061f\", \"\")\n",
        "            else:  # 50% du temps ajouter un suffixe\n",
        "                nouvelle_question = question_orig.replace(\"\u061f\", \"\") + random.choice(suffixes_questions)\n",
        "\n",
        "            # Ajouter l'exemple augment\u00e9\n",
        "            questions_augmentees.append(nouvelle_question)\n",
        "            reponses_augmentees.append(reponses[idx])\n",
        "            notes_augmentees.append(notes[idx])\n",
        "            indices_utilises.add(idx)\n",
        "\n",
        "        elif technique == \"modifier_reponse\":\n",
        "            # S\u00e9lectionner un exemple al\u00e9atoire non utilis\u00e9 si possible\n",
        "            candidats = [j for j in range(nb_exemples_originaux) if j not in indices_utilises]\n",
        "            if not candidats:  # Si tous ont \u00e9t\u00e9 utilis\u00e9s, prendre n'importe lequel\n",
        "                candidats = list(range(nb_exemples_originaux))\n",
        "\n",
        "            idx = random.choice(candidats)\n",
        "\n",
        "            # Appliquer des substitutions \u00e0 la r\u00e9ponse\n",
        "            nouvelle_reponse = appliquer_substitutions(reponses[idx])\n",
        "\n",
        "            # Ajouter l'exemple augment\u00e9\n",
        "            questions_augmentees.append(questions[idx])\n",
        "            reponses_augmentees.append(nouvelle_reponse)\n",
        "            notes_augmentees.append(notes[idx])\n",
        "            indices_utilises.add(idx)\n",
        "\n",
        "        elif technique == \"combiner_exemples\":\n",
        "            # Trouver des paires d'exemples avec la m\u00eame note\n",
        "            exemples_par_note = {}\n",
        "            for j in range(nb_exemples_originaux):\n",
        "                note = notes[j]\n",
        "                if note not in exemples_par_note:\n",
        "                    exemples_par_note[note] = []\n",
        "                exemples_par_note[note].append(j)\n",
        "\n",
        "            # Choisir une note qui a au moins deux exemples\n",
        "            notes_disponibles = [n for n in exemples_par_note if len(exemples_par_note[n]) >= 2]\n",
        "            if not notes_disponibles:\n",
        "                continue  # Passer \u00e0 la prochaine it\u00e9ration si pas d'option viable\n",
        "\n",
        "            note_choisie = random.choice(notes_disponibles)\n",
        "\n",
        "            # Choisir deux exemples al\u00e9atoires avec cette note\n",
        "            idx1, idx2 = random.sample(exemples_par_note[note_choisie], 2)\n",
        "\n",
        "            # Combiner les r\u00e9ponses\n",
        "            reponse_combinee = combiner_reponses(reponses[idx1], reponses[idx2])\n",
        "\n",
        "            # Ajouter l'exemple augment\u00e9 (utiliser la question de idx1)\n",
        "            questions_augmentees.append(questions[idx1])\n",
        "            reponses_augmentees.append(reponse_combinee)\n",
        "            notes_augmentees.append(notes[idx1])\n",
        "            indices_utilises.add(idx1)\n",
        "            indices_utilises.add(idx2)\n",
        "\n",
        "    # Retourner les donn\u00e9es augment\u00e9es\n",
        "    return questions_augmentees, reponses_augmentees, notes_augmentees\n",
        "\n",
        "# 4. Fonction pour adapter la sortie de T5 (conversion de texte en note num\u00e9rique)\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def convert_t5_output_to_grade(prediction, tokenizer):\n",
        "    \"\"\"\n",
        "    Convertit la sortie du mod\u00e8le T5 en note num\u00e9rique\n",
        "\n",
        "    Args:\n",
        "        prediction: La pr\u00e9diction brute du mod\u00e8le\n",
        "        tokenizer: Le tokenizer utilis\u00e9\n",
        "\n",
        "    Returns:\n",
        "        int: La note pr\u00e9dite (1-5)\n",
        "    \"\"\"\n",
        "    decoded_prediction = tokenizer.decode(prediction, skip_special_tokens=True)\n",
        "\n",
        "    # Essayer de convertir en entier (note de 1 \u00e0 5)\n",
        "    try:\n",
        "        grade = int(decoded_prediction.strip())\n",
        "        # S'assurer que la note est bien dans l'intervalle 1-5\n",
        "        if grade < 1:\n",
        "            grade = 1\n",
        "        elif grade > 5:\n",
        "            grade = 5\n",
        "    except:\n",
        "        # Si la conversion \u00e9choue, attribuer la note moyenne\n",
        "        grade = 3\n",
        "\n",
        "    return grade\n",
        "\n",
        "# 5. Fonction d'\u00e9valuation d\u00e9taill\u00e9e pour AraT5\n",
        "# -------------------------------------------\n",
        "\n",
        "def evaluate_arat5(model, dataloader, tokenizer, device):\n",
        "    \"\"\"\n",
        "    \u00c9value le mod\u00e8le AraT5 sur un jeu de donn\u00e9es\n",
        "\n",
        "    Args:\n",
        "        model: Le mod\u00e8le \u00e0 \u00e9valuer\n",
        "        dataloader: Le chargeur de donn\u00e9es\n",
        "        tokenizer: Le tokenizer utilis\u00e9\n",
        "        device: L'appareil de calcul (CPU/GPU)\n",
        "\n",
        "    Returns:\n",
        "        dict: Les m\u00e9triques d'\u00e9valuation\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # G\u00e9n\u00e9rer les pr\u00e9dictions\n",
        "            predictions = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=10\n",
        "            )\n",
        "\n",
        "            # Convertir les pr\u00e9dictions et les labels en notes num\u00e9riques\n",
        "            for pred, lab in zip(predictions, labels):\n",
        "                # Supprimer les valeurs -100 des labels et d\u00e9coder\n",
        "                label_ids = lab.clone()\n",
        "                label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "                decoded_label = tokenizer.decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "                try:\n",
        "                    true_grade = int(decoded_label.strip())\n",
        "                    # Ajuster \u00e0 l'intervalle 0-4 pour les m\u00e9triques\n",
        "                    true_grade = max(1, min(true_grade, 5)) - 1\n",
        "                except:\n",
        "                    # Si la conversion \u00e9choue, ignorer cet exemple\n",
        "                    continue\n",
        "\n",
        "                pred_grade = convert_t5_output_to_grade(pred, tokenizer) - 1  # Ajuster \u00e0 0-4\n",
        "\n",
        "                all_preds.append(pred_grade)\n",
        "                all_labels.append(true_grade)\n",
        "\n",
        "    if len(all_preds) == 0:\n",
        "        return {\n",
        "            \"loss\": total_loss / len(dataloader) if len(dataloader) > 0 else 0,\n",
        "            \"accuracy\": 0,\n",
        "            \"kappa\": 0,\n",
        "            \"confusion_matrix\": np.zeros((5, 5)),\n",
        "            \"mae\": 0\n",
        "        }\n",
        "\n",
        "    # Calcul de l'exactitude\n",
        "    accuracy = sum(1 for p, l in zip(all_preds, all_labels) if p == l) / len(all_preds)\n",
        "\n",
        "    # Calcul du Kappa de Cohen\n",
        "    kappa = cohen_kappa_score(all_labels, all_preds)\n",
        "\n",
        "    # Matrice de confusion\n",
        "    conf_matrix = confusion_matrix(all_labels, all_preds, labels=range(5))\n",
        "\n",
        "    # \u00c9cart moyen absolu\n",
        "    mae = sum(abs(p - l) for p, l in zip(all_preds, all_labels)) / len(all_preds)\n",
        "\n",
        "    return {\n",
        "        \"loss\": total_loss / len(dataloader),\n",
        "        \"accuracy\": accuracy,\n",
        "        \"kappa\": kappa,\n",
        "        \"confusion_matrix\": conf_matrix,\n",
        "        \"mae\": mae\n",
        "    }\n",
        "\n",
        "# 6. Fonction principale pour l'entra\u00eenement du mod\u00e8le AraT5\n",
        "# --------------------------------------------------------\n",
        "\n",
        "def entrainer_arat5_model(nb_exemples=3000, batch_size=4, num_epochs=15,\n",
        "                        learning_rate=3e-5, warmup_ratio=0.1,\n",
        "                        patience=5, max_length=256, gradient_accumulation_steps=4):\n",
        "    \"\"\"\n",
        "    Fonction am\u00e9lior\u00e9e pour entra\u00eener le mod\u00e8le AraT5 avec de meilleures performances\n",
        "\n",
        "    Args:\n",
        "        nb_exemples (int): Nombre d'exemples \u00e0 g\u00e9n\u00e9rer pour l'entra\u00eenement\n",
        "        batch_size (int): Taille du batch pour le chargement des donn\u00e9es\n",
        "        num_epochs (int): Nombre maximal d'\u00e9poques d'entra\u00eenement\n",
        "        learning_rate (float): Taux d'apprentissage initial\n",
        "        warmup_ratio (float): Ratio d'\u00e9chauffement du scheduler\n",
        "        patience (int): Nombre d'\u00e9poques sans am\u00e9lioration avant l'arr\u00eat pr\u00e9coce\n",
        "        max_length (int): Longueur maximale des s\u00e9quences\n",
        "        gradient_accumulation_steps (int): Nombre d'\u00e9tapes pour l'accumulation de gradient\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, tokenizer, best_val_acc, history)\n",
        "    \"\"\"\n",
        "    print(\"Chargement du tokenizer et du mod\u00e8le AraT5...\")\n",
        "    # Utiliser le mod\u00e8le AraT5 pour la notation\n",
        "    model_name = \"UBC-NLP/AraT5-base\"\n",
        "    # Utiliser explicitement la version slow du tokenizer pour \u00e9viter les erreurs avec le tokenizer fast\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "    # 1. Cr\u00e9ation de donn\u00e9es de meilleure qualit\u00e9\n",
        "    print(f\"Cr\u00e9ation des donn\u00e9es d'entra\u00eenement avec th\u00e8mes islamiques et arabes ({nb_exemples} exemples)...\")\n",
        "    questions, reponses, notes = creer_donnees_islamique_arabe(nb_exemples)\n",
        "\n",
        "    # 2. Augmentation des donn\u00e9es plus diversifi\u00e9e\n",
        "    print(\"Augmentation des donn\u00e9es...\")\n",
        "    questions_aug, reponses_aug, notes_aug = augmenter_donnees_ameliore(questions, reponses, notes)\n",
        "\n",
        "    # 3. Division stratifi\u00e9e des donn\u00e9es avec validation crois\u00e9e\n",
        "    print(\"Division des donn\u00e9es en ensembles d'entra\u00eenement, validation et test...\")\n",
        "    # R\u00e9servation d'un ensemble de test (10%)\n",
        "    q_temp, q_test, r_temp, r_test, n_temp, n_test = train_test_split(\n",
        "        questions_aug, reponses_aug, notes_aug,\n",
        "        test_size=0.1, random_state=42, stratify=notes_aug\n",
        "    )\n",
        "\n",
        "    # Division entra\u00eenement/validation (80%/20% des donn\u00e9es restantes)\n",
        "    q_train, q_val, r_train, r_val, n_train, n_val = train_test_split(\n",
        "        q_temp, r_temp, n_temp,\n",
        "        test_size=0.2, random_state=42, stratify=n_temp\n",
        "    )\n",
        "\n",
        "    print(f\"R\u00e9partition des notes dans l'ensemble d'entra\u00eenement:\")\n",
        "    for note in range(5):\n",
        "        count = n_train.count(note)\n",
        "        print(f\"Note {note+1}/5: {count} exemples ({count/len(n_train)*100:.1f}%)\")\n",
        "\n",
        "    # 4. Cr\u00e9ation des datasets\n",
        "    train_dataset = AraT5NotationDataset(q_train, r_train, n_train, tokenizer, max_length=max_length)\n",
        "    val_dataset = AraT5NotationDataset(q_val, r_val, n_val, tokenizer, max_length=max_length)\n",
        "    test_dataset = AraT5NotationDataset(q_test, r_test, n_test, tokenizer, max_length=max_length)\n",
        "\n",
        "    # 5. Cr\u00e9ation des dataloaders (utilisons num_workers=0 pour \u00e9viter d'\u00e9ventuels probl\u00e8mes multiprocessing)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=0)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=0)\n",
        "\n",
        "    # 6. Configuration de l'optimiseur avec un meilleur learning rate\n",
        "    # Utilisation du regroupement des param\u00e8tres pour un training efficace\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": 0.01,\n",
        "        },\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": 0.0,\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "\n",
        "    # 7. Configuration du scheduler avec warmup\n",
        "    total_steps = len(train_loader) * num_epochs // gradient_accumulation_steps\n",
        "    warmup_steps = int(total_steps * warmup_ratio)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=warmup_steps,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    # 8. D\u00e9placer le mod\u00e8le sur GPU si disponible\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Utilisation de l'appareil: {device}\")\n",
        "    model.to(device)\n",
        "\n",
        "    # 9. Entra\u00eenement avec early stopping et accumulation de gradient\n",
        "    best_val_acc = 0\n",
        "    patience_counter = 0\n",
        "    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": [], \"val_kappa\": [], \"val_mae\": []}\n",
        "\n",
        "    print(f\"D\u00e9but de l'entra\u00eenement pour {num_epochs} \u00e9poques maximum...\")\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\u00c9poque {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        # Phase d'entra\u00eenement\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=\"Training\")\n",
        "        optimizer.zero_grad()  # R\u00e9initialiser les gradients au d\u00e9but de l'\u00e9poque\n",
        "\n",
        "        for step, batch in enumerate(progress_bar):\n",
        "            # D\u00e9placer les tenseurs vers le GPU\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "\n",
        "            loss = outputs.loss\n",
        "\n",
        "            # Normaliser la perte en fonction des \u00e9tapes d'accumulation\n",
        "            loss = loss / gradient_accumulation_steps\n",
        "            loss.backward()\n",
        "\n",
        "            total_train_loss += loss.item() * gradient_accumulation_steps\n",
        "\n",
        "            # Mise \u00e0 jour des param\u00e8tres apr\u00e8s accumulation du gradient\n",
        "            if (step + 1) % gradient_accumulation_steps == 0:\n",
        "                # Clip gradient norm pour \u00e9viter l'explosion des gradients\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "                # Mise \u00e0 jour des poids et du scheduler\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            # Mettre \u00e0 jour la barre de progression\n",
        "            progress_bar.set_postfix({\n",
        "                'loss': total_train_loss / (progress_bar.n + 1),\n",
        "                'lr': scheduler.get_last_lr()[0]\n",
        "            })\n",
        "\n",
        "        # S'assurer que tous les gradients sont mis \u00e0 jour m\u00eame si le dernier batch est incomplet\n",
        "        if len(train_loader) % gradient_accumulation_steps != 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        history[\"train_loss\"].append(avg_train_loss)\n",
        "\n",
        "        print(f\"Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Phase d'\u00e9valuation\n",
        "        eval_results = evaluate_arat5(model, val_loader, tokenizer, device)\n",
        "        val_loss = eval_results[\"loss\"]\n",
        "        val_acc = eval_results[\"accuracy\"]\n",
        "        val_kappa = eval_results[\"kappa\"]\n",
        "        val_mae = eval_results[\"mae\"]\n",
        "\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        history[\"val_kappa\"].append(val_kappa)\n",
        "        history[\"val_mae\"].append(val_mae)\n",
        "\n",
        "        print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
        "        print(f\"Kappa: {val_kappa:.4f}, MAE: {val_mae:.4f}\")\n",
        "        print(\"Matrice de confusion:\")\n",
        "        print(eval_results[\"confusion_matrix\"])\n",
        "\n",
        "        # Sauvegarder le meilleur mod\u00e8le (bas\u00e9 sur pr\u00e9cision)\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            # Sauvegarder le mod\u00e8le entier plut\u00f4t que juste les state_dict\n",
        "            model.save_pretrained(\"best_arat5_model\")\n",
        "            tokenizer.save_pretrained(\"best_arat5_model\")\n",
        "            print(f\"Meilleur mod\u00e8le sauvegard\u00e9! Accuracy: {val_acc:.4f}\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping apr\u00e8s {epoch+1} \u00e9poques\")\n",
        "            break\n",
        "\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Charger le meilleur mod\u00e8le pour l'\u00e9valuation finale\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"best_arat5_model\")\n",
        "    model.to(device)\n",
        "\n",
        "    # \u00c9valuation sur l'ensemble de test\n",
        "    print(\"\u00c9valuation finale sur l'ensemble de test...\")\n",
        "    test_results = evaluate_arat5(model, test_loader, tokenizer, device)\n",
        "    print(f\"Test Loss: {test_results['loss']:.4f}, Test Accuracy: {test_results['accuracy']:.4f}\")\n",
        "    print(f\"Test Kappa: {test_results['kappa']:.4f}, Test MAE: {test_results['mae']:.4f}\")\n",
        "    print(\"Matrice de confusion finale:\")\n",
        "    print(test_results[\"confusion_matrix\"])\n",
        "\n",
        "    return model, tokenizer, best_val_acc, history\n",
        "\n",
        "# 7. Fonction pour tester le mod\u00e8le sur des exemples r\u00e9els\n",
        "# ------------------------------------------------------\n",
        "\n",
        "def tester_arat5_model(model, tokenizer, device):\n",
        "    \"\"\"\n",
        "    Teste le mod\u00e8le AraT5 sur des exemples r\u00e9els et vari\u00e9s\n",
        "    \"\"\"\n",
        "    # D\u00e9finir des exemples de test islamiques\n",
        "    exemples_test_islamique = [\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\",\n",
        "            \"reponse\": \"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u062e\u0645\u0633\u0629: \u0634\u0647\u0627\u062f\u0629 \u0623\u0646 \u0644\u0627 \u0625\u0644\u0647 \u0625\u0644\u0627 \u0627\u0644\u0644\u0647 \u0648\u0623\u0646 \u0645\u062d\u0645\u062f\u064b\u0627 \u0631\u0633\u0648\u0644 \u0627\u0644\u0644\u0647\u060c \u0648\u0625\u0642\u0627\u0645 \u0627\u0644\u0635\u0644\u0627\u0629\u060c \u0648\u0625\u064a\u062a\u0627\u0621 \u0627\u0644\u0632\u0643\u0627\u0629\u060c \u0648\u0635\u0648\u0645 \u0631\u0645\u0636\u0627\u0646\u060c \u0648\u062d\u062c \u0627\u0644\u0628\u064a\u062a \u0644\u0645\u0646 \u0627\u0633\u062a\u0637\u0627\u0639 \u0625\u0644\u064a\u0647 \u0633\u0628\u064a\u0644\u0627.\",\n",
        "            \"note_attendue\": 4\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\",\n",
        "            \"reponse\": \"\u0627\u0644\u0634\u0647\u0627\u062f\u062a\u064a\u0646 \u0648\u0627\u0644\u0635\u0644\u0627\u0629 \u0648\u0627\u0644\u0632\u0643\u0627\u0629 \u0648\u0627\u0644\u0635\u064a\u0627\u0645 \u0648\u0627\u0644\u062d\u062c.\",\n",
        "            \"note_attendue\": 2\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\",\n",
        "            \"reponse\": \"\u0627\u0644\u0635\u0644\u0627\u0629 \u0648\u0627\u0644\u0635\u064a\u0627\u0645 \u0648\u0627\u0644\u062d\u062c.\",\n",
        "            \"note_attendue\": 1\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\",\n",
        "            \"reponse\": \"\u0644\u0627 \u0623\u0639\u0631\u0641 \u0628\u0627\u0644\u0636\u0628\u0637.\",\n",
        "            \"note_attendue\": 0\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0634\u0631\u0648\u0637 \u0627\u0644\u0635\u0644\u0627\u0629\u061f\",\n",
        "            \"reponse\": \"\u0634\u0631\u0648\u0637 \u0627\u0644\u0635\u0644\u0627\u0629 \u0647\u064a: \u0627\u0644\u0625\u0633\u0644\u0627\u0645\u060c \u0648\u0627\u0644\u0639\u0642\u0644\u060c \u0648\u0627\u0644\u062a\u0645\u064a\u064a\u0632\u060c \u0648\u062f\u062e\u0648\u0644 \u0627\u0644\u0648\u0642\u062a\u060c \u0648\u0631\u0641\u0639 \u0627\u0644\u062d\u062f\u062b\u060c \u0648\u0625\u0632\u0627\u0644\u0629 \u0627\u0644\u0646\u062c\u0627\u0633\u0629\u060c \u0648\u0633\u062a\u0631 \u0627\u0644\u0639\u0648\u0631\u0629\u060c \u0648\u0627\u0633\u062a\u0642\u0628\u0627\u0644 \u0627\u0644\u0642\u0628\u0644\u0629\u060c \u0648\u0627\u0644\u0646\u064a\u0629.\",\n",
        "            \"note_attendue\": 4\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0634\u0631\u0648\u0637 \u0627\u0644\u0635\u0644\u0627\u0629\u061f\",\n",
        "            \"reponse\": \"\u0645\u0646 \u0634\u0631\u0648\u0637 \u0627\u0644\u0635\u0644\u0627\u0629 \u0627\u0644\u0637\u0647\u0627\u0631\u0629 \u0648\u0627\u0633\u062a\u0642\u0628\u0627\u0644 \u0627\u0644\u0642\u0628\u0644\u0629 \u0648\u0633\u062a\u0631 \u0627\u0644\u0639\u0648\u0631\u0629.\",\n",
        "            \"note_attendue\": 2\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # D\u00e9finir des exemples de test de langue arabe\n",
        "    exemples_test_arabe = [\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0623\u0642\u0633\u0627\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\",\n",
        "            \"reponse\": \"\u062a\u0646\u0642\u0633\u0645 \u0627\u0644\u0643\u0644\u0645\u0629 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0625\u0644\u0649 \u062b\u0644\u0627\u062b\u0629 \u0623\u0642\u0633\u0627\u0645: \u0627\u0633\u0645 \u0648\u0641\u0639\u0644 \u0648\u062d\u0631\u0641. \u0627\u0644\u0627\u0633\u0645 \u0647\u0648 \u0645\u0627 \u062f\u0644 \u0639\u0644\u0649 \u0645\u0639\u0646\u0649 \u0641\u064a \u0646\u0641\u0633\u0647 \u0648\u0644\u0645 \u064a\u0642\u062a\u0631\u0646 \u0628\u0632\u0645\u0646 \u0645\u062b\u0644: \u0643\u062a\u0627\u0628\u060c \u0642\u0644\u0645\u060c \u0645\u062d\u0645\u062f. \u0648\u0627\u0644\u0641\u0639\u0644 \u0647\u0648 \u0645\u0627 \u062f\u0644 \u0639\u0644\u0649 \u0645\u0639\u0646\u0649 \u0641\u064a \u0646\u0641\u0633\u0647 \u0648\u0627\u0642\u062a\u0631\u0646 \u0628\u0632\u0645\u0646 \u0645\u062b\u0644: \u0643\u062a\u0628\u060c \u064a\u0643\u062a\u0628\u060c \u0627\u0643\u062a\u0628. \u0648\u0627\u0644\u062d\u0631\u0641 \u0647\u0648 \u0645\u0627 \u062f\u0644 \u0639\u0644\u0649 \u0645\u0639\u0646\u0649 \u0641\u064a \u063a\u064a\u0631\u0647 \u0645\u062b\u0644: \u0641\u064a\u060c \u0639\u0644\u0649\u060c \u0645\u0646.\",\n",
        "            \"note_attendue\": 4\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0623\u0642\u0633\u0627\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\",\n",
        "            \"reponse\": \"\u0623\u0642\u0633\u0627\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0647\u064a: \u0627\u0633\u0645 \u0648\u0641\u0639\u0644 \u0648\u062d\u0631\u0641.\",\n",
        "            \"note_attendue\": 2\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0623\u0642\u0633\u0627\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\",\n",
        "            \"reponse\": \"\u0627\u0633\u0645 \u0648\u0641\u0639\u0644 \u0641\u0642\u0637.\",\n",
        "            \"note_attendue\": 1\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0627\u0644\u0645\u0641\u0627\u0639\u064a\u0644 \u0627\u0644\u062e\u0645\u0633\u0629 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\",\n",
        "            \"reponse\": \"\u0627\u0644\u0645\u0641\u0627\u0639\u064a\u0644 \u0627\u0644\u062e\u0645\u0633\u0629 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0647\u064a: \u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0628\u0647\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0627\u0644\u0645\u0637\u0644\u0642\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0641\u064a\u0647 (\u0638\u0631\u0641 \u0627\u0644\u0632\u0645\u0627\u0646 \u0648\u0638\u0631\u0641 \u0627\u0644\u0645\u0643\u0627\u0646)\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0644\u0623\u062c\u0644\u0647\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0645\u0639\u0647. \u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0628\u0647 \u0647\u0648 \u0645\u0627 \u0648\u0642\u0639 \u0639\u0644\u064a\u0647 \u0641\u0639\u0644 \u0627\u0644\u0641\u0627\u0639\u0644. \u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0627\u0644\u0645\u0637\u0644\u0642 \u0647\u0648 \u0645\u0635\u062f\u0631 \u064a\u0630\u0643\u0631 \u0644\u062a\u0648\u0643\u064a\u062f \u0627\u0644\u0641\u0639\u0644 \u0623\u0648 \u0628\u064a\u0627\u0646 \u0646\u0648\u0639\u0647 \u0623\u0648 \u0639\u062f\u062f\u0647. \u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0641\u064a\u0647 \u0647\u0648 \u0627\u0633\u0645 \u0645\u0646\u0635\u0648\u0628 \u064a\u062f\u0644 \u0639\u0644\u0649 \u0632\u0645\u0627\u0646 \u0648\u0642\u0648\u0639 \u0627\u0644\u0641\u0639\u0644 \u0623\u0648 \u0645\u0643\u0627\u0646\u0647. \u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0644\u0623\u062c\u0644\u0647 \u0647\u0648 \u0645\u0635\u062f\u0631 \u0642\u0644\u0628\u064a \u064a\u0630\u0643\u0631 \u0644\u0628\u064a\u0627\u0646 \u0633\u0628\u0628 \u062d\u062f\u0648\u062b \u0627\u0644\u0641\u0639\u0644. \u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0645\u0639\u0647 \u0647\u0648 \u0627\u0633\u0645 \u0641\u0636\u0644\u0629 \u064a\u0630\u0643\u0631 \u0628\u0639\u062f \u0648\u0627\u0648 \u0628\u0645\u0639\u0646\u0649 '\u0645\u0639' \u0645\u0633\u0628\u0648\u0642\u0629 \u0628\u0641\u0639\u0644 \u0623\u0648 \u0645\u0627 \u0641\u064a\u0647 \u0645\u0639\u0646\u0627\u0647 \u0644\u0644\u062f\u0644\u0627\u0644\u0629 \u0639\u0644\u0649 \u0627\u0644\u0645\u0635\u0627\u062d\u0628\u0629.\",\n",
        "            \"note_attendue\": 4\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0627\u0644\u0645\u0641\u0627\u0639\u064a\u0644 \u0627\u0644\u062e\u0645\u0633\u0629 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\",\n",
        "            \"reponse\": \"\u0627\u0644\u0645\u0641\u0627\u0639\u064a\u0644 \u0627\u0644\u062e\u0645\u0633\u0629 \u0647\u064a: \u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0628\u0647\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0627\u0644\u0645\u0637\u0644\u0642\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0641\u064a\u0647\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0644\u0623\u062c\u0644\u0647\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0645\u0639\u0647.\",\n",
        "            \"note_attendue\": 2\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    tous_exemples = exemples_test_islamique + exemples_test_arabe\n",
        "\n",
        "    resultats = []\n",
        "    print(\"Test du mod\u00e8le AraT5 sur des exemples r\u00e9els:\")\n",
        "\n",
        "    # On va stocker d'abord toutes les lignes dans une liste\n",
        "    lignes_resultats = []\n",
        "\n",
        "    for i, exemple in enumerate(tous_exemples):\n",
        "        question = exemple[\"question\"]\n",
        "        reponse = exemple[\"reponse\"]\n",
        "        note_attendue = exemple[\"note_attendue\"]\n",
        "\n",
        "        input_text = f\"\u0633\u0624\u0627\u0644: {question} \u0625\u062c\u0627\u0628\u0629: {reponse}\"\n",
        "\n",
        "        inputs = tokenizer(\n",
        "            input_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        input_ids = inputs.input_ids.to(device)\n",
        "        attention_mask = inputs.attention_mask.to(device)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            prediction = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=10\n",
        "            )\n",
        "\n",
        "        note_predite = convert_t5_output_to_grade(prediction[0], tokenizer) - 1\n",
        "\n",
        "        correct = note_predite == note_attendue\n",
        "\n",
        "        resultat = {\n",
        "            \"question\": question,\n",
        "            \"reponse\": reponse,\n",
        "            \"note_attendue\": note_attendue,\n",
        "            \"note_predite\": note_predite,\n",
        "            \"correct\": correct\n",
        "        }\n",
        "        resultats.append(resultat)\n",
        "\n",
        "        # On ajoute dans la liste pour construire le DataFrame plus tard\n",
        "        lignes_resultats.append({\n",
        "            'Question': question,\n",
        "            'R\u00e9ponse': reponse[:50] + \"...\" if len(reponse) > 50 else reponse,\n",
        "            'Note attendue': note_attendue + 1,\n",
        "            'Note pr\u00e9dite': note_predite + 1,\n",
        "            'Correct': correct\n",
        "        })\n",
        "\n",
        "        print(f\"Exemple {i+1}:\")\n",
        "        print(f\"Question: {question}\")\n",
        "        print(f\"R\u00e9ponse (extrait): {reponse[:100]}...\")\n",
        "        print(f\"Note attendue: {note_attendue + 1}/5, Note pr\u00e9dite: {note_predite + 1}/5\")\n",
        "        print(f\"R\u00e9sultat: {'\u2713' if correct else '\u2717'}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Maintenant on cr\u00e9e le DataFrame \u00e0 partir de la liste\n",
        "    df_resultats = pd.DataFrame(lignes_resultats)\n",
        "\n",
        "    accuracy = sum(r[\"correct\"] for r in resultats) / len(resultats)\n",
        "    mae = sum(abs(r[\"note_predite\"] - r[\"note_attendue\"]) for r in resultats) / len(resultats)\n",
        "\n",
        "    print(f\"R\u00e9sultats finaux sur {len(resultats)} exemples:\")\n",
        "    print(f\"Pr\u00e9cision: {accuracy:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "\n",
        "    return resultats, df_resultats\n",
        "\n",
        "# 8. Fonction pour visualiser les r\u00e9sultats d'entra\u00eenement\n",
        "# ------------------------------------------------------\n",
        "\n",
        "def visualiser_resultats_arat5(history):\n",
        "    \"\"\"\n",
        "    Visualise les m\u00e9triques d'entra\u00eenement du mod\u00e8le AraT5\n",
        "\n",
        "    Args:\n",
        "        history (dict): Historique d'entra\u00eenement contenant les m\u00e9triques\n",
        "    \"\"\"\n",
        "    # Cr\u00e9er la figure avec 3 sous-graphiques\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    # Graphique des pertes\n",
        "    ax1.plot(history[\"train_loss\"], 'b-', label=\"Train\")\n",
        "    ax1.plot(history[\"val_loss\"], 'r-', label=\"Validation\")\n",
        "    ax1.set_title(\"\u00c9volution de la perte\")\n",
        "    ax1.set_xlabel(\"\u00c9poque\")\n",
        "    ax1.set_ylabel(\"Perte\")\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    # Graphique de l'exactitude et du kappa\n",
        "    ax2.plot(history[\"val_acc\"], 'g-', label=\"Accuracy\")\n",
        "    ax2.plot(history[\"val_kappa\"], 'm-', label=\"Kappa\")\n",
        "    ax2.set_title(\"Accuracy et Kappa\")\n",
        "    ax2.set_xlabel(\"\u00c9poque\")\n",
        "    ax2.set_ylabel(\"Valeur\")\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    # Graphique de MAE\n",
        "    ax3.plot(history[\"val_mae\"], 'c-', label=\"MAE\")\n",
        "    ax3.set_title(\"Erreur moyenne absolue (MAE)\")\n",
        "    ax3.set_xlabel(\"\u00c9poque\")\n",
        "    ax3.set_ylabel(\"MAE\")\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"resultats_entrainement_arat5.png\", dpi=300)\n",
        "\n",
        "    return fig\n",
        "\n",
        "# 9. Fonction pour analyser les performances du mod\u00e8le en d\u00e9tail\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "def analyser_performances_arat5(model, tokenizer, test_loader, device):\n",
        "    \"\"\"\n",
        "    Analyse d\u00e9taill\u00e9e des performances du mod\u00e8le AraT5 sur un ensemble de test\n",
        "\n",
        "    Args:\n",
        "        model: Mod\u00e8le AraT5 entra\u00een\u00e9\n",
        "        tokenizer: Tokenizer du mod\u00e8le\n",
        "        test_loader: DataLoader pour l'ensemble de test\n",
        "        device: Appareil de calcul (CPU/GPU)\n",
        "\n",
        "    Returns:\n",
        "        dict: Rapport d\u00e9taill\u00e9 des performances\n",
        "    \"\"\"\n",
        "    # \u00c9valuation du mod\u00e8le\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_confs = []  # Confiance des pr\u00e9dictions\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=\"\u00c9valuation d\u00e9taill\u00e9e\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # G\u00e9n\u00e9rer les pr\u00e9dictions\n",
        "            outputs = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=10,\n",
        "                return_dict_in_generate=True,\n",
        "                output_scores=True\n",
        "            )\n",
        "\n",
        "            # Convertir les pr\u00e9dictions et les labels en notes num\u00e9riques\n",
        "            for i, (pred_seq, lab) in enumerate(zip(outputs.sequences, labels)):\n",
        "                # Supprimer les valeurs -100 des labels et d\u00e9coder\n",
        "                label_ids = lab.clone()\n",
        "                label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "                decoded_label = tokenizer.decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "                try:\n",
        "                    true_grade = int(decoded_label.strip())\n",
        "                    # Ajuster \u00e0 l'intervalle 0-4 pour les m\u00e9triques\n",
        "                    true_grade = max(1, min(true_grade, 5)) - 1\n",
        "                except:\n",
        "                    # Si la conversion \u00e9choue, ignorer cet exemple\n",
        "                    continue\n",
        "\n",
        "                # Obtenir la pr\u00e9diction\n",
        "                pred_grade = convert_t5_output_to_grade(pred_seq, tokenizer) - 1  # Ajuster \u00e0 0-4\n",
        "\n",
        "                # Calcul approximatif de la confiance du mod\u00e8le\n",
        "                sequence_scores = outputs.scores[0][i]  # Prendre les scores de la premi\u00e8re position g\u00e9n\u00e9r\u00e9e\n",
        "                token_probs = torch.nn.functional.softmax(sequence_scores, dim=-1)\n",
        "                confidence = token_probs[torch.argmax(token_probs)].item()  # Probabilit\u00e9 du token le plus probable\n",
        "\n",
        "                all_preds.append(pred_grade)\n",
        "                all_labels.append(true_grade)\n",
        "                all_confs.append(confidence)\n",
        "\n",
        "    if not all_preds:\n",
        "        return {\"error\": \"Aucune pr\u00e9diction valide\"}\n",
        "\n",
        "    # Calculer les m\u00e9triques de performance\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    kappa = cohen_kappa_score(all_labels, all_preds, weights='quadratic')\n",
        "    mae = np.mean(np.abs(np.array(all_preds) - np.array(all_labels)))\n",
        "\n",
        "    # Classification report\n",
        "    class_names = ['1/5', '2/5', '3/5', '4/5', '5/5']  # Convertir \u00e0 l'\u00e9chelle 1-5 pour l'affichage\n",
        "    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
        "\n",
        "    # Matrice de confusion\n",
        "    cm = confusion_matrix(all_labels, all_preds, labels=range(5))\n",
        "\n",
        "    # Cr\u00e9er des visualisations\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # 1. Matrice de confusion\n",
        "    plt.subplot(2, 2, 1)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Matrice de confusion')\n",
        "    plt.xlabel('Pr\u00e9diction')\n",
        "    plt.ylabel('Valeur r\u00e9elle')\n",
        "\n",
        "    # 2. Distribution des notes r\u00e9elles vs pr\u00e9dites\n",
        "    plt.subplot(2, 2, 2)\n",
        "    df = pd.DataFrame({'R\u00e9elle': [class_names[i] for i in all_labels],\n",
        "                      'Pr\u00e9dite': [class_names[i] for i in all_preds]})\n",
        "    real_counts = df['R\u00e9elle'].value_counts().sort_index()\n",
        "    pred_counts = df['Pr\u00e9dite'].value_counts().sort_index()\n",
        "\n",
        "    combined = pd.DataFrame({'R\u00e9elle': real_counts, 'Pr\u00e9dite': pred_counts}).fillna(0)\n",
        "    combined.plot(kind='bar', ax=plt.gca())\n",
        "    plt.title('Distribution des notes')\n",
        "    plt.xlabel('Note')\n",
        "    plt.ylabel(\"Nombre d'exemples\")\n",
        "\n",
        "    # 3. Pr\u00e9cision par note\n",
        "    plt.subplot(2, 2, 3)\n",
        "    per_class_acc = [report[name]['precision'] for name in class_names]\n",
        "    plt.bar(class_names, per_class_acc)\n",
        "    plt.title('Pr\u00e9cision par note')\n",
        "    plt.xlabel('Note')\n",
        "    plt.ylabel('Pr\u00e9cision')\n",
        "\n",
        "    # 4. Relation entre confiance et pr\u00e9cision\n",
        "    plt.subplot(2, 2, 4)\n",
        "    correct = np.array(all_preds) == np.array(all_labels)\n",
        "    confidence_correct = pd.DataFrame({'Confiance': all_confs, 'Correct': correct})\n",
        "\n",
        "    # Regrouper par plages de confiance\n",
        "    confidence_bins = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "    confidence_correct['Bin'] = pd.cut(confidence_correct['Confiance'], bins=confidence_bins)\n",
        "    binned_accuracy = confidence_correct.groupby('Bin')['Correct'].mean()\n",
        "\n",
        "    binned_accuracy.plot(kind='bar', ax=plt.gca())\n",
        "    plt.title('Pr\u00e9cision vs Confiance')\n",
        "    plt.xlabel('Confiance')\n",
        "    plt.ylabel('Pr\u00e9cision')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('analyse_performances_arat5.png')\n",
        "\n",
        "    # R\u00e9sum\u00e9 des r\u00e9sultats\n",
        "    results = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"kappa\": kappa,\n",
        "        \"mae\": mae,\n",
        "        \"classification_report\": report,\n",
        "        \"confusion_matrix\": cm,\n",
        "        \"analysis_plot\": 'analyse_performances_arat5.png'\n",
        "    }\n",
        "\n",
        "    # Imprimer les principaux r\u00e9sultats\n",
        "    print(f\"Accuracy globale: {accuracy:.4f}\")\n",
        "    print(f\"Kappa de Cohen: {kappa:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(\"\\nRapport de classification:\")\n",
        "    print(pd.DataFrame(report).transpose())\n",
        "\n",
        "    return results\n",
        "\n",
        "# 10. Fonction pour noter une nouvelle r\u00e9ponse\n",
        "# ------------------------------------------\n",
        "\n",
        "def noter_nouvelle_reponse(question, reponse, model, tokenizer, device=None):\n",
        "    \"\"\"\n",
        "    Utilise le mod\u00e8le AraT5 entra\u00een\u00e9 pour noter une nouvelle r\u00e9ponse\n",
        "\n",
        "    Args:\n",
        "        question (str): La question pos\u00e9e\n",
        "        reponse (str): La r\u00e9ponse \u00e0 \u00e9valuer\n",
        "        model: Le mod\u00e8le AraT5 entra\u00een\u00e9\n",
        "        tokenizer: Le tokenizer du mod\u00e8le\n",
        "        device: L'appareil de calcul (CPU/GPU)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (note, confiance)\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Pr\u00e9paration de l'entr\u00e9e\n",
        "    input_text = f\"\u0633\u0624\u0627\u0644: {question} \u0625\u062c\u0627\u0628\u0629: {reponse}\"\n",
        "\n",
        "    # Tokenisation\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # D\u00e9placer les entr\u00e9es vers l'appareil appropri\u00e9\n",
        "    input_ids = inputs.input_ids.to(device)\n",
        "    attention_mask = inputs.attention_mask.to(device)\n",
        "\n",
        "    # G\u00e9n\u00e9ration avec les scores pour calculer la confiance\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=10,\n",
        "            return_dict_in_generate=True,\n",
        "            output_scores=True\n",
        "        )\n",
        "\n",
        "    # Obtenir la pr\u00e9diction\n",
        "    prediction = outputs.sequences[0]\n",
        "    note = convert_t5_output_to_grade(prediction, tokenizer)\n",
        "\n",
        "    # Calculer la confiance (probabilit\u00e9 du token pr\u00e9dit)\n",
        "    scores = outputs.scores[0][0]  # Scores pour le premier token g\u00e9n\u00e9r\u00e9\n",
        "    probs = torch.nn.functional.softmax(scores, dim=-1)\n",
        "    max_prob = torch.max(probs).item()\n",
        "\n",
        "    # Affichage d\u00e9taill\u00e9\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"R\u00e9ponse: {reponse[:100]}...\" if len(reponse) > 100 else f\"R\u00e9ponse: {reponse}\")\n",
        "    print(f\"Note attribu\u00e9e: {note}/5 (confiance: {max_prob:.2f})\")\n",
        "\n",
        "    # Explication de la note\n",
        "    explications = {\n",
        "        1: \"Cette r\u00e9ponse est tr\u00e8s insuffisante. Elle manque de contenu pertinent ou contient des erreurs graves.\",\n",
        "        2: \"Cette r\u00e9ponse est insuffisante. Elle contient quelques \u00e9l\u00e9ments corrects mais manque de profondeur ou de pr\u00e9cision.\",\n",
        "        3: \"Cette r\u00e9ponse est moyenne. Elle couvre partiellement le sujet mais pourrait \u00eatre plus d\u00e9velopp\u00e9e ou plus pr\u00e9cise.\",\n",
        "        4: \"Cette r\u00e9ponse est bonne. Elle couvre la plupart des aspects importants du sujet avec une bonne pr\u00e9cision.\",\n",
        "        5: \"Cette r\u00e9ponse est excellente. Elle est compl\u00e8te, pr\u00e9cise et bien structur\u00e9e.\"\n",
        "    }\n",
        "\n",
        "    print(f\"Explication: {explications[note]}\")\n",
        "\n",
        "    return note, max_prob\n",
        "\n",
        "# 11. Fonction principale pour ex\u00e9cuter tout le processus\n",
        "# ----------------------------------------------------\n",
        "\n",
        "def main_arat5_ameliore():\n",
        "    \"\"\"\n",
        "    Fonction principale am\u00e9lior\u00e9e pour l'entra\u00eenement et l'\u00e9valuation du mod\u00e8le AraT5\n",
        "    pour la notation automatique des r\u00e9ponses en arabe\n",
        "    \"\"\"\n",
        "    # 1. Entra\u00eenement du mod\u00e8le avec les fonctions am\u00e9lior\u00e9es\n",
        "    model, tokenizer, best_val_acc, history = entrainer_arat5_model(\n",
        "        nb_exemples=3000,        # Plus d'exemples\n",
        "        batch_size=16,           # Adapt\u00e9 selon la m\u00e9moire disponible\n",
        "        num_epochs=15,\n",
        "        learning_rate=3e-5,\n",
        "        patience=5,\n",
        "        gradient_accumulation_steps=4  # Pour simuler des batches plus grands\n",
        "    )\n",
        "\n",
        "    # 2. Visualisation des r\u00e9sultats d'entra\u00eenement\n",
        "    fig = visualiser_resultats_arat5(history)\n",
        "    plt.close(fig)\n",
        "\n",
        "    # 3. Charger le meilleur mod\u00e8le pour les tests\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    best_model = T5ForConditionalGeneration.from_pretrained(\"best_arat5_model\")\n",
        "    best_model.to(device)\n",
        "\n",
        "    # 4. Effectuer des tests sur des exemples r\u00e9els et vari\u00e9s\n",
        "    print(\"\\nTests sur des exemples r\u00e9els...\")\n",
        "    try:\n",
        "        resultats_test, df_resultats = tester_arat5_model(best_model, tokenizer, device)\n",
        "\n",
        "        # 5. Cr\u00e9er un graphique comparant les notes attendues et pr\u00e9dites\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        # Tracer les barres\n",
        "        width = 0.35\n",
        "        x = np.arange(len(df_resultats))\n",
        "        plt.bar(x - width/2, df_resultats['Note attendue'], width, label='Note attendue')\n",
        "        plt.bar(x + width/2, df_resultats['Note pr\u00e9dite'], width, label='Note pr\u00e9dite')\n",
        "\n",
        "        # Ajouter des \u00e9tiquettes et des titres\n",
        "        plt.xlabel('Exemple de test')\n",
        "        plt.ylabel('Note (\u00e9chelle 1-5)')\n",
        "        plt.title('Comparaison des notes attendues et pr\u00e9dites')\n",
        "        plt.xticks(x, [f'Ex{i+1}' for i in range(len(df_resultats))])\n",
        "        plt.yticks([1, 2, 3, 4, 5])\n",
        "        plt.legend()\n",
        "\n",
        "        # Ajouter des symboles pour indiquer les pr\u00e9dictions correctes/incorrectes\n",
        "        for i, correct in enumerate(df_resultats['Correct']):\n",
        "            plt.text(i, 5.2, '\u2713' if correct else '\u2717', ha='center',\n",
        "                    color='green' if correct else 'red', fontsize=12)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('resultats_test_arat5.png', dpi=300)\n",
        "\n",
        "        # 6. Sauvegarder le mod\u00e8le et les r\u00e9sultats\n",
        "        print(\"\\nSauvegarde du mod\u00e8le et des r\u00e9sultats...\")\n",
        "\n",
        "        # Sauvegarde du mod\u00e8le final\n",
        "        best_model.save_pretrained(\"arat5_notation_final_ameliore\")\n",
        "        tokenizer.save_pretrained(\"arat5_notation_final_ameliore\")\n",
        "\n",
        "        # Sauvegarde des r\u00e9sultats de test\n",
        "        df_resultats.to_csv(\"resultats_test_arat5.csv\", index=False)\n",
        "\n",
        "        # Sauvegarde de l'historique d'entra\u00eenement\n",
        "        pd.DataFrame(history).to_csv(\"historique_entrainement_arat5.csv\", index=False)\n",
        "\n",
        "        print(\"Mod\u00e8le et r\u00e9sultats sauvegard\u00e9s avec succ\u00e8s!\")\n",
        "        print(f\"Meilleure pr\u00e9cision obtenue avec AraT5: {best_val_acc:.4f}\")\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        print(f\"Une erreur s'est produite pendant la phase de test : {e}\")\n",
        "        traceback.print_exc()\n",
        "        print(\"\\nContinuation avec les exemples individuels...\")\n",
        "\n",
        "    # 7. Exemples d'utilisation du mod\u00e8le\n",
        "    print(\"\\nExemples d'utilisation du mod\u00e8le pour noter de nouvelles r\u00e9ponses:\")\n",
        "\n",
        "    # Exemple 1 - Bonne r\u00e9ponse\n",
        "    print(\"\\nExemple 1 - R\u00e9ponse compl\u00e8te et pr\u00e9cise:\")\n",
        "    noter_nouvelle_reponse(\n",
        "        \"\u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\",\n",
        "        \"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u062e\u0645\u0633\u0629: \u0634\u0647\u0627\u062f\u0629 \u0623\u0646 \u0644\u0627 \u0625\u0644\u0647 \u0625\u0644\u0627 \u0627\u0644\u0644\u0647 \u0648\u0623\u0646 \u0645\u062d\u0645\u062f\u064b\u0627 \u0631\u0633\u0648\u0644 \u0627\u0644\u0644\u0647\u060c \u0648\u0625\u0642\u0627\u0645 \u0627\u0644\u0635\u0644\u0627\u0629\u060c \u0648\u0625\u064a\u062a\u0627\u0621 \u0627\u0644\u0632\u0643\u0627\u0629\u060c \u0648\u0635\u0648\u0645 \u0631\u0645\u0636\u0627\u0646\u060c \u0648\u062d\u062c \u0627\u0644\u0628\u064a\u062a \u0644\u0645\u0646 \u0627\u0633\u062a\u0637\u0627\u0639 \u0625\u0644\u064a\u0647 \u0633\u0628\u064a\u0644\u0627.\",\n",
        "        best_model,\n",
        "        tokenizer,\n",
        "        device\n",
        "    )\n",
        "\n",
        "    # Exemple 2 - R\u00e9ponse incompl\u00e8te\n",
        "    print(\"\\nExemple 2 - R\u00e9ponse incompl\u00e8te:\")\n",
        "    noter_nouvelle_reponse(\n",
        "        \"\u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\",\n",
        "        \"\u0627\u0644\u0635\u0644\u0627\u0629 \u0648\u0627\u0644\u0632\u0643\u0627\u0629 \u0648\u0627\u0644\u0635\u0648\u0645 \u0648\u0627\u0644\u062d\u062c.\",\n",
        "        best_model,\n",
        "        tokenizer,\n",
        "        device\n",
        "    )\n",
        "\n",
        "    # Exemple 3 - Mauvaise r\u00e9ponse\n",
        "    print(\"\\nExemple 3 - R\u00e9ponse incorrecte:\")\n",
        "    noter_nouvelle_reponse(\n",
        "        \"\u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\",\n",
        "        \"\u0644\u0627 \u0623\u0639\u0631\u0641 \u0628\u0627\u0644\u0636\u0628\u0637.\",\n",
        "        best_model,\n",
        "        tokenizer,\n",
        "        device\n",
        "    )\n",
        "\n",
        "    return best_model, tokenizer, history, df_resultats\n",
        "\n",
        "# Ex\u00e9cution du code principal si ex\u00e9cut\u00e9 comme script\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main_arat5_ameliore()\n",
        "    except Exception as e:\n",
        "        # Afficher plus d'informations sur l'erreur pour faciliter le d\u00e9bogage\n",
        "        import traceback\n",
        "        print(f\"Une erreur s'est produite : {e}\")\n",
        "        print(\"\\nTraceback complet :\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "        # Si c'est une erreur de CUDA, sugg\u00e9rer des solutions\n",
        "        if \"CUDA\" in str(e):\n",
        "            print(\"\\nSuggestion : Il semble y avoir un probl\u00e8me avec CUDA. Essayez de r\u00e9duire la taille du batch ou utilisez CPU.\")\n",
        "            print(\"Pour utiliser CPU uniquement, ajoutez : os.environ['CUDA_VISIBLE_DEVICES'] = '-1' au d\u00e9but du script.\")\n",
        "\n",
        "        # Si c'est une erreur de m\u00e9moire\n",
        "        if \"memory\" in str(e).lower() or \"out of memory\" in str(e).lower():\n",
        "            print(\"\\nSuggestion : Probl\u00e8me de m\u00e9moire. Essayez de r\u00e9duire :\")\n",
        "            print(\"1. batch_size (actuellement 16)\")\n",
        "            print(\"2. max_length (actuellement 512)\")\n",
        "            print(\"3. nb_exemples (actuellement 3000)\")\n",
        "            print(\"4. Utilisez une accumulation de gradient plus grande (actuellement 4)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "def telecharger_et_preparer_arat5(modele_id=\"UBC-NLP/AraT5-base\",\n",
        "                                chemin_modele_local=\"arat5_notation_modele\",\n",
        "                                utiliser_modele_local=True):\n",
        "    \"\"\"\n",
        "    T\u00e9l\u00e9charge et pr\u00e9pare le mod\u00e8le AraT5 pour la notation\n",
        "\n",
        "    Args:\n",
        "        modele_id (str): Identifiant du mod\u00e8le AraT5 de base\n",
        "        chemin_modele_local (str): Chemin vers le mod\u00e8le local entra\u00een\u00e9\n",
        "        utiliser_modele_local (bool): Si True, utilise le mod\u00e8le local s'il existe\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, tokenizer, device)\n",
        "    \"\"\"\n",
        "    # V\u00e9rifier si le GPU est disponible\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Utilisation de l'appareil: {device}\")\n",
        "\n",
        "    # V\u00e9rifier si un mod\u00e8le local existe d\u00e9j\u00e0\n",
        "    if utiliser_modele_local and os.path.exists(chemin_modele_local):\n",
        "        print(f\"Chargement du mod\u00e8le local depuis {chemin_modele_local}...\")\n",
        "        try:\n",
        "            tokenizer = AutoTokenizer.from_pretrained(chemin_modele_local, use_fast=False)\n",
        "            model = T5ForConditionalGeneration.from_pretrained(chemin_modele_local)\n",
        "            model.to(device)\n",
        "            print(\"Mod\u00e8le local charg\u00e9 avec succ\u00e8s!\")\n",
        "            return model, tokenizer, device\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur lors du chargement du mod\u00e8le local: {e}\")\n",
        "            print(\"T\u00e9l\u00e9chargement du mod\u00e8le de base \u00e0 la place...\")\n",
        "\n",
        "    # T\u00e9l\u00e9charger le mod\u00e8le de base\n",
        "    print(f\"T\u00e9l\u00e9chargement du mod\u00e8le de base {modele_id}...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(modele_id, use_fast=False)\n",
        "    model = T5ForConditionalGeneration.from_pretrained(modele_id)\n",
        "    model.to(device)\n",
        "\n",
        "    print(\"Mod\u00e8le t\u00e9l\u00e9charg\u00e9 avec succ\u00e8s!\")\n",
        "    print(\"Note: Ce mod\u00e8le n'est pas encore fine-tun\u00e9 pour la notation. Utilisez un mod\u00e8le entra\u00een\u00e9 pour de meilleurs r\u00e9sultats.\")\n",
        "\n",
        "    return model, tokenizer, device\n",
        "\n",
        "def convert_t5_output_to_grade(prediction, tokenizer):\n",
        "    \"\"\"\n",
        "    Convertit la sortie du mod\u00e8le T5 en note num\u00e9rique\n",
        "\n",
        "    Args:\n",
        "        prediction: La pr\u00e9diction brute du mod\u00e8le\n",
        "        tokenizer: Le tokenizer utilis\u00e9\n",
        "\n",
        "    Returns:\n",
        "        int: La note pr\u00e9dite (1-5)\n",
        "    \"\"\"\n",
        "    decoded_prediction = tokenizer.decode(prediction, skip_special_tokens=True)\n",
        "\n",
        "    # Essayer de convertir en entier (note de 1 \u00e0 5)\n",
        "    try:\n",
        "        grade = int(decoded_prediction.strip())\n",
        "        # S'assurer que la note est bien dans l'intervalle 1-5\n",
        "        if grade < 1:\n",
        "            grade = 1\n",
        "        elif grade > 5:\n",
        "            grade = 5\n",
        "    except:\n",
        "        # Si la conversion \u00e9choue, attribuer la note moyenne\n",
        "        grade = 3\n",
        "\n",
        "    return grade\n",
        "\n",
        "def noter_reponse_interactive(model, tokenizer, device):\n",
        "    \"\"\"\n",
        "    Interface interactive pour noter des r\u00e9ponses\n",
        "\n",
        "    Args:\n",
        "        model: Le mod\u00e8le AraT5\n",
        "        tokenizer: Le tokenizer\n",
        "        device: L'appareil de calcul (CPU/GPU)\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"SYST\u00c8ME DE NOTATION DE R\u00c9PONSES EN ARABE\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Entrez votre question et la r\u00e9ponse \u00e0 \u00e9valuer.\")\n",
        "    print(\"Entrez 'q' ou 'quit' pour quitter.\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Explication des notes\n",
        "    explications = {\n",
        "        1: \"TR\u00c8S INSUFFISANT - R\u00e9ponse incorrecte ou sans contenu pertinent.\",\n",
        "        2: \"INSUFFISANT - R\u00e9ponse partiellement correcte mais tr\u00e8s incompl\u00e8te.\",\n",
        "        3: \"MOYEN - R\u00e9ponse acceptable avec des \u00e9l\u00e9ments corrects mais manque de d\u00e9tails.\",\n",
        "        4: \"BON - R\u00e9ponse correcte et assez compl\u00e8te.\",\n",
        "        5: \"EXCELLENT - R\u00e9ponse compl\u00e8te, pr\u00e9cise et bien structur\u00e9e.\"\n",
        "    }\n",
        "\n",
        "    # Historique des notations pour afficher des statistiques\n",
        "    historique = []\n",
        "\n",
        "    while True:\n",
        "        # Saisie de la question\n",
        "        question = input(\"\\nQuestion (ou 'q' pour quitter): \")\n",
        "        if question.lower() in ['q', 'quit', 'exit']:\n",
        "            break\n",
        "\n",
        "        # Saisie de la r\u00e9ponse\n",
        "        reponse = input(\"R\u00e9ponse \u00e0 \u00e9valuer: \")\n",
        "        if reponse.lower() in ['q', 'quit', 'exit']:\n",
        "            break\n",
        "\n",
        "        # Option pour entrer une note attendue (pour comparaison)\n",
        "        note_attendue_str = input(\"Note attendue (1-5, ou laisser vide): \")\n",
        "        note_attendue = None\n",
        "        if note_attendue_str.strip():\n",
        "            try:\n",
        "                note_attendue = int(note_attendue_str)\n",
        "                if note_attendue < 1 or note_attendue > 5:\n",
        "                    print(\"Note hors plage, ignor\u00e9e.\")\n",
        "                    note_attendue = None\n",
        "            except:\n",
        "                print(\"Format de note invalide, ignor\u00e9e.\")\n",
        "\n",
        "        # Formater l'entr\u00e9e\n",
        "        input_text = f\"\u0633\u0624\u0627\u0644: {question} \u0625\u062c\u0627\u0628\u0629: {reponse}\"\n",
        "        inputs = tokenizer(\n",
        "            input_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # D\u00e9placer les entr\u00e9es sur l'appareil appropri\u00e9\n",
        "        input_ids = inputs.input_ids.to(device)\n",
        "        attention_mask = inputs.attention_mask.to(device)\n",
        "\n",
        "        # G\u00e9n\u00e9rer la pr\u00e9diction\n",
        "        print(\"\\nAnalyse en cours...\")\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=10,\n",
        "                return_dict_in_generate=True,\n",
        "                output_scores=True\n",
        "            )\n",
        "\n",
        "        # Obtenir la pr\u00e9diction\n",
        "        prediction = outputs.sequences[0]\n",
        "        note = convert_t5_output_to_grade(prediction, tokenizer)\n",
        "\n",
        "        # Calculer la confiance\n",
        "        scores = outputs.scores[0][0]\n",
        "        probs = torch.nn.functional.softmax(scores, dim=-1)\n",
        "        max_prob = torch.max(probs).item()\n",
        "\n",
        "        # Ajouter \u00e0 l'historique\n",
        "        historique.append({\n",
        "            'question': question,\n",
        "            'reponse': reponse,\n",
        "            'note': note,\n",
        "            'confiance': max_prob,\n",
        "            'note_attendue': note_attendue\n",
        "        })\n",
        "\n",
        "        # Afficher le r\u00e9sultat\n",
        "        print(\"\\n\" + \"-\"*50)\n",
        "        print(f\"R\u00c9SULTAT DE L'\u00c9VALUATION:\")\n",
        "        print(\"-\"*50)\n",
        "        print(f\"Note attribu\u00e9e: {note}/5\")\n",
        "        print(f\"Confiance: {max_prob:.2f}\")\n",
        "        if note_attendue:\n",
        "            print(f\"Note attendue: {note_attendue}/5\")\n",
        "            print(f\"\u00c9cart: {abs(note - note_attendue)}\")\n",
        "            if note == note_attendue:\n",
        "                print(\"\u2713 La note correspond \u00e0 la note attendue!\")\n",
        "            else:\n",
        "                print(\"\u2717 La note diff\u00e8re de la note attendue.\")\n",
        "        print(f\"\\nExplication: {explications[note]}\")\n",
        "        print(\"-\"*50)\n",
        "\n",
        "        # Si nous avons \u00e9valu\u00e9 plusieurs r\u00e9ponses, afficher des statistiques\n",
        "        if len(historique) > 1:\n",
        "            print(\"\\nSTATISTIQUES DES NOTATIONS:\")\n",
        "            notes_donnees = [h['note'] for h in historique]\n",
        "            notes_moyennes = sum(notes_donnees) / len(notes_donnees)\n",
        "            print(f\"- Nombre d'\u00e9valuations: {len(historique)}\")\n",
        "            print(f\"- Note moyenne attribu\u00e9e: {notes_moyennes:.2f}/5\")\n",
        "\n",
        "            # Si des notes attendues ont \u00e9t\u00e9 fournies\n",
        "            notes_attendues = [h['note_attendue'] for h in historique if h['note_attendue'] is not None]\n",
        "            if notes_attendues:\n",
        "                ecarts = [abs(h['note'] - h['note_attendue']) for h in historique if h['note_attendue'] is not None]\n",
        "                ecart_moyen = sum(ecarts) / len(ecarts)\n",
        "                match_exact = sum(1 for e in ecarts if e == 0)\n",
        "                match_1 = sum(1 for e in ecarts if e <= 1)\n",
        "\n",
        "                print(f\"- \u00c9cart moyen avec les notes attendues: {ecart_moyen:.2f}\")\n",
        "                print(f\"- Correspondance exacte: {match_exact}/{len(notes_attendues)} ({match_exact/len(notes_attendues)*100:.1f}%)\")\n",
        "                print(f\"- Correspondance \u00e0 \u00b11 point: {match_1}/{len(notes_attendues)} ({match_1/len(notes_attendues)*100:.1f}%)\")\n",
        "\n",
        "    # Afficher un r\u00e9sum\u00e9 final des notations\n",
        "    if historique:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"R\u00c9SUM\u00c9 DES NOTATIONS\")\n",
        "        print(\"=\"*50)\n",
        "        print(f\"Nombre total d'\u00e9valuations: {len(historique)}\")\n",
        "\n",
        "        # Distribution des notes\n",
        "        print(\"\\nDistribution des notes:\")\n",
        "        notes_distribution = {}\n",
        "        for i in range(1, 6):\n",
        "            count = sum(1 for h in historique if h['note'] == i)\n",
        "            notes_distribution[i] = count\n",
        "            print(f\"  Note {i}/5: {count} r\u00e9ponses ({count/len(historique)*100:.1f}%)\")\n",
        "\n",
        "        # Comparaison avec notes attendues si disponibles\n",
        "        notes_attendues = [h['note_attendue'] for h in historique if h['note_attendue'] is not None]\n",
        "        if notes_attendues and len(notes_attendues) >= 3:\n",
        "            print(\"\\nComparaison avec les notes attendues:\")\n",
        "            ecarts = [abs(h['note'] - h['note_attendue']) for h in historique if h['note_attendue'] is not None]\n",
        "            ecart_moyen = sum(ecarts) / len(ecarts)\n",
        "            print(f\"  \u00c9cart moyen: {ecart_moyen:.2f}\")\n",
        "            print(f\"  Correspondance exacte: {sum(1 for e in ecarts if e == 0)/len(ecarts)*100:.1f}%\")\n",
        "            print(f\"  Correspondance \u00e0 \u00b11 point: {sum(1 for e in ecarts if e <= 1)/len(ecarts)*100:.1f}%\")\n",
        "\n",
        "            # Visualiser la comparaison si nous avons suffisamment de donn\u00e9es\n",
        "            try:\n",
        "                plt.figure(figsize=(12, 6))\n",
        "                indices = range(len(notes_attendues))\n",
        "                plt.plot(indices, [h['note_attendue'] for h in historique if h['note_attendue'] is not None], 'bo-', label='Note attendue')\n",
        "                plt.plot(indices, [h['note'] for h in historique if h['note_attendue'] is not None], 'ro-', label='Note pr\u00e9dite')\n",
        "                plt.ylim(0.5, 5.5)\n",
        "                plt.yticks([1, 2, 3, 4, 5])\n",
        "                plt.xlabel('Exemple')\n",
        "                plt.ylabel('Note (1-5)')\n",
        "                plt.title('Comparaison des notes attendues et pr\u00e9dites')\n",
        "                plt.legend()\n",
        "                plt.grid(True, linestyle='--', alpha=0.7)\n",
        "                plt.savefig('comparaison_notes.png')\n",
        "                print(\"\\nGraphique de comparaison sauvegard\u00e9 sous 'comparaison_notes.png'\")\n",
        "            except Exception as e:\n",
        "                print(f\"Erreur lors de la cr\u00e9ation du graphique: {e}\")\n",
        "\n",
        "    print(\"\\nMerci d'avoir utilis\u00e9 le syst\u00e8me de notation!\")\n",
        "\n",
        "def tester_modele_avec_exemples(model, tokenizer, device, nb_exemples=5):\n",
        "    \"\"\"\n",
        "    Teste le mod\u00e8le sur un ensemble d'exemples pr\u00e9d\u00e9finis\n",
        "\n",
        "    Args:\n",
        "        model: Le mod\u00e8le AraT5\n",
        "        tokenizer: Le tokenizer\n",
        "        device: L'appareil de calcul (CPU/GPU)\n",
        "        nb_exemples: Nombre d'exemples \u00e0 tester\n",
        "    \"\"\"\n",
        "    # Exemples pr\u00e9d\u00e9finis\n",
        "    exemples = [\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\",\n",
        "            \"reponse\": \"\u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u062e\u0645\u0633\u0629: \u0634\u0647\u0627\u062f\u0629 \u0623\u0646 \u0644\u0627 \u0625\u0644\u0647 \u0625\u0644\u0627 \u0627\u0644\u0644\u0647 \u0648\u0623\u0646 \u0645\u062d\u0645\u062f\u064b\u0627 \u0631\u0633\u0648\u0644 \u0627\u0644\u0644\u0647\u060c \u0648\u0625\u0642\u0627\u0645 \u0627\u0644\u0635\u0644\u0627\u0629\u060c \u0648\u0625\u064a\u062a\u0627\u0621 \u0627\u0644\u0632\u0643\u0627\u0629\u060c \u0648\u0635\u0648\u0645 \u0631\u0645\u0636\u0627\u0646\u060c \u0648\u062d\u062c \u0627\u0644\u0628\u064a\u062a \u0644\u0645\u0646 \u0627\u0633\u062a\u0637\u0627\u0639 \u0625\u0644\u064a\u0647 \u0633\u0628\u064a\u0644\u0627.\",\n",
        "            \"note_attendue\": 5\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\",\n",
        "            \"reponse\": \"\u0627\u0644\u0634\u0647\u0627\u062f\u062a\u064a\u0646 \u0648\u0627\u0644\u0635\u0644\u0627\u0629 \u0648\u0627\u0644\u0632\u0643\u0627\u0629 \u0648\u0627\u0644\u0635\u064a\u0627\u0645 \u0648\u0627\u0644\u062d\u062c.\",\n",
        "            \"note_attendue\": 3\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\",\n",
        "            \"reponse\": \"\u0627\u0644\u0635\u0644\u0627\u0629 \u0648\u0627\u0644\u0635\u064a\u0627\u0645 \u0648\u0627\u0644\u062d\u062c.\",\n",
        "            \"note_attendue\": 2\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0623\u0631\u0643\u0627\u0646 \u0627\u0644\u0625\u0633\u0644\u0627\u0645 \u0627\u0644\u062e\u0645\u0633\u0629\u061f\",\n",
        "            \"reponse\": \"\u0644\u0627 \u0623\u0639\u0631\u0641 \u0628\u0627\u0644\u0636\u0628\u0637.\",\n",
        "            \"note_attendue\": 1\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0623\u0642\u0633\u0627\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\",\n",
        "            \"reponse\": \"\u062a\u0646\u0642\u0633\u0645 \u0627\u0644\u0643\u0644\u0645\u0629 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0625\u0644\u0649 \u062b\u0644\u0627\u062b\u0629 \u0623\u0642\u0633\u0627\u0645: \u0627\u0633\u0645 \u0648\u0641\u0639\u0644 \u0648\u062d\u0631\u0641. \u0627\u0644\u0627\u0633\u0645 \u0647\u0648 \u0645\u0627 \u062f\u0644 \u0639\u0644\u0649 \u0645\u0639\u0646\u0649 \u0641\u064a \u0646\u0641\u0633\u0647 \u0648\u0644\u0645 \u064a\u0642\u062a\u0631\u0646 \u0628\u0632\u0645\u0646 \u0645\u062b\u0644: \u0643\u062a\u0627\u0628\u060c \u0642\u0644\u0645\u060c \u0645\u062d\u0645\u062f. \u0648\u0627\u0644\u0641\u0639\u0644 \u0647\u0648 \u0645\u0627 \u062f\u0644 \u0639\u0644\u0649 \u0645\u0639\u0646\u0649 \u0641\u064a \u0646\u0641\u0633\u0647 \u0648\u0627\u0642\u062a\u0631\u0646 \u0628\u0632\u0645\u0646 \u0645\u062b\u0644: \u0643\u062a\u0628\u060c \u064a\u0643\u062a\u0628\u060c \u0627\u0643\u062a\u0628. \u0648\u0627\u0644\u062d\u0631\u0641 \u0647\u0648 \u0645\u0627 \u062f\u0644 \u0639\u0644\u0649 \u0645\u0639\u0646\u0649 \u0641\u064a \u063a\u064a\u0631\u0647 \u0645\u062b\u0644: \u0641\u064a\u060c \u0639\u0644\u0649\u060c \u0645\u0646.\",\n",
        "            \"note_attendue\": 5\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0623\u0642\u0633\u0627\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\",\n",
        "            \"reponse\": \"\u0623\u0642\u0633\u0627\u0645 \u0627\u0644\u0643\u0644\u0627\u0645 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0647\u064a: \u0627\u0633\u0645 \u0648\u0641\u0639\u0644 \u0648\u062d\u0631\u0641.\",\n",
        "            \"note_attendue\": 3\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0634\u0631\u0648\u0637 \u0627\u0644\u0635\u0644\u0627\u0629\u061f\",\n",
        "            \"reponse\": \"\u0634\u0631\u0648\u0637 \u0627\u0644\u0635\u0644\u0627\u0629 \u0647\u064a: \u0627\u0644\u0625\u0633\u0644\u0627\u0645\u060c \u0648\u0627\u0644\u0639\u0642\u0644\u060c \u0648\u0627\u0644\u062a\u0645\u064a\u064a\u0632\u060c \u0648\u062f\u062e\u0648\u0644 \u0627\u0644\u0648\u0642\u062a\u060c \u0648\u0631\u0641\u0639 \u0627\u0644\u062d\u062f\u062b\u060c \u0648\u0625\u0632\u0627\u0644\u0629 \u0627\u0644\u0646\u062c\u0627\u0633\u0629\u060c \u0648\u0633\u062a\u0631 \u0627\u0644\u0639\u0648\u0631\u0629\u060c \u0648\u0627\u0633\u062a\u0642\u0628\u0627\u0644 \u0627\u0644\u0642\u0628\u0644\u0629\u060c \u0648\u0627\u0644\u0646\u064a\u0629.\",\n",
        "            \"note_attendue\": 5\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0634\u0631\u0648\u0637 \u0627\u0644\u0635\u0644\u0627\u0629\u061f\",\n",
        "            \"reponse\": \"\u0645\u0646 \u0634\u0631\u0648\u0637 \u0627\u0644\u0635\u0644\u0627\u0629 \u0627\u0644\u0637\u0647\u0627\u0631\u0629 \u0648\u0627\u0633\u062a\u0642\u0628\u0627\u0644 \u0627\u0644\u0642\u0628\u0644\u0629 \u0648\u0633\u062a\u0631 \u0627\u0644\u0639\u0648\u0631\u0629.\",\n",
        "            \"note_attendue\": 3\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0627\u0644\u0645\u0641\u0627\u0639\u064a\u0644 \u0627\u0644\u062e\u0645\u0633\u0629 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\",\n",
        "            \"reponse\": \"\u0627\u0644\u0645\u0641\u0627\u0639\u064a\u0644 \u0627\u0644\u062e\u0645\u0633\u0629 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0647\u064a: \u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0628\u0647\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0627\u0644\u0645\u0637\u0644\u0642\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0641\u064a\u0647 (\u0638\u0631\u0641 \u0627\u0644\u0632\u0645\u0627\u0646 \u0648\u0638\u0631\u0641 \u0627\u0644\u0645\u0643\u0627\u0646)\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0644\u0623\u062c\u0644\u0647\u060c \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0645\u0639\u0647.\",\n",
        "            \"note_attendue\": 4\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"\u0645\u0627 \u0647\u064a \u0627\u0644\u0645\u0641\u0627\u0639\u064a\u0644 \u0627\u0644\u062e\u0645\u0633\u0629 \u0641\u064a \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f\",\n",
        "            \"reponse\": \"\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0628\u0647 \u0648\u0627\u0644\u0645\u0641\u0639\u0648\u0644 \u0641\u064a\u0647.\",\n",
        "            \"note_attendue\": 2\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Limiter au nombre d'exemples demand\u00e9\n",
        "    exemples = exemples[:min(nb_exemples, len(exemples))]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"TEST DU MOD\u00c8LE SUR DES EXEMPLES PR\u00c9D\u00c9FINIS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    resultats = []\n",
        "\n",
        "    for i, exemple in enumerate(exemples):\n",
        "        print(f\"\\nExemple {i+1}/{len(exemples)}:\")\n",
        "        print(f\"Question: {exemple['question']}\")\n",
        "        print(f\"R\u00e9ponse: {exemple['reponse'][:100]}...\" if len(exemple['reponse']) > 100 else f\"R\u00e9ponse: {exemple['reponse']}\")\n",
        "\n",
        "        # Formater l'entr\u00e9e\n",
        "        input_text = f\"\u0633\u0624\u0627\u0644: {exemple['question']} \u0625\u062c\u0627\u0628\u0629: {exemple['reponse']}\"\n",
        "        inputs = tokenizer(\n",
        "            input_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # D\u00e9placer les entr\u00e9es sur l'appareil appropri\u00e9\n",
        "        input_ids = inputs.input_ids.to(device)\n",
        "        attention_mask = inputs.attention_mask.to(device)\n",
        "\n",
        "        # G\u00e9n\u00e9rer la pr\u00e9diction\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=10,\n",
        "                return_dict_in_generate=True,\n",
        "                output_scores=True\n",
        "            )\n",
        "\n",
        "        # Obtenir la pr\u00e9diction\n",
        "        prediction = outputs.sequences[0]\n",
        "        note_predite = convert_t5_output_to_grade(prediction, tokenizer)\n",
        "\n",
        "        # Calculer la confiance\n",
        "        scores = outputs.scores[0][0]\n",
        "        probs = torch.nn.functional.softmax(scores, dim=-1)\n",
        "        max_prob = torch.max(probs).item()\n",
        "\n",
        "        # Ajouter aux r\u00e9sultats\n",
        "        resultats.append({\n",
        "            'question': exemple['question'],\n",
        "            'reponse': exemple['reponse'],\n",
        "            'note_attendue': exemple['note_attendue'],\n",
        "            'note_predite': note_predite,\n",
        "            'confiance': max_prob,\n",
        "            'correct': note_predite == exemple['note_attendue'],\n",
        "            'ecart': abs(note_predite - exemple['note_attendue'])\n",
        "        })\n",
        "\n",
        "        # Afficher le r\u00e9sultat\n",
        "        print(f\"Note attendue: {exemple['note_attendue']}/5\")\n",
        "        print(f\"Note pr\u00e9dite: {note_predite}/5 (confiance: {max_prob:.2f})\")\n",
        "        print(\"R\u00e9sultat: \" + (\"\u2713 Correct\" if note_predite == exemple['note_attendue'] else f\"\u2717 Incorrect (\u00e9cart: {abs(note_predite - exemple['note_attendue'])})\"))\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    # Afficher les statistiques globales\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"R\u00c9SULTATS DU TEST\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    exactitude = sum(r['correct'] for r in resultats) / len(resultats)\n",
        "    ecart_moyen = sum(r['ecart'] for r in resultats) / len(resultats)\n",
        "    dans_un_point = sum(1 for r in resultats if r['ecart'] <= 1) / len(resultats)\n",
        "\n",
        "    print(f\"Nombre d'exemples: {len(resultats)}\")\n",
        "    print(f\"Exactitude (pr\u00e9diction exacte): {exactitude:.2f} ({sum(r['correct'] for r in resultats)}/{len(resultats)})\")\n",
        "    print(f\"\u00c9cart moyen: {ecart_moyen:.2f}\")\n",
        "    print(f\"Pr\u00e9dictions \u00e0 \u00b11 point: {dans_un_point:.2f} ({sum(1 for r in resultats if r['ecart'] <= 1)}/{len(resultats)})\")\n",
        "\n",
        "    # Visualiser les r\u00e9sultats\n",
        "    try:\n",
        "        # Cr\u00e9er un graphique de comparaison\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        indices = range(len(resultats))\n",
        "        plt.plot(indices, [r['note_attendue'] for r in resultats], 'bo-', label='Note attendue')\n",
        "        plt.plot(indices, [r['note_predite'] for r in resultats], 'ro-', label='Note pr\u00e9dite')\n",
        "        plt.ylim(0.5, 5.5)\n",
        "        plt.yticks([1, 2, 3, 4, 5])\n",
        "        plt.xticks(indices, [f'Ex{i+1}' for i in indices])\n",
        "        plt.xlabel('Exemple')\n",
        "        plt.ylabel('Note (1-5)')\n",
        "        plt.title('Comparaison des notes attendues et pr\u00e9dites')\n",
        "        plt.legend()\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "        # Ajouter des indicateurs de correspondance\n",
        "        for i, r in enumerate(resultats):\n",
        "            plt.text(i, 5.2, '\u2713' if r['correct'] else '\u2717',\n",
        "                   ha='center', color='green' if r['correct'] else 'red', fontsize=12)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('resultats_test_examples.png')\n",
        "        print(\"\\nGraphique de comparaison sauvegard\u00e9 sous 'resultats_test_examples.png'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur lors de la cr\u00e9ation du graphique: {e}\")\n",
        "\n",
        "    return resultats\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Fonction principale pour tester le mod\u00e8le AraT5\n",
        "    \"\"\"\n",
        "    print(\"SYST\u00c8ME DE NOTATION AUTOMATIQUE EN ARABE\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # T\u00e9l\u00e9charger et pr\u00e9parer le mod\u00e8le\n",
        "    # Pour utiliser un mod\u00e8le entra\u00een\u00e9, sp\u00e9cifiez le chemin correct\n",
        "    model, tokenizer, device = telecharger_et_preparer_arat5(\n",
        "        chemin_modele_local=\"best_arat5_model\"  # Modifiez avec votre chemin\n",
        "    )\n",
        "\n",
        "    # Menu principal\n",
        "    while True:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"MENU PRINCIPAL\")\n",
        "        print(\"=\"*50)\n",
        "        print(\"1. Mode interactif (entrer des questions et r\u00e9ponses)\")\n",
        "        print(\"2. Tester le mod\u00e8le sur des exemples pr\u00e9d\u00e9finis\")\n",
        "        print(\"3. Quitter\")\n",
        "\n",
        "        choix = input(\"\\nVotre choix (1-3): \")\n",
        "\n",
        "        if choix == '1':\n",
        "            noter_reponse_interactive(model, tokenizer, device)\n",
        "        elif choix == '2':\n",
        "            nb_exemples = 5\n",
        "            try:\n",
        "                nb_input = input(\"Nombre d'exemples \u00e0 tester (1-10, d\u00e9faut=5): \")\n",
        "                if nb_input.strip():\n",
        "                    nb_exemples = int(nb_input)\n",
        "                    nb_exemples = max(1, min(10, nb_exemples))\n",
        "            except:\n",
        "                print(\"Valeur invalide, utilisation de la valeur par d\u00e9faut (5)\")\n",
        "\n",
        "            tester_modele_avec_exemples(model, tokenizer, device, nb_exemples)\n",
        "        elif choix == '3':\n",
        "            print(\"\\nMerci d'avoir utilis\u00e9 le syst\u00e8me de notation automatique!\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"\\nChoix invalide. Veuillez entrer 1, 2, ou 3.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3afb562f0ddb45fd8580a8fa52ea46db",
            "d4447517179442188300a293a488a07d",
            "ebabf6f21d3743a5b91ce200c9583b9b",
            "b907a5524f5b4d8bb720a9caa0c8a49e",
            "043487af67e94a07a223c106e85dbe20",
            "978dd8179e54493b9b45b13c710247db",
            "fe69de0eab644cbbae558ab72d45dc1c",
            "585323f6ce6240da89bbe758a0c112f7",
            "52d287c068fa424abb89e70da8c405f1",
            "49982e8ce73145a9868f79c1683d4a70",
            "e638b01ecf6f4e6c88f09b5915428b8b",
            "7130a7ab461043e4af74af1015919a81",
            "9dda30c38ea74edbb13cfb820c9d3418",
            "64e37bc0b22242abab2f4472bc30c355",
            "9497be6b27f2457e87c271d94b341fa6",
            "abe798d94d91434ea78f2779470aaed1",
            "29c0c78a9ff245fbad2767bf968699f8",
            "976591eb0ff84caf847a0517c9885e86",
            "510da51030244aeaaabf02f3358e79af",
            "abf69c2690314697800082082bfbbb35",
            "952167dee6f644f2a52c054b026a6289",
            "08fcb8acbef9415e8e90ee3471b05417",
            "b84060cc44e04353ba0ca823deac0ae7",
            "0fe62f1eb349451e9d4a10e85c737a95",
            "ad8d6fa2a3ba4e6cbf7ed5241e935ace",
            "940e08289df74703a83e1b59c12e1180",
            "c10284631d8546b0a0d272725abee486",
            "9d90d36922ca48b0832e3871773476b3",
            "93df43cfe56c475da6036a4a898fcb77",
            "6aab6f51de9b4298b0b1a6d59a0b5ec7",
            "294a8b393b194d069e682c36d99ad333",
            "771ac60e36b04938ac84dd9e9d532e46",
            "5de50799b0cd45e9b18c7cd936023c63",
            "4cebe836690d471182ec1e8c48f7d79b",
            "1a095ca87b884693a2e00f9d4c483a8e",
            "07b5f3ce8c6e45a182f964e432993965",
            "735415fc2d3547c19da5ceaff1238423",
            "76b8a8dac6c54a95a13d88847eb227ac",
            "754520b5a1d94c858dadb54cd65cf842",
            "a08b94be7ef543bf8d667db6e76abbf9",
            "a1fc6e755aee46ef80e8ab4ac800898f",
            "ca9735659c6f48999c4ecb506e13c8d6",
            "af473c771236423fb6161d57a2523282",
            "6a17dc60093e4c10aa4f4fe8c15f0751",
            "137db1e3798c499c81a502e480322fd3",
            "64e7b3af4fab454e85f40b08ca41b1b4",
            "7a47aedc98e24c328139eb53e0aeafaa",
            "4f9ad940657547bebe0da53e22382313",
            "edf4ea668d574e36816508f4d9c93541",
            "59598302744945a3b20bbd9cf9e7d2c4",
            "6d12ce5f1c9b4a609e9eb027d1e53233",
            "d87c84f8df2b40faa5b7b71b2eff8dda",
            "24b8da519f2742b089f720ef90f121b9",
            "b7ab81c1e85c4e08972cab5e54113939",
            "78f5e99d982f4a019e964da218d1ace4",
            "cd142d8abbdd4568bde85bb1190b553b",
            "5d784f044a6a4e8eaa2dfaf765a197b1",
            "99e9b8c0f58448048cd7ad62acf00822",
            "1a26b8e7131a47b4ad17f5d2182a222e",
            "17363429dced43ad85b190a0e913becf",
            "7d732f5a84a242a4a945c62e448fd535",
            "04eb032b530c4de0844b1d24de28162e",
            "fb4975ccf04e44e5a4b806c368cdda1c",
            "56f858c1534f4d928f8fc476bd0d6884",
            "14648dabe7b44d1d87730bf339dd219e",
            "429031390bae42bdadc848ace866f49e"
          ]
        },
        "id": "k_0FfDEOtXyu",
        "outputId": "def4a9f1-83d4-4f8a-9ab4-19c23988443d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYST\u00c8ME DE NOTATION AUTOMATIQUE EN ARABE\n",
            "==================================================\n",
            "Utilisation de l'appareil: cuda\n",
            "T\u00e9l\u00e9chargement du mod\u00e8le de base UBC-NLP/AraT5-base...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/81.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3afb562f0ddb45fd8580a8fa52ea46db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/541 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7130a7ab461043e4af74af1015919a81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/2.44M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b84060cc44e04353ba0ca823deac0ae7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/98.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cebe836690d471182ec1e8c48f7d79b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "137db1e3798c499c81a502e480322fd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd142d8abbdd4568bde85bb1190b553b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mod\u00e8le t\u00e9l\u00e9charg\u00e9 avec succ\u00e8s!\n",
            "Note: Ce mod\u00e8le n'est pas encore fine-tun\u00e9 pour la notation. Utilisez un mod\u00e8le entra\u00een\u00e9 pour de meilleurs r\u00e9sultats.\n",
            "\n",
            "==================================================\n",
            "MENU PRINCIPAL\n",
            "==================================================\n",
            "1. Mode interactif (entrer des questions et r\u00e9ponses)\n",
            "2. Tester le mod\u00e8le sur des exemples pr\u00e9d\u00e9finis\n",
            "3. Quitter\n",
            "\n",
            "Votre choix (1-3): 1\n",
            "\n",
            "==================================================\n",
            "SYST\u00c8ME DE NOTATION DE R\u00c9PONSES EN ARABE\n",
            "==================================================\n",
            "Entrez votre question et la r\u00e9ponse \u00e0 \u00e9valuer.\n",
            "Entrez 'q' ou 'quit' pour quitter.\n",
            "==================================================\n",
            "\n",
            "Question (ou 'q' pour quitter): \u0645\u0627 \u0631\u0623\u064a\u0643 \u0641\u064a \u062a\u0623\u062b\u064a\u0631 \u0648\u0633\u0627\u0626\u0644 \u0627\u0644\u062a\u0648\u0627\u0635\u0644 \u0627\u0644\u0627\u062c\u062a\u0645\u0627\u0639\u064a \u0639\u0644\u0649 \u0627\u0644\u0639\u0644\u0627\u0642\u0627\u062a \u0627\u0644\u0627\u062c\u062a\u0645\u0627\u0639\u064a\u0629 \u0641\u064a \u0627\u0644\u0645\u062c\u062a\u0645\u0639 \u0627\u0644\u0639\u0631\u0628\u064a\u061f\n",
            "R\u00e9ponse \u00e0 \u00e9valuer: \u0648\u0633\u0627\u0626\u0644 \u0627\u0644\u062a\u0648\u0627\u0635\u0644 \u0627\u0644\u0627\u062c\u062a\u0645\u0627\u0639\u064a \u0642\u0631\u0651\u0628\u062a \u0627\u0644\u0645\u0633\u0627\u0641\u0627\u062a \u0648\u0633\u0647\u0651\u0644\u062a \u0627\u0644\u062a\u0648\u0627\u0635\u0644\u060c \u0644\u0643\u0646\u0647\u0627 \u0623\u0636\u0639\u0641\u062a \u0627\u0644\u0639\u0644\u0627\u0642\u0627\u062a \u0627\u0644\u062d\u0642\u064a\u0642\u064a\u0629 \u0628\u064a\u0646 \u0627\u0644\u0646\u0627\u0633. \u0641\u0647\u064a \u0645\u0641\u064a\u062f\u0629 \u0625\u0630\u0627 \u0627\u0633\u062a\u064f\u062e\u062f\u0645\u062a \u0628\u0634\u0643\u0644 \u0625\u064a\u062c\u0627\u0628\u064a\u060c \u0644\u0643\u0646 \u0642\u062f \u062a\u0633\u0628\u0628 \u0639\u0632\u0644\u0629 \u0648\u0645\u0634\u0627\u0643\u0644 \u0627\u062c\u062a\u0645\u0627\u0639\u064a\u0629 \u0625\u0630\u0627 \u0623\u064f\u0633\u064a\u0621 \u0627\u0633\u062a\u062e\u062f\u0627\u0645\u0647\u0627.\n",
            "Note attendue (1-5, ou laisser vide): \n",
            "\n",
            "Analyse en cours...\n",
            "\n",
            "--------------------------------------------------\n",
            "R\u00c9SULTAT DE L'\u00c9VALUATION:\n",
            "--------------------------------------------------\n",
            "Note attribu\u00e9e: 3/5\n",
            "Confiance: 0.76\n",
            "\n",
            "Explication: MOYEN - R\u00e9ponse acceptable avec des \u00e9l\u00e9ments corrects mais manque de d\u00e9tails.\n",
            "--------------------------------------------------\n",
            "\n",
            "Question (ou 'q' pour quitter): q\n",
            "\n",
            "==================================================\n",
            "R\u00c9SUM\u00c9 DES NOTATIONS\n",
            "==================================================\n",
            "Nombre total d'\u00e9valuations: 1\n",
            "\n",
            "Distribution des notes:\n",
            "  Note 1/5: 0 r\u00e9ponses (0.0%)\n",
            "  Note 2/5: 0 r\u00e9ponses (0.0%)\n",
            "  Note 3/5: 1 r\u00e9ponses (100.0%)\n",
            "  Note 4/5: 0 r\u00e9ponses (0.0%)\n",
            "  Note 5/5: 0 r\u00e9ponses (0.0%)\n",
            "\n",
            "Merci d'avoir utilis\u00e9 le syst\u00e8me de notation!\n",
            "\n",
            "==================================================\n",
            "MENU PRINCIPAL\n",
            "==================================================\n",
            "1. Mode interactif (entrer des questions et r\u00e9ponses)\n",
            "2. Tester le mod\u00e8le sur des exemples pr\u00e9d\u00e9finis\n",
            "3. Quitter\n",
            "\n",
            "Votre choix (1-3): 1\n",
            "\n",
            "==================================================\n",
            "SYST\u00c8ME DE NOTATION DE R\u00c9PONSES EN ARABE\n",
            "==================================================\n",
            "Entrez votre question et la r\u00e9ponse \u00e0 \u00e9valuer.\n",
            "Entrez 'q' ou 'quit' pour quitter.\n",
            "==================================================\n",
            "\n",
            "Question (ou 'q' pour quitter): Q\n",
            "\n",
            "Merci d'avoir utilis\u00e9 le syst\u00e8me de notation!\n",
            "\n",
            "==================================================\n",
            "MENU PRINCIPAL\n",
            "==================================================\n",
            "1. Mode interactif (entrer des questions et r\u00e9ponses)\n",
            "2. Tester le mod\u00e8le sur des exemples pr\u00e9d\u00e9finis\n",
            "3. Quitter\n",
            "\n",
            "Votre choix (1-3): 3\n",
            "\n",
            "Merci d'avoir utilis\u00e9 le syst\u00e8me de notation automatique!\n"
          ]
        }
      ]
    }
  ]
}